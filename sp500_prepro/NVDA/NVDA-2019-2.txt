Jensen Huang: Yes, Mark. So, first of all, Turing, as you know, is the world’s first ray-tracing GPU. And it completes our new computer graphics platform, which is going to reinvent computer graphics altogether. It unites four different computing modes rasterization, accelerated ray-tracing, computing with CUDA, and artificial intelligence. It uses these four basic methods to create imagery for the future. There’s two different -- two major ways that we’ll experience the benefits right-away. The first is for the markets of visualization today, they require photorealistic images. Whether it’s a IKEA Catalog or movie, or architectural engineering, or product design, car design, all of these types of markets require photorealistic images. And the only way to really achieve that is to use ray-tracing with physically based materials and lighting. The technology is rather complicated, has been computing intensive for very long time. And it wasn’t until now that we’ve been able to achieve it in a productive way. And so, Turing has the ability to do ray-tracing, accelerated ray-tracing, and it also has the ability to combine very large frame buffers, because these data sets are extremely large. And so, that marketplace is quite large, and it’s never been served by GPUs before, until now, all of that has been run on CPU render farms, gigantic render farms in all these movie studios and service centers and so on and so forth. The second area where you’re going to see the benefits of ray-tracing, we haven’t announced.
Jensen Huang: Yes, Mark. At GTC this last year in March -- GDC and GTC, we announced a brand new platform called NVIDIA RTX. And this platform has those four computation methods that I described, for generating images. We put that platform out with the support of Microsoft. They call it the Microsoft DirectX Raytracing. And the major game engine companies, Epic has implemented real-time ray-tracing and the RTX into, the Unreal Engine. And at GDC and GTC, we demonstrated for the very first time on four Volta GPUs, on four Volta GPUs, the ability to do that. And it was the intention of - to get this platform out to all of the game developers. And we’ve been working with game developers throughout this time. This week, at SIGGRAPH, we announced our Quadro, which is the first -- the Quadro RTX 8000, 6000 and 5000, the world’s first accelerated ray-tracing GPUs. And I demonstrated one Quadro running the same application that we demonstrated on four Volta GPUsrunning in March. And the performance is really spectacular. And so, I think the answer to your question is, developers all have access to RTX. It’s in Microsoft’s DirectX; it’s in the most popular game engine in the world; and you’re going to start to see developers use it. On the workstation side, on the Professional Visualization side, all of the major ISVs have jumped on to adopt it. And at SIGGRAPH this year there, there you could see a whole bunch of developers demonstrating the NVIDIA RTX with accelerated ray-tracing, generating full realistic images. And so, I would say that no platform, in our history, has on day one of announcement, had so many developers jump onto it. And stay tuned. We’ve got a lot more stories to tell you about RTX.
Jensen Huang: Matt, on the channel inventory side, we see inventory in the lower end of our stack. And that inventory is well-positioned for back-to-school and the building season that’s coming up on Q3. And so, I feel pretty good about that. The rest of our product launches and the ramp-up of Turing is going really well. And so, I think the rest of the announcements we haven’t made, but stay tuned. The RTX family is going to be a real game-changer for us. And the reinvention of computer graphics altogether has been embraced by so many developers. We’re going to see some really exciting stuff this year.
Jensen Huang: Let’s see. Pascal was really successful. Pascal, relative to Maxwell, was a leap in fact, and it was a really significant upgrade. The architectures were largely the same. They were both programmable shading. They were both at the same generation programmable shading. But Pascal was much, much more energy efficient, I think it was something like 30%, 40% more energy efficient than Maxwell. And that translated to performance benefits to customers. The success of Pascal was fantastic. There’s just simply no comparison to Turing. Turing is a reinvention of computer graphics; it is the first ray-tracing GPU in the world; it’s the first GPU that will be able to ray trace light in an environment and create photorealistic shadows and reflections and be able to model things like areal lights and global illumination and indirect lighting. The images are going to be so subtle and so beautiful, when you look at it, it just looks like a movie. And yet it’s backwards compatible, with everything that we’ve done. This new hybrid rendering model which extends what we’ve built before but added to it two new capabilities artificial intelligence and accelerated ray-tracing is just fantastic. So, everything of the past will be brought along and benefits, and it’s going to create new visuals that weren’t possible before. We also did a good job on laying the foundations of the development platform for the developers. We partnered with Microsoft to create DXR, Vulkan RT is also coming, and we have OptiX that are used by ProViz renderers and developers all over the world. And so, we have the benefit of laying the foundation stack by stack by stack over the years. And as result, on the data that Turing comes out, we’re going to have a richness of applications that gamers will be able to enjoy. You mentioned guidance. I actually think that on a year-over-year performance, we’re doing terrific. And I’m super excited about the ramp of Turing. It is the case that we benefited in the last several quarters from an unusual lift from crypto. In the beginning of the year, we thought and we projected that crypto would be a larger contribution through the rest of year. But, at this time, we consider it to be immaterial for the second half. And so, that makes comparisons on a sequential basis -- on a I guess, quarterly sequential basis harder. But, on a year-to-year basis, I think we’re doing terrific. Every single one of our platforms are growing, high-performance computing of course, Datacenters is growing. AI, the adoption continues to seep from one industry to another industry. The automation that’s going to be brought about by AI, is going to bring productivity gains to industries like nobody has ever seen before. And now with Turing, we’re going to be able to reignite the Professional Visualization business, open us up to photorealistic rendering for the very first time, render farms, and everybody who is designing products that has to visualize it photo realistically to reinventing and resetting graphics for video games. And so, I think we’re in a great position, and I’m looking forward to reporting Q3, when the time comes.
Jensen Huang: Yes. That’s right. Atif, let me just add a little bit more to that. I think, the one simple way to think about that is this. In the transportation industry, let’s take one particular vertical, there are two dynamics that are happening that are very, very abundantly clear, and that will double -- transform that industry. The first of course is ride hailing and ride sharing. Those platforms in order to make a recommendation of which taxi to bring to which passenger, which customer, is a really large computing problem. It’s a machine learning problem; it’s an optimization problem at very, very large scale. And in every -- in each and every one of those instances, you need high-performance computers to use machine learning to figure out how to make that perfect match, or the most optimal match. The second is self-driving cars. Every single car company that’s working on robot taxis or self-driving cars, needs to collect data, label data, train on your network, or train a whole bunch of on your networks, and run those neural networks and cars. And so, you just make your list of how many people are actually building self-driving cars. And every single one of them will need even more GPU accelerated servers. And that’s just for developing the model. The next stage is to simulate the entire software because we know that the industry or the world travels 10 trillion miles per year. And the best we could possibly do is to drive several million normal miles. And what we really want to do is to be able to simulate and stress, stress test our software stack. And the only way to do that is to do in virtual reality. And so, that’s another supercomputer that you have to build for simulating all your software across those billions and billions of virtually created challenging miles. And then lastly, before you OTA, the software, you’re going to have to re-sim and replay against all of the miles that you’ve collected over the years to make sure that you have no regressions before you OTA the new models into a fleet of cars. And so, transportation is going to be a very large industry. Healthcare is the same way, from medical imaging that is now using AI just about everywhere to genomics that has discovered deep learning and the benefits of artificial intelligence, and in the future pathology. The list goes on. And so, industry after industry after industry, we’re discovering the benefits of deep learning, and the industries could be really, really revolutionized by them.
Jensen Huang: We’re expecting the channel inventory to work itself out. We are masters at managing our channel, and we understand the channel very well. As you know, the way that we go to market is through the channels around the world. We’re not concerned about the channel inventory. As we ramp Turing, whenever we ramp a new architecture, we ramp it from the top down. And so, we have plenty of opportunities as we go back to the back to school in the gaming cycle to manage the inventory. So, we feel pretty good about that. As a result, comparing Volta andTuring, entering, CUDA iscompatible, that’s one of the benefits of CUDA. CUDA, all of the applications that take advantage of CUDA are written on top of cuDNN, which is our network platform to TensorRT that takes advantage -- that takes the output of the frameworks and optimize it for runtime. All of those tools and libraries run on top of Voltaand run on top of Turing and run on top of Pascal. What Turing adds over Pascal is the same Tensor Corethat is inside Volta. Of course, Volta is designed for large scale training. Eight GPUs could be connected together. They have the fastest HBM2 memories. And it’s designed for datacenter applications, has 64-bit double-precision, ECC, high-resilience computing, and all of the software and system software capability and tools that make Voltathe perfect high-performance computing accelerator. In the case of Turing, it’s really designed for three major applications. The first application is to open up Pro Visualization, which is a really large market that has historically used render farms. And we’re really unable to use GPUs until we now have -- we now have the ability to do full path trace, global illumination with very, very large data sets. So, that’s one market that’s brand new as a result of Turing. The second market is to reinvent computer graphics, real time computer graphics for video games and other real time visualization applications. When you see the images created by Turing, you’re going to have a really hard time wanting to see the images of the past. It just looks amazing. And then the third, Turing has a really supercharged Tensor Core. And this Tensor Core is used for image generation. It’s also used for high throughput, deep learning inferencing for data centers. And so, these applications for Turing would suggest that there are multiple SKUs of Turing, which is one of the reasons why we have such a great engineering team, we could scale one architecture across a whole lot of platforms at one time. And so, I hope that answers your question that the Tensor Core inference capability of Turing is going to be off the charts.
Jensen Huang: Well, I think the second question is easier to answer and the reason -- the first one is just ambiguous. It’s hard to predict, anyway. It’s hard to estimate, no matter what. But, the second question, the answer is we’re expecting -- we’re projecting zero basically. And for the first question, how much of GeForce could’ve been used for crypto? A lot of gamers at night, they could -- while they’re sleeping, they could do some mining. And so, do they buy it for mining or did they buy it for gaming, it’s kind of hard to say. And some miners were unable to buy our OEM products, and so they jumped on to the market to buy it from retail, and that probably happened a great deal as well. And that all happened in the last -- the previous several quarters, probably starting from late Q3, Q4, Q1, and very little last quarter, and we’re projecting no crypto-mining going forward.
Jensen Huang: Yes, Aaron. I think, that if you look at the -- if you start from first principles, here’s the simple way to look at it. Demand is continuing to grow at historical levels of 10x computing demand. Computing demand is increasing at historical levels of 10x every five years. 10x every five years is approximately Moore’s Law. And computing demand continues to grow at 10x every five years. However, Moore’s Law stopped. And so, that gap in the world in high-performance computing, in medical imaging, in life sciences computing, in artificial intelligence, that gap -- because those applications demand more computing capability, that gap can only be served in another way. And NVIDIA’s videos GPU accelerated computing that we pioneered, really stands to benefit from that. And so, at the highest level, whether it’s supercomputing, and this year -- you heard Collette say earlier that NVIDIA GPUs represented 56% of all the new performance that came into the world’s TOP500. The TOP500 is called the TOP500, because it reflects the future of computing. And my expectation is that more and more from one vertical industry after another, and I mentioned transportation, I mentioned healthcare, the vertical industries go on and on, that as computing demand continues at a factor of 10x every five years, developers are rational and logical to have jumped on NVIDIA’s GPU computing to boost their demand. I think that’s probably the best way to answer it.
Jensen Huang: HGX-1 was I guess kind of the prototype of HGX-2. HGX-2 is doing incredibly well, and for all the reasons that you mentioned. It is an even the largest hyperscale data centers can’t afford to create these really complicated motherboards at the scale that we’re talking about. And so, we created HGX-2, and it was immediately adopted by several most important hyperscalers in the world. And we were at GTC Taiwan, and we announced basically all of the leading server OEMs and ODMs supporting HGX-2 and are ready to take it to market. So, we’re in the process of finishing HGX-2 and ramping into production. And so, I think HGX-2 is a huge success for exactly the reasons that you mentioned. We could use it for essentially a standard motherboard, like the ATX motherboard for PCs that could be used for hyper scalars, it could be used for HPC, it could be used for datacenters, and it’s a really fantastic design. It just allows people to adopt this really complicated and high-performance and really high-speed interconnect motherboard in a really easy way.
Jensen Huang: Sure. Well, the Crypto mining market is very different today than it was three years ago. And even though, new cards -- at the current prices, it doesn’t make much sense for new cards to be sold into the mining market. The existing capacity is still being used. And you can see the hash rates continue. And so, my sense is that the installed base of miners will continue to use their cards. And then, probably the more important factor though is that that we’re in the process of announcing a brand new way of doing computer graphics. And with Turing and our RTX platform, computer graphics will never be the same. And so, I think there’s -- our new generation of new GPUs is really going to great. I also think that -- I appreciate Elon’s comments about our Company, and I also think Tesla makes great cars, and I drive them very happily. And with respect to the next generation, it is the case that when we first started working on autonomous vehicles, they needed our help. And we used a three-year-old Pascal GPU for the current generation of autopilot computers. And it is very clear now that in order to have a safe autopilot system, we need a lot more computing horsepower. In order to have a safe computing -- in order to have safe driving, the algorithms have to be rich and has to be able to handle corner conditions in a lot of diverse situations. And every time that there’s more and more corner conditions or more subtle things that you have to do or you have to drive more smoothly or be able to take turns more quickly, all of those -- all of those requirements require greater computing capability. And that’s exactly the reason why we built Xavier. Xavier is in production now. We’re seeing great success and customers are super excited about Xavier. And that’s exactly the reason why we’ve built it. And I think a super-hard to build a Xavier and all the software stack on top of it. And if it doesn’t turn out for whatever reasons, it doesn’t turn out for them, they can give me a call, and I’d be more than happy to help.
Jensen Huang: We had a great quarter. Our core platforms exceeded expectations, even as crypto largely disappeared. Each of our platforms AI, Gaming, ProViz and self driving cars continued to enjoy great adoption. These markets are -- we are enabling are some of the most impactful to world -- to the world today. We launched Turing this week. It was 10 years in the making and completes the NVIDIA RTX platform. NVIDIA RTX with Turing is the greatest advance since CUDA, nearly a decade ago. I’m incredibly proud of our Company for tackling this incredible challenge, reinventing the entire graphic stack, and giving the industry a surge of excitement as we reinvent computer graphics. Stay tuned as we unfold the exciting RTX story. See you guys next time.
Colette Kress: Sure. Thanks for your questions. So, when you look at our inventory on the balance sheet, I think it’s generally consistent with what you have seen over the last several months in terms of what we will be bringing to market. Turing is an extremely important piece of architecture, and as you know, it will be with us for some time. So, I think the inventory balance is getting ready for that. And don’t forget, our work in terms of Datacenter and what we have for Volta is also a very, very complex computer in some cases in terms of what we have also in terms of there. So, just those things together, plus our Pascal architecture is still here, makes up almost all of what we have there in terms of inventory.
Colette Kress: Let me start first with your question regarding gross margins. We have essentially reached, as we move into Q3, normalization of our gross margins. I believe, over the last several quarters, we have seen the impact of crypto and what that can do to elevate our overall gross margins. We believe we’ve reached a normal period, as we’re looking forward to essentially no cryptocurrency as we move forward.
Colette Kress: So, as you know, we generally give our view on guidance for one quarter out. You are correct that our Datacenter results that we see is always a tremendous, unique mix every single quarter in terms of what we’re seeing. But, there’s still some underlying points of that that will likely continue. The growth in terms of use by the hyperscales, continued industry-by-industry coming on-board, essentially just because the needs of accelerated computing for the workloads and for the data that they have is so essential. So, we still expect as we go into Q3 for Datacenter to grow, both sequentially and year-over-year. And we’ll see probably a mix of both, selling our Tesla V100 platforms, but also a good contribution from DGX.
Colette Kress: So, when you look at our overall segments, as you’ve even seen our results in terms of this last Q2, there is growth across every single one of our platforms from a year-over-year standpoint. We probably possibly see that again in our Q3 guidance, the year-over-year growth across each and every one of those platforms. Of course, our OEM business will be down likely year-over-year, again just due to absence of those cryptocurrency in our forecast. When we think about sequentially, our hopes is absolutely our Datacenter will grow and will likely see the growth of our Gaming business as well. It’s still early, still we’ve got many different scenarios on our ProViz and Auto. But definitely our Gaming and our Datacenter are expected to grow sequentially.
Colette Kress: Yes. So, let me take your first part of the question regarding our gross margins and what we have seen from crypto. Although crypto revenue may not be large, it still has a derivative impact on our stack in terms of what we are selling and to both replenish the overall channel and such. So, over the last several quarters, that we had stabilizing that overall channel, we did get the great effect of selling just about everything and our margins really been able to benefit from that. Again, when we look at the overall growth year-over-year for Q2, you have 500 basis points in terms of growth. We’re excited about what we have now here for Q3 as well, which is also significant growth year-over-year. Of course, we have our high value added platforms as we move forward, both -- those in Datacenter, those in terms of what we expect the effects of Turing in terms of on our Quadro piece as well. But that will take some time for that all to partake. So, we’ll see how that goes. We haven’t announced anything further at this time. But, yes, we’ll see probably over the longer term, the effects of Turing can do.
