Jen-Hsun Huang - NVIDIA Corp.: So first of all, Q2 was a transition quarter for our data center. I thought we did great. We almost tripled year over year, and we ramped Volta into volume production. And because Volta was so much better than our last generation processor – Volta is 100 times faster than Kepler, 100 times faster than Kepler just four years ago, and Kepler was already 10 times faster than CPUs. And so Volta was such a giant leap when we announced it in GTC right at the beginning of the quarter. I thought the team did fantastically transitioning the customer base to Volta, and now Volta is in high-volume production. The application of data center – you asked a larger question about data center. Data center is a very large market, as you know, and the reason for that is because the vast majority of the world's future computing will be largely done in data centers. And there's a very well accepted notion now that GPU acceleration of servers delivers extraordinary value proposition. If you have a data-intensive application, and the vast majority of the future applications in data centers will be data intensive, a GPU could reduce the number of servers you require or increase the amount of throughput pretty substantially. Just adding one GPU to a server could reduce several hundred thousand dollars of reduction in number of servers. And so the value proposition and the cost savings of using GPUs is quite extraordinary. There are several applications in data centers. First of all, there's training and there's high-performance computing. There's cloud virtual PC, as what Amazon AWS G3 announcement was about this quarter. And then there are also new applications such as inferencing as these models are now going into production, and the new applications that are coming online, which is likely to overwhelm the Internet in the near future, which is live video, consumers taking live video on their phones and sharing it with their friends. And there are going to be hundreds of millions of these happening all the time, and each one of these videos will have to be transcoded to a variety of formats to be shared with their friends and also has to be – you have to perform AI on it instantaneously so that you could avoid inappropriate video from being streamed to large audiences. And so the number of applications where GPUs are valuable, from training to high-performance computing to virtual PCs to new applications like inferencing and transcoding and AI, are starting to emerge. The one area where you're talking about ASICs and TPUs, TPU is basically an ASIC. The way to think about that is this. After four generations of evolution of our GPU, NVIDIA GPU is basically a TPU that does a lot more. We could perform deep learning applications, whether it's in training or in inferencing now, starting with the Pascal P4 and the Volta generation. We can inference better than any known ASIC on the market that I've ever seen. And so the new generation of our GPUs is essentially a TPU that does a lot more. And we can do all the things that I just mentioned and the vast number of applications that are emerging in the cloud. And so our belief is this. Our belief is that, number one, a GPU has to be versatile to handle the vast array of big data and data-intensive applications that are happening in the cloud, because the cloud is a computer. It's not an appliance. It's not a toaster. It's not a lightbulb. It's not a microphone. The cloud has a large number of applications that are data-intensive. And second, we have to be world-class at deep learning, and our GPUs have evolved into something that can be absolutely world-class at TPU, but it has to do all of the things that a data center needs to do.
Jen-Hsun Huang - NVIDIA Corp.: Thanks. Cryptocurrency and blockchain is here to stay. The market need for it is going to grow, and over time it will become quite large. It is very clear that new currencies will come to market, and it's very clear that the GPU is just fantastic at cryptography. And as these new algorithms are being developed, the GPU is really quite ideal for it. And so this is a market that is not likely to go away anytime soon, and the only thing that we can probably expect is that there will be more currencies to come. It will come in a whole lot of different nations. It will emerge from time to time, and the GPU is really quite great for it. What we've done, our strategy is to stay very, very close to the market. We understand its dynamics really well. And we offer the coin miners a special coin-mining SKU. And this product configuration – this GPU configuration is optimized for mining. We stay very close to the market. We know its every single move and we know its dynamics. And then last thing that I can say is that the larger of a GPU company you are, the greater ability you could absorb the volatility. And so between the combination of the fact that we have GPUs at just about every single price point, we have such incredibly efficient designs that we're so close to the marketplace. And because we have such large volumes, we have the ability to rock and roll with this market as it goes. But this is an important market that likely will continue to grow over time.
Jen-Hsun Huang - NVIDIA Corp.: Sure, let's see. First of all, we actually gave a really great guidance last quarter, and we beat it by $250 million. And the $250 million you could see in our – we categorized under the OEM SKUs basically the cryptocurrency SKUs. And that, if you reverse-engineered it out, I think is approximately $150 million. And we serve the vast – I would say the large majority of the cryptocurrency demand out of that specialized products. There are still small miners that buy GeForces here and there, and that probably also increased the demand of GeForces. There were a lot of shortages all over the world. And as we go into this quarter, there's still cryptocurrency mining demand that we know is out there. And based on our analytics and understanding of the marketplace, there will be some amount of demand for the foreseeable future. But it's also the case that there were gamers whose needs and demands were not filled last quarter. The second quarter is an important part of the year for us. GeForce is in an incredibly great strategic position. After all of the numerous product launches that we've seen from other players, it's very, very clear that the GeForce product lineup is absolutely the best in the world. And the second half is going to see some very exciting titles. You've got Destiny 2. You have Call of Duty from Activision. You have Star Wars: Battlefront from EA. These are going be blockbusters, and we're expecting them to do incredibly well. We also know that a game that came out of nowhere – and this is one of the things that's really great about the video game market, you never know where the next amazing new title is going to come from. PLAYERUNKNOWN'S BATTLEGROUNDS, it's really essentially Survivor meets Hunger Games. How could that not be a fun game? So they've done incredibly well. And so I think the market dynamic is really vibrant for the second half of the year, and we have a really great position. With respect to our guidance, the way to think about our guidance, we gave a good guidance and we're comfortable with our guidance. And we know that the dynamics in our business, our data center position is quite exciting. We know that our gaming business is vibrant and our position is excellent. We saw growth across all of our product segments. And we'll just see how it turns out at the end of next quarter.
Jen-Hsun Huang - NVIDIA Corp.: First of all, it's very difficult to reverse-engineer from the first ramp of Volta any impact on gross margins, and the reason for that is because the first ramps tend to be more costly, and you're still trying to stabilize yield. There are a lot of complexities involved. But what I can tell you is that we shipped a lot of Voltas. We shipped a lot of Voltas, and Volta is fully ramped. Customers are clamoring for it. The leap generationally for deep learning is quite extraordinary. And so we're expecting Volta to be very, very successful.
Jen-Hsun Huang - NVIDIA Corp.: So the first way to think about our ASP is to think about the value proposition that our GPUs provide. Whenever you include a Volta in your data center, in your server that is doing data-intensive processing, the number of commodity servers that it replaces and the number of just NICs [Network Interface Cards] and cables that it replaces is pretty extraordinary. Every single Volta allows you to save several hundred thousand dollars. And so the price of Volta is driven by the fact that, of course, the manufacturing cost is quite extraordinary. These are expensive things to go and design. The manufacturing cost itself, you guys can estimate it, is probably in the several hundred dollars to close to $1,000. However, the software intensity of developing Volta, the architectural intensity of developing Volta, all of the software intensity associated with all the algorithms and optimizing all the algorithms of Volta is really where the value-add ultimately ends up. And so I guess the pricing – your question relates is pricing. We expect pricing to be quite favorable for Volta. And then your second question I think is related to acceleration. The data center growth opportunity for us is quite significant, as you know. There are several applications that demand GPUs today. Almost every single data center in the world today recognizes that GPU is the path forward for data-intensive processing. Every single OEM and every single cloud service provider now supports NVIDIA GPUs and offer video GPUs, and Volta is going be the engine that serves them. So I'm expecting a lot of good things from Volta.
Jen-Hsun Huang - NVIDIA Corp.: Sure, thanks a lot, Atif. The roadmap for auto looks like this. For this year and next, what you should see is development partnerships that we have with a growing number of car companies, and they're reflected in NRE projects, development systems, and purchasing of our AI supercomputers like DGX. And so for the next I would say this year and the vast majority of next year, that's what you should expect from the autonomous driving perspective. Starting next year, you're going to start to see robot taxis start to come to the road. We're working with a handful, maybe I guess about six or seven really exciting robot taxi projects around the world. And you could see them start to go into a prototype or beta testing starting now, and then next year you'll see a lot more of them. And starting 2019, you'll see them go into real commercial services. And so those are robot taxis, what some in the industry call Level 5s, basically driverless cars. And then the fully autonomous drivered cars, driven cars, branded cars will start hitting the road around 2020 and 2021. So the way to think about it is this year and next is really about development. Starting next year and the following year is robot taxis. And then 2021 to forward you're going to see a lot of Level 4s.
Jen-Hsun Huang - NVIDIA Corp.: Sure. Our Pro business, call it roughly nearly $1 billion. It grew 8% last year. It grew 8% the year before that, maybe a little bit less, and this year it grew about 10%, maybe a little faster. The way to think about that business is it's really a platform for design, digital design of all kinds. And it's designing movies, designing cars, designing products, people designing websites. Anybody who's doing digital design could really benefit from a Quadro platform. It's very software-intensive. It's certified with every major computer-aided design package. It's certified by large industrial companies all over the world. You could use Quadro and bring up a database 10 years from now and know that because of the nature of how we manage our software, the certification process we go through with each one of the major industry partners, we could pull up an entire design that was designed five years ago 10 years from now. And so if anything were to happen to a product or a plane or a ship or a building, the level of certainty in your data integrity is going be complete. And so the software intensity is high, and our platform is recognized all over the world as the industry standard. The growth opportunity for Quadro are several, and it's starting to kick in. And I'm rather optimistic about its future growth as well. One of them is photorealistic rendering. We now have the ability to use our artificial intelligence and ray tracing technology in combination, called OptiX 5.0, that we just announced at SIGGRAPH. That allows you to visualize photorealistic rendering practically interactively, and it's just an amazing thing to watch. Second, we now have a new system called an external GPU system. That's a partnership between the work that we did with Intel and all of our partners in the ecosystem by taking advantage of Thunderbolt 3 and the new external GPU-capable Windows system. You can now have an external system connect to Thunderbolt and basically our GPU is outside the laptop. And so for some 25 million – 20 million users of thin and light notebooks, you can now have the ability to have a GPU as well and get a boost in your productivity like you've never seen before. And so you can now have thin notebooks and still have the benefit of our GPUs. And so that's a new market for us. We're going to see virtual reality do quite well, especially in design. And we partnered with HP recently to do an industrial version of a backpack that allows designers to be able to freely roam within their design space and completely in virtual reality. So there's a variety of growth drivers in that business that I'm quite excited about.
Jen-Hsun Huang - NVIDIA Corp.: Sure, thanks a lot. So first of all, to answer that question, I would say there are three factors. The first factor is our strategic position. Our competitive lineup is probably the best it's ever been, better than last year even, which was incredibly strong, better than the year before that because it was incredibly strong. I think our strategic position and the value of our architecture is more powerful today than ever. And so I think number one is our strategic position. The second, if the demand were there in the second half with respect to – from a perspective of gaming demand and if there's any residual crypto demand, we will surely be able to serve it. And then lastly, the factors related to our guidance, our guidance is we're comfortable with our guidance. We're happy with our guidance, and we want to have an opportunity to come back and give you an update in Q3.
Jen-Hsun Huang - NVIDIA Corp.: The answer to your first question is yes. Volta was a giant leap. It's got 120 teraflops. Another way to think about that is eight of them in one node is essentially one petaflops, which puts it among the top 20 fastest supercomputers on the planet. And the entire world's top 500 supercomputers are only 700 petaflops. And with eight Voltas in one box, we're doing artificial intelligence that represents one of them. So Volta is just a gigantic leap for deep learning and it's such a gigantic leap for processing that – and we announced it at GTC, if you recall, which is practically right at the beginning of the quarter. And so the transition was not insignificant, and it was that the team just executed flawlessly. I'm so proud of the team. They executed the most complex processor that's ever been built. And working with our teams, working with our partners at TSMC and Samsung and all of our package partners still, and they just did a great job for us, and so the team did great. Now looking forward, there's a whole bunch of growth drivers for our data center business. Deep learning is – training is a growth driver. Cloud computing, high-performance computing is a growth driver, and we have new growth drivers with inferencing. And so I'm pretty excited about our prospects going into the age of – the generation of Volta. In terms of the guidance and what we expect, I think our dynamics are really positive. And so we've just got to – we're happy with the guidance, and let's give you an update at the end of the quarter.
Jen-Hsun Huang - NVIDIA Corp.: I think at the highest level, the way to think about that is data-intensive computing, whether it's deep learning or high-performance computing, the GPU is just phenomenal at it. NVIDIA's CUDA GPU was, after 12 years of driving this architecture and pioneering this computing approach, it's just a home run. And the value proposition and the money that it saves people, the amount of energy that it saves is quite extraordinary. One way to think about that is if you speed up an application by a factor of 10, you're basically saying that it takes 10 times fewer servers to do the same job, or you could do 10 times as much work in the same amount of servers. So the value proposition is really quite great. The applications that we serve is really diverse now. It used to be just high-performance computing and supercomputing. But the number of applications we serve in Internet service providers, manufacturing, healthcare, financial services, transportation, the number of data-intensive applications and industries that need them is really growing very fast. And so how fast does that – what does that imply in terms of long-term growth? It's hard to say. But first principles would suggest that every single data center in the world will be GPU-accelerated someday. And I've always believed that, and I believe that even more today. Because I believe that in the future, this new computing model that we all finally call AI is going be a highly data-intensive business model, and the GPU is the ideal computing model for that. So I'm not exactly sure if that completely answers your question, and partly because I'm not exactly sure. I just know that on first principles, the computing architecture is ideal. There's every evidence that every single data center and every single OEM and every single Internet service provider is jumping on this architecture and jumping on Volta. And I believe that AI is going be the future of computing. And so somewhere between those beliefs and executing the business is the truth.
Jen-Hsun Huang - NVIDIA Corp.: That's a good question, Hans, and it's a good observation. Because Purley, I didn't know if everybody understood that code name, but Purley is a new motherboard, a new platform for Intel servers, and the CPU is Skylake. It's an excellent server platform. And obviously, every OEM and every service provider was waiting for the launch of that, and it officially launched in the middle of this quarter. And so did it affect the rollout of new servers based on GPUs? It probably did, and surely it did. But now that it's ramped, it's a successful ramp. Every single cloud provider and every single OEM is now fully geared up to take that server to market, and they all have GPU options. Every single OEM in the world now and every cloud provider and every ODM now has NVIDIA GPU chassis and platforms, whether it's in one GPU in 1U to eight GPUs in a supercomputing configuration. And so the number of options of ways to enjoy NVIDIA GPUs is really quite countless now. Volta for gaming, we haven't announced anything. And all I can say is that our pipeline is filled with some exciting new toys for the gamers, and we have some really exciting new technology to offer them in the pipeline. But for the holiday season for the foreseeable future, I think Pascal is just unbeatable. It's just the best thing out there. And everybody who's looking forward to playing Call of Duty or Destiny 2, if they don't already have one, should run out and get themselves a Pascal.
Jen-Hsun Huang - NVIDIA Corp.: First of all, it's not really possible because our GPUs are all architecturally compatible, which at some level is one of our strengths. There are hundreds of millions of NVIDIA GPUs in the world, and they're all CUDA compatible, and they're all 100% CUDA compatible. And we're so rigorous and so disciplined about ensuring their compatibility that for developers it's really a wonderful platform. However, we're thoughtful about how we configure the GPUs so that they're best for the applications. Some applications would like to have the maximum amount of performance in a few nodes. Some would like to have the maximum amount of performance within 30 watts. Some would like to have the maximum amount of flexibility with all of the I/O and connectors and all the display connectors. Some people like to have multi-GPUs and that they have the ability to configure them together. And so every market has a slightly different need, and we have to understand the market needs and understand what it is that the customers are looking for, and configure something that is best for them.
Jen-Hsun Huang - NVIDIA Corp.: Let's see. A neural net in terms of complexity is approximately – not quite, but approximately doubling every year. And this is one of the exciting things about artificial intelligence. In no time in my history of looking at computers in the last 35 years have we ever seen a double exponential where the GPU computing model, our GPUs are essentially increasing in performance by approximately three times each year. In order to be 100 times in just four years, we have to increase overall system performance by a factor of three, by over a factor of three every year. And yet on the other hand, on top of it, the neural network architecture and the algorithms that are being developed are improving in accuracy by about twice each year. And so object recognition accuracy is improving by twice each year, or the error rate is decreasing by half each year. And speech recognition is improving by a factor of two each year. And so you've got these two exponentials that are happening, and it's pretty exciting. That's one of the reasons why AI is moving so fast.
Jen-Hsun Huang - NVIDIA Corp.: Our GPUs are useless without software, I'll start from the back and work forward. Our GPUs are useless without software, and the reason for that is because otherwise each one of the markets, whether it's playing games or professional visualization or high-performance computing, doing molecular dynamics computation or doing seismic processing, or perceiving the three-dimensional world around the car and reasoning about where it is and trying to figure out how to drive, all of that software is very, very different. What we do is there's a core in our company. The core architecture is a GPU core. However, the configuration of the products and the chips and the systems are very different from market to market. So somebody asked me earlier, the gentleman asked me about cryptocurrency. That configuration is very, very different than a gaming configuration, which is different than a high-performance computing configuration, and it's different from our inferencing configuration and it's different from our self-driving car configuration. And so the chips are designed to be different, even though they're architecturally identical. And then the systems are designed to be market-specific and application-specific. And the software on top of it is super, super application-specific. And that's one of the reasons why our company is increasingly differentiated from a components company and what we call a platform company. Each one of these platforms that we bring to market are very, very different, even though at its core, this data-intensive parallel computing architecture called CUDA is essential among all of them. We don't break out the automotive from the rest of the Tegra business. The Tegra business consists of basically three parts at the moment. One major component of it is the Nintendo Switch gaming console, and it's just doing incredibly well. I'm so happy for Nintendo because they're risk takers. They're innovators. They're not influenced by what other people do, and they're original thinkers. And I just love the way they invented the Switch and the way they've taken it to market. I'm so happy for them. And it's doing really well. The second major component is our self-driving car platforms, and a lot of it still is infotainment systems. Our infotainment system is going to evolve into an AI cockpit product line. We initially started with autonomous driving. But you probably heard me say at GTC that our future infotainment systems will basically turn your cockpit or turn your car into an AI. So your whole car will become an AI. It will talk to you. It will know where you are. It knows who's in the cabin. And if there are potential things to be concerned about around the car, it might even just tell you in natural language. And so the entire car will become an AI. We announced at CES a partnership with Daimler, and they talked about the work that we're doing together in the next-generation car how we're going bring AI to the car. And that's our first visible, highly visible project, and there are others that we're working on. And then the future projects, starting from end of next year with robot taxis, and starting with 2020 the autonomous cars, fully autonomous cars, you're going to see the rest of that come online, and that's a major component of Tegra. And then the last component, the third component, major component I would say is AI at the edge. That's the next major revolution. And we have a new product line that we announced about a year ago. It's called Jetson. Jetson is just an amazing little AI computer. And if you want to do deep learning at the edge, whether it's really, really clever cameras for smart and safe cities, to traffic lights that can now monitor traffic, Jetson AI at the edge is going be the next growth opportunity for us. And those three major segments make up essentially the Tegra business. We haven't split each one of them out separately, but one of these days we'll consider doing that.
Jen-Hsun Huang - NVIDIA Corp.: Ambrish (sic) [Gabriel], that's a good question. Partly I'm not in total control of the answer. But on first principles, let me maybe explain it this way. I believe that there are a few hundred million office workers and information workers whose PCs will be virtualized and just become an application like Netflix, and it will be virtualized. They'll be streamed from our cloud GPUs called GRID. I believe that every single company in the world, manufacturing, healthcare, finance will use computational approaches to analyzing their business. And some of them will use AI and some of them will use traditional first principle physics-based algorithms. And it's hard to say exactly what the split is going to be. My guess, however, is that AI will be the larger part of that, but you're going to see hybrid versions of it. Most computation – the reason why we're so bullish about CUDA and our GPU, which is able to do both general purpose computation as well as deep learning, is because most algorithms have the combination of both. Inside the card, we don't just use deep learning. We use CUDA and deep learning. We use CUDA for all kinds of algorithms, computer vision algorithms including deep learning. And we're seeing in quantum chemistry, in physics simulations like fluid dynamics, more and more of the algorithms are hybrids of deep learning and numerics. And so that segment of the marketplace is hard to predict. And then there's just the consumer Internet service providers and the billions and billions of queries that are going into the cloud. Some of them are text, some of them are speech, and increasingly some of them are video. The amount of traffic that's going to be inferenced using deep learning is going be quite explosive. It's hard to know exactly the pace of each one of these, but I think on first principles, we would all agree that these are large computation challenges, and that the previous model of using just microprocessors to do that computation is not efficient, and that the GPU with its parallel data processing capability and now our fourth-generation deep learning architecture, you essentially have a GPU that does a whole bunch more. And so I think the approach that we take has great promise, and we're just super-enthusiastic about it. But exactly how much it's going contribute in the near term in percentages is going be hard to guess.
Jen-Hsun Huang - NVIDIA Corp.: Okay, that was great. I appreciate all the questions. We had a great quarter. We're seeing exciting growth dynamics driving in each of our businesses. This is the era of artificial intelligence, and NVIDIA has dedicated ourselves to be its brain. Cloud and Internet service providers are going all in on AI and jumping onto our new Volta GPU. Enterprises and giant industries from transportation to healthcare to manufacturing to financial services have an awakened to the power of AI. And the growing pipeline of the NVIDIA DGX AI supercomputer is a great indicator. The next revolution of AI will be at the edge, and the most visible impactful evidence will be the autonomous vehicle. Our strategy is to build a ground-up deep learning platform for self-driving cars, and that has put us in pole position to lead the charge. And in gaming, which is actually the first consumer AI application, we have a great strategic position in this growing market. We have a once in a lifetime opportunity ahead. We can make an amazing impact on the future of the world. Thanks for joining us today, and we look forward to giving you another update next quarter.
