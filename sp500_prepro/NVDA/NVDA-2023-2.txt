Colette Kress: Well, let me start first there and see if I can assist in terms of how to think about after we get through our completion just now of Q2 and what we have provided here for guidance for Q3. Across those two quarters, the Q2 of ‘23, the Q3 of ‘23, we have likely undershipped gaming to our end demand significantly. We expect that sell-through or essentially our end demand for those combined two quarters of Q2 and Q3 to be approximately $5 billion. Now, on top of this, keep in mind that we do have gaming growth drivers to consider for the future. These can include our new gaming product introductions that are around the corner as well as new segments of the market that we plan to reach with our gaming technology to just name a couple. I’ll turn it over to Jensen to talk a little bit more about that. Now, regarding any further types of write-downs on this perspective, we did a thorough assessment with this quarter, not only just looking at what we needed for this quarter, but what we need for the long term. Keep in mind, our inventory provisions and write-downs that we took into account had to reflect some of the purchasing that we did a supply back more than a year ago when we were still in extreme supply shortages in almost all of our products. And so, this was an opportunity for us to resize given the macroeconomic conditions, what we needed in terms of supply. So, our expectations were higher, and we took this opportunity to write them down to what our current expectations are. I’ll turn it over to Jensen to see if he wants to add more.
Colette Kress: Great. Thanks for the question. And it’s kind of a little bit of an add-on to some of the statements that Jensen was discussing regarding our supply chain and what we’re seeing today. Our supply chain during the quarter really was quite difficult, was quite challenging to work through. Our platforms, including HDX, networking chips, cables, switches, were very important to the customers. It’s not just about us selling the GPUs. So even though customers orders components themselves, they’re looking from us what we may refer to as kits, kits that go with those GPUs for them to stand up their data centers. We also experienced supply disruptions internally with our logistics and our component availability. Some of our supply arrived very late in the quarter. We had very little time from a logistics and availability to get those things out. Customers were impacted as well by availability of key third-party other components that we weren’t offering, which were slowing down some of their deployments. So what we did in our Q2 orders that couldn’t be delivered in Q3, given that some of these supply constraints existed, and we had Q3 demand where we did have supply in Q2. So we worked with customers to optimize that supply and demand, and that’s what we’ve disclosed to you.
Colette Kress: Thanks for the question. So our inventory charges, as we commented, we’re taking a thorough look of not only this last quarter as well as the quarter that we’re guiding, but looking over the long term of what we need for demand and then what we had in terms of supply. Remember, we had purchased this very early on in the year as we needed to, to drive the commitment of the supply that we already have. And so what is happening here for the data center, we had great, high expectations. We still have very strong, solid growth projection for data center as well. We’re going to take this opportunity for some of the prior architecture pieces to write down those given what we see as just a change in terms of our expectations going forward. So you are correct. There are also pieces in there for gaming. We have written down some silicon and chips as the macroeconomic conditions and you get ready for our future product launches take into account, but there’s also components, services and capacity in some of the other drivers that are incorporated in those write-downs.
Colette Kress: Yes. Thanks for the question. And that’s a pretty good understanding of our guidance. And we do expect, yes, gaming to decrease, not in the dollar amount that it decreased between Q1 and Q2. So that may be of our 2 areas of the decline, our gaming and ProViz, that may be about 3/4 of it associated with that gaming. And then Professional Visualization would probably be about 1/4 of the 2 areas that will decline. Our Data Center yes, we do expect it to grow. It may grow about what we just saw between Q1 and Q2. We’ll continue to look at it. There may be some more opportunity there. And automotive, very similar to our thoughts at the very beginning of the quarter, we are expecting continued growth through each of the quarters of this fiscal year. We felt that Q2 was an inflection point. So we’ll continue to grow into Q3 and hopefully Q4 going forward. I’ll turn it over to Jensen to see his thoughts in terms of Hopper, what Hopper brings to us in Q4 and expectations.
Colette Kress: So within our Q2 results, we have been continuing to improve our supply for networking. We have a lot of important products that the CSP needs, many of our customers’ needs, and we have been working to really improve that supply. And we were able to set very strong growth in terms of networking, both sequentially and year-over-year. And as we move into the next quarter, we’re going to have to see which is going to be growth larger. We’re just going to have to take a lot once we finish that quarter. But our supply for compute is here. But as we’ve discussed, sometimes it’s important that they have many of our other components that we provide in networking at the same time that we are providing the GPUs. So sometimes those are very important for us to deliver together. So we always have to keep that in mind. So it’s not always supply constrained, but there are certain parts of it that are.
Colette Kress: Let me start and see if Jensen wants to add on to it. Our execution has absolutely been phenomenal. When you think about the challenges of we’re almost putting together a full data center for our customers and getting it shipped out. So we’re no different in the same way that the CSPs are challenging. We’re setting up their data centers as we’re such an integral part of that. And so networking has been short of supply. These are the same supply issues that some of our CSPs are having. So our supply arrived a little bit late in the quarter for some of our key products that we needed to get out. And putting that together caused some disruption in our logistics and distribution. We were pleased in terms of reaching the leverage of networking that we did, but we did have some challenges this quarter.
Colette Kress: Yes, Stacy. Regarding our inventory charges that we had, when you think about what we have in supply, whether it be chips, components, whether it be memory. Remember, a lot of these things can be used interchangeably across the 2. Additionally, the value of our inventory for data center is much different than the value of what we have for gaming from an overall cost perspective. So we’re creating capacity opportunity, putting together all of those systems in terms of data center. It is prior architectures. Absolutely, this is not a question regarding anything of our future products coming to market. Nothing on the inventory provision has to do with that. So we took this as looking at the macroeconomic conditions, as we’ve discussed. Our expectations, our plans were higher. They’re still quite solid that we see in demand both for gaming as well as solid for data center, and that will continue. But we did have to just take a rightsizing of that note.
Colette Kress: Yes. Thanks for the question. So our gross margins outside of the inventory charges in Q2 as well as going into Q3 is really about our sales mix that we have and probably also to understand that our sales mix in the next quarter for GPUs is not in the high end. And so that has impacted our gross margin as we move into Q3. You are correct. We do expect that data center will assist in our gross margins but we also have growth plans in auto. Auto is below our company average, and so that will tend to offset some of those upper bound things that we will see in terms of data center. From time to time, there’s always a small amount of scraps that we will have in our gross margin estimates. So nothing material is planned. But there is small scraps that may occur from quarter-to-quarter that are included in our gross margins.
Colette Kress: Okay. No. No, there is nothing in our Q3 regarding those inventory provisions that we took in terms of earning that back, in terms of our Q3. Regarding our split between our hyperscalers and data centers and what we refer to as our vertical industries. They always tend to be about the same, 50% for one, 50% for the others. They’re still in about that range. We had discussed that our China hyperscales did not drive growth in terms of sequentially here. And so that did influence in terms of the hyperscales, but still we are approximately in that 50%, 50%.
Jensen Huang: Yes. Thanks, Colette. C.J., our sell-through is off the highs in the beginning of the year, but it’s still very solid. In fact, sell-through is -- has increased 70% since pre-COVID, pre-pandemic. And so, it’s very clear that gaming is -- the fundamentals of gaming are strong, and this medium is really doing well. Not to mention the gaming platforms are being used -- our gaming PCs are being used for influencers, people sharing content, creating content, V bloggers, VTuber, there’s all kinds of new ways of engaging and spending time with video games. Our strategy is to reduce the sell-in -- reduce the sell-in this quarter, next quarter to let channel inventory correct. Obviously, we’re off the highs, and the macro condition turned sharply worse. And so, our first strategy is to reduce sell-in in the next couple of quarters to correct channel inventory. We’ve also instituted programs to price position our current products to prepare for next-generation products. Ampere is the most popular GPU we’ve ever created. It is in the top 15 most popular gaming GPUs on Steam. And it remains the best GPUs in the world, and it will be very successful for some time. However, we do have exciting new next-generation coming and it’s going to be layered on top of that. And so, we’ve taken -- we’ve done two things. We’ve reduced sell-in to let channel inventory correct and we’ve implemented programs with our partners to price position the products in the channel in preparation for our next generation. All of this we anticipate were working towards a path to being in a good shape going into next year. Okay? So, that’s what our game plan is.
Jensen Huang: Thanks, Vivek. The sell-through -- the sell-through, as I mentioned earlier, of GeForce is solid. The end market gaming demand is solid. It’s off the highs, which was really high recently in the beginning of the year. And so, we have -- and because we were building for such a vibrant market, we found ourselves with excess inventory. And so, our strategy is to sell well below -- sell in well below the current sell-through levels in the marketplace to give the channel an opportunity to correct. We’ll do that for a couple of quarters or so. We believe that by the end of the year, we’ll be in a good shape going into next year. And so, I hope that answers your question. But, the important thing is our sell-in rate is far below what is happening in the market for sell-throughs. The sell-through is solid, has increased 70% since pre-COVID. And so, the gaming market is really quite vibrant. On the second question, on data center end markets, we hear fairly broadly that GPU supply is in shortage in the cloud. We hear quite broadly that demand for GPU rentals far exceeds current supply. And it’s fairly sensible to us, partly because the number of use cases for GPUs in the cloud has grown quite a bit. If you look at one particular segment in just managing -- collecting data and managing the data of the AV fleet and using that data to train AI models, using that data to reconstruct HD maps, the usage of GPUs in the cloud for just that one application has grown a lot. And furthermore, there’s the deep learning-based recommender systems has demonstrated such significant effectiveness. And it helps internet service providers to enhance engagement, enhance click-through rate. And so that -- so this particular form of recommender systems is going to really drive a fair amount of data processing and machine learning in the cloud. And then, of course, over the last several years, a very important model has emerged called transformers. You and I’ve spoken about this model several times in the past. And it’s been found that this transformer model, this large language -- this language model, which when scaled up in size, exhibits really spectacular and effective capabilities for -- to be used to learn skills with either few shots or almost no shot, meaning it could learn skills, it could perform skills that it has never learned because the knowledge was somehow encoded from the large amount of data that it had learned from. And so, this large language model area of innovation is used in, of course, conversational chat, Q&A summarization, text generation, image generation. But very importantly, it’s being used in life sciences for understanding chemistry. We’ve done some very important work in this area ourselves called MegaMolBART, understanding proteins, understanding DNA to learn the language of these large -- very, very large, spatially as well as temporally or sequentially types of data. And so, the impact of this area is really quite worth staying close to. It’s called large language models. I think Stanford did a paper that called it the Foundation models that could be used for training all kinds of other types of AIs. And so, we’re seeing a great deal of demand for GPUs in the cloud. We were challenged this quarter with a fair amount of supply chain challenges because as you know, we don’t just sell the GPU chip, but these systems are really complex with a large number of chips in the system components that we offer like HGX. And so kitting -- all of the components that have to come together for us to be able to deliver the final component. And then furthermore, these data centers sit idle until the last piece comes together. And the last piece includes very complicated switches and very complicated NICs and networkings and cables. And so these -- building these high-performance computing data centers at very large scale for the world’s cloud is not particularly easy. And so the supply chain challenges have been somewhat disruptive. But the demand is there. And on top of that, we’re ramping into Hopper, which is really a fantastic generation.
Jensen Huang: Let me answer the questions about the North American and the China hyperscalers. The Chinese hyperscalers and the Chinese Internet companies really, really slowed down infrastructure investment this year, particularly starting in -- they’ve been rather slow in building out and really accelerate -- well really slowed down in Q2. This slowdown can’t last forever. And the number of new technologies in software, the number of people who are using clouds and the number of cloud services is continuing to grow. And so I fully expect investment to return. They’re a very important market for us, a very large market for us. And the fact that North American hyperscalers doubled year-over-year our revenues at North American hyperscalers, and that was offset by declines in China said something about the slowdown in China. And so I don’t think that’s going to last forever. I think it’s going to return. With respect to Hopper, we’re in full production now. And we’re racing to get Hopper 2, all of the CSPs are dying to get them. And it goes with our HGX, which is multiple Hoppers on a system tray, it’s really a supercomputer in a motherboard, if you will. And it goes along with it networking gear and switch gear. And so there’s the enormous amounts of resources apply from all of the CSPs around the world and ourselves to get Hopper. We expect to ship substantial Hoppers in Q4.
Jensen Huang: Our Hopper supports previous generation CPUs. But I guess, next-generation GPUs, CPUs, Sapphire Rapids and Genoa after that as well as Graviton. And so -- so we certify and test across all of the CPUs because the cloud service providers demand it. And they intend to deploy NVIDIA accelerators, NVIDIA Hoppers across a large number of CPUs. There is no question that the delay is disruptive and a lot of engineers have to scramble. It would have been a lot easier if next-generation CPUs were to have executed more perfectly. However, Hopper goes into an environment with CSPs where they connect our PCI Express connectors to old generation, current generation CPUs as well. And so nobody likes the delay. The next-generation CPUs will trigger a refresh of infrastructure and new servers. And so I’m super excited about them. However, we’re going to be able to go to market plentifying with Hopper supporting existing infrastructure.
Jensen Huang: The first thing I’d say, Aaron, is that we are selling in or we’re selling far below the market demand, far -- excuse me, far below the market sell-through. And the reason for that is to allow the inventory the channel inventory, the OEM inventories to correct. And this allows us to prepare for our next generation. And our next generation has Hopper for compute, but we also have the next generation for computer graphics that will be coming to market. Hopper is a giant new generation because it is designed to perform this new type of AI model called Transformers. It has an engine inside it called Transformer engine with numerical formats and pipelines that allows us to do a spectacular job on Transformer-type of models, which includes large language models, but it also includes computer vision models that are now able to be processed with this new type of AI model called Transformers. And so I fully expect Hopper 2 to be the next springboard for future growth. And -- and the importance of this new model, Transformer, can’t possibly be understated and can’t be overstated. This is the impact of this model across robotics, computer vision, languages, biology, chemistry, drug design is just really quite spectacular. And I’m sure that you’ve been hearing about this new breakthrough in AI, and Hopper was designed for this.
Jensen Huang: Hopper was designed for transformers. The new transformers was going to be important. Nobody could have predicted the profound importance of large language models. Large language models, excitement, innovation, ideas, companies, start-ups, industries, all exceeding everyone’s expectations. I don’t think anybody could have predicted the impact of Transformers as it scaled up to these giant sizes. There’s a fair amount of literature now written about language models that were smallish in the old days, in the beginning several years ago, 3 years ago. And the ones that are in the hundreds of billions and moving towards probably several trillion parameters, the effectiveness of the AI is really quite spectacular. And to have AI that was never trained on a particular skill and yet within 1 shot or 1 shot of trying or even no shots, are able to perform that skill is beyond anybody’s expectations, I would think. And so I think the -- the success of Hopper is -- reflects the amount of work and pent-up demand for large training systems that Hopper is going to go into. If that’s an indicator, I think Hopper is going to be a spectacular success.
Jensen Huang: Whether the broader enterprise market is -- the verticals are going to be affected by that? I would say, first of all, we don’t know. Second of all, unlike like our Workstation business, our ProViz business, there’s no installed base. Most of the ProViz sales tend to be tend to be upgrades or replacements from something that has -- our installed base of 3 or 4 or 5 years that people -- whatever upgrade cycle they happen to have. And so in the case of ProViz, the companies that are buying are ProViz, our ProViz systems likely already have systems that they’ve been using. And so if they were to tighten up ProViz for whatever reason, the people could continue to use what they have. In the case of our AI business, there’s no real installed base. These are all brand-new things that people are growing into. And the productivity benefits or the cost savings benefits of using autonomous systems is fairly profound. And it’s not so much that the demand isn’t out there. Everybody would like to be more productive. Everybody would like to save more money. Everybody would like to move faster. It’s just that AI understanding and AI’s use is still spreading. And so we’re delighted by the rate of growth and the rate of adoption of enterprise. My sense is that our AI business and our Viz business have very different characteristics for that reason. But what Colette said earlier is about our ProViz businesses last quarter is absolutely true, which is OEMs realizing that the end market is slowing and taking the opportunity to correct their inventory.
Jensen Huang: I would say that without crypto dynamic, the mix would go down. However, the overall trend long term, the ASP is drifting up. And the way to think about that is a game console, when -- my first game console was $99. Lately, game consoles are selling for about $599. And the reason for that is because it’s more useful than ever. You use your gaming console for your greatest form of entertainment, and you use it for a very, very long time. And GeForce essentially is a game console inside your PC. And we’ve always believed that the ASP of GeForce should drift towards the average selling price of a game console. And so it should be something along the lines of $500 or so roughly at this time. We also have GeForce in the cloud. And because GeForce in the cloud is hosting many gamers simultaneously, it tends to want to be a much more powerful GeForce. And so our cloud gaming GeForce tends to be -- our cloud gaming graphics tends to be a much higher end. And so -- and then, of course, there’s the design aspect of it. Most designers and most creators are able to use GeForce these days. And they use their PC to create content, and much of that content goes into video games and/or they’re using video games to create their artistic content. And so the GeForce is not just for gaming for them. The GeForce is essentially their creative work station as well. And so there are several dynamics that are causing the ASP of GeForce to go up, and we’ve been seeing this trend for several years now.
Jensen Huang: Thanks, everyone. We’re navigating our supply chain transitions in a challenging macro environment. In Gaming, our partners and ecosystem are responding to a sudden slowdown in consumer demand and correcting channel inventory. Still, the fundamentals of gaming are strong. We’ll get through this over the next few months and go into next year with our new architecture. I look forward to telling you more about it at GTC next month. In Data Center, AI where computers are helping us write software that was impossible before is driving a computing revolution and transforming every industry. NVIDIA’s leadership in full stack data center scale, accelerated computing has made us the ideal partner for companies racing to leverage the power of AI. Even with the current macroeconomic headwinds, demand for our data center products have never been stronger. The next wave of computing is coming. With AI and 3D graphics advances, developers will extend the Internet with virtual world overlays that connect to the physical world. This next evolution of the Internet is called metaverse. We created Omniverse to connect the digital and physical world and be an open platform for creating and operating metaverse applications. The immediate applications for Omniverse span product design, manufacturing and operations. Omniverse is off to a great start. Our automotive revenue is inflecting, and we expect it to be our next $1 billion business. Autonomous driving is one of the biggest challenges AI can solve, and computing opportunity for us spans the data center to the car. Autonomous driving will transform the auto industry into a tech industry. Automotive is one of the first to transform into a software-defined tech industry that all industries will be. We’re building NVIDIA AI and NVIDIA Omniverse to be the engines for the world’s enterprise to become software-defined, AI-powered technology companies. I look forward to next month’s GTC conference, where we will share new advances of RTX reinventing 3D graphics and gaming. AI’s continuing breakthroughs and building the metaverse, the next evolution of the internet. So join us. We look forward to updating you on our progress next quarter. Thank you.
