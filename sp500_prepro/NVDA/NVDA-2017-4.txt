Jen-Hsun Huang - NVIDIA Corp.: Yeah, C.J. first of all, thanks a lot. Well, the single biggest mover would have to be Datacenter. I mean, when you look back on last year and we look forward, there's a lot of reasons why Datacenter business overall grew 3x, grew by a factor of three. And so I would expect that to happen, to continue. There's several elements of our Datacenter business. There's the high performance computing part. There's the AI part. There's GRID, which is graphics virtualization. There's cloud computing, which is providing our GPU platform up in the cloud for startups and enterprises and all kinds of external customers to be able to access in the cloud, as well as a brand new AI supercomputing appliance that we created last year for anybody who would like to engage deep learning and AI, but don't have the skills or don't have the resources or don't have the desire to build their own high performance computing cluster. And so we integrated all of that with all of the complicated software stacks into an appliance that we maintain over the cloud. We call that DGX-1. And so these pieces, AI, high performance computing, cloud computing, GRID and DGX all in contribution, contributed to our growth in Datacenter quite substantially. And so my sense is that, that as we look forward to next year, we're going to continue to see that major trend. Of course, gaming was a very large and important factor. And my expectation is that gaming is going to continue to do that. And then longer-term, longer-term our position in self-driving cars, I think, is becoming more and more clear to people over time. And I expect that self-driving cars will be available on the road starting this year with early movers, and no later than 2020 for Level 4 by the majors, and you might even see some of them pull into 2019. And so those are some of the things that we're looking forward to.
Jen-Hsun Huang - NVIDIA Corp.: Well, let's say we typically assume that we have an installed base of a couple of 100 million GeForce gamers, and we've upgraded about two quarters of them, as in two operating quarters out of four years. It takes about three to four years to upgrade the entire installed base. And we started ramping Pascal, as you know, a few quarters ago. And our data would suggest that the upgrade cycle is going well, and we have plenty to go.
Jen-Hsun Huang - NVIDIA Corp.: Well, on hyperscale, you're absolutely right, that there's internal, what we call, internal use for deep learning, and then there's the hosting GPU in the cloud for external high-performance computing use, which includes deep learning. Inside the hyperscalers, the early adopters are moving obviously very, very fast. But everybody has to follow. Everybody has to follow. Deep learning has proven to be too effective, and you guys, everybody knows now that every hyperscaler in the world is investing very heavily in deep learning. And so my expectation is that, over the next coming years, deep learning and AI will become the essential tool by which they do their computing. Now, when they host it in the cloud, people out in the cloud use it for a variety of applications, and one of the reasons why the NVIDIA GPU is such a great platform is because of its broad utility. We've been working on GPU computing now for coming up on 12 years, and industry-after-industry, our GPU computing architecture has been embraced for high-performance computing, for data processing, for deep learning and such. And so when somebody hosts it up in the cloud, for example, Amazon putting our GPUs up in the cloud, that instance has the ability to do molecular dynamics, to deep learning training, to deep learning inferencing. Companies could use it for offloading their computation to start-ups being able to build their company and build their application, and then host it for hundreds of millions of people to use. And so I think the hyperscalers are going to continue to adopt GPU both for internal consumption, and cloud hosting for some time to come. And we're just in the beginning of that cycle, and that's one of the reasons why we have quite a fair amount of enthusiasm around the growth here. You mentioned Enterprise, and enterprise, it has all woken to the power of AI, and everybody understands that they have a treasure trove of data that they would like to find a way to discover insight from. In the case of real applications that we're engaging now, you could just imagine that in the transportation industry, car companies creating self-driving cars, one car company after another needs to take all of their row data and start to train their neural networks for their future self-driving cars. And so they use our DGX or Tesla GPUs to train the networks, which is then used to run their cars running on DRIVE PX. So that's one application example. Another application example, which is quite significant, is going to be the future of processing all of the HD maps in the world. You guys might have seen that, we announced that GTC, this API SDK called MapWorks. MapWorks takes video information, video information that is recorded from a car, and reconstructs the three-dimensional terrain information from that live video. And so it has to do computer vision, 3D reconstruction. It has to determine and detect where the lanes are, the signs are, the lights are, and even some interesting 3D features, maybe buildings and curbs and such. And it will do that automatically. And we need to process that for the world, for the planet. And you can just imagine how much video is being recorded today, and how much data is being generated, and how much inferencing, computer vision and 3D reconstruction that has to be done, and our GPUs are really quite perfect for it. And so MapWorks runs on top of our GPUs, and we're working with just about every mapping company in the world today to adopt MapWorks, and to do HD processing for their maps. So that's another example. Medical imaging companies all over the world have recognized the importance of deep learning, and their ability to detect cancer and retinopathy, and the list of examples goes on and on. And so all the different modalities have now recognized the importance of deep learning, and you're going to start to see one medical imaging company after another. The list of examples just keep on going. I mean, the fact of the matter is, at this point deep learning and AI has really become how future software development is going to be done for a large number of industries. And that's the enthusiasm that we're seeing around the world.
Jen-Hsun Huang - NVIDIA Corp.: The first year of VR has sold several hundred thousand units, and many hundreds of thousands of units. And our VR works, SDK, which allows us to process graphics in very low latency, dealing with all of the computer vision processing, whether it's lens warping and such, it has delivered really excellent results. The early VR is really targeted at early adopters. And I think the focus of ensuring an excellent experience that surprises people, that delight people, by Oculus and by Valve and by Epic and by Vive, by ourselves, by the industry, has really been a good focus. And I think that we've delivered on the promise of a great experience. The thing that we have to do now is that we have to make the headsets easier-to-use, with fewer cables. We have to make it lighter, we have to make it cheaper. And so those are all things that the industry is working on, and as the applications continue to come online, you're going to see that they're going to meet themselves and find success. I think the experience is very, very clear that VR is exciting. However, remember that we are also in the VR â€“ we also brought VR to computer-aided design and to professional applications. In this particular area, the cost is just simply not an issue. And in fact, many of the applications previously were power walls or caves, VR caves that cost hundreds of thousands of dollars. And now you could put that same experience, if not even better, on the desk of designers and creators. And so I think that you're going to find that creative use and professional use of VR is going to grow quite rapidly. And just recently, we announced a brand new Quadro 5000, P5000 with VR, the world's first VR notebook that went to market with HP and Dell. And they're doing terrifically. And so I would think about VR in the context of both professional applications as well as consumer applications, but I think the first year was absolutely a great success.
Jen-Hsun Huang - NVIDIA Corp.: Well, the global PC gaming market is still vibrant and growing. And the number of eSports gamers around the world is growing. You guys know that Overwatch is a home run. Activision Blizzard's Overwatch is raging all over Asia and eSports fans all over the world are picking it up, and it's graphically very intensive. Without a 1050 class and above, it's simply a non-starter and to really enjoy it, you need at least a 1060. And so this last quarter we launched a 1050 and a 1050 Ti all over the world, and we're seeing terrific success out of that. And my expectation going into next year is that Overwatch is going to continue to spread all over the world. It's really basically just started. It started in the West and it's now moving into the East where the largest eSports markets are. And so Overwatch is going to be a huge success. League of Legends is going to continue to be a huge success. And my expectation is that the eSports along with AAA titles that are coming out this year is going to keep PC gaming continue to grow. And so I quite frankly thought Q4 was pretty terrific, and we had a record quarter. We had a record year, and I don't remember the last time that a large business the size of ours, and surely the size of a Datacenter business, grew by a factor of three. And so I think we're in a great position going into next year.
Jen-Hsun Huang - NVIDIA Corp.: Yes. First of all thanks, thanks for the question. The way to think about that is deep learning is a breakthrough technique in the category of machine learning, and machine learning is an essential tool to enable AI, to achieve AI. If a computer can't learn, and if it can't learn continuously and adapt with the environment, there's no way to ever achieve artificial intelligence. Learning, as you know, is a foundational part of intelligence, and deep learning is a breakthrough technique where the software can write software by itself by learning from a large quantity of data. Prior to deep learning, other techniques like expert systems and rule-based systems and hand-engineered features, where engineers would write algorithms to figure out how to detect a cat, and then they would figure out how to write another algorithm to detect a car. You could imagine how difficult that is and how imperfect that is. It basically kind of works, but it doesn't work good enough, well enough to be useful. And then deep learning came along. The reason why deep learning took a long time to come along is because its singular handicap is that it requires an enormous amount of data to train the network, and it requires an enormous amount of computation. And that's why a lot of people credit the work that we've done with our programmable GPUs and our GPU computing platform and the early collaboration with deep learning. AI researchers as the big bang, if you will, the catalyst that made modern AI possible. We made it possible to crunch through an enormous amount of data to train these very deep neural networks. Now, the reason why deep learning has just swept the world, it started with a convolution of neural networks, but reinforcement networks and time sequence networks and all kinds of interesting adversarial networks. And the list of types of networks, I mean, there are 100 networks being created a week, and papers are coming out of everywhere. The reason why is because deep learning has proven to be quite robust. It is incredibly useful, and this tool has at the moment found no boundaries of problems that it's figured out how to solve. And I think that the traditional methods of machine learning are still going to be useful if the absolute precision of the prediction or classification is not necessarily super important. For example, if you wanted to understand the sentiment of consumers on a particular new product that you sent, whether the sentiment is exactly right, so long as you understand the basic trend, and you largely understand the sentiment, I think people would consider that information to be useful. However, if you're using machine learning for cancer detection, obviously we need to have a little precision that is quite high. And so whether it's in health care or financial services or high-performance computing and in some areas where, for example, ad supported Internet search, small differences in accuracy could make a very large difference in the financial results for the advertiser and for the people hosting the service. And so in all these cases, deep learning has found a great utility, and that's one of the reasons why we're seeing so much growth. And obviously for self-driving cars, being kind of right is not a good idea, and we like to be exactly right.
Jen-Hsun Huang - NVIDIA Corp.: Sure. First of all, you know that we are a full stack platform. The way we think about all of our platforms is from the application all the way back to the fundamental architecture in a semiconductor device. And so in the case of DRIVE PX, we created the architecture, optimized for neural net, for sensor fusion, for high-speed processing. The semiconductor design, in the case of DRIVE PX 2 called Tegra Parker, the system software for high-speed sensor fusion and moving data all the way around the car, the better you do that, the lower cost the system will be. The neural networks on top of that, that sits on top of our deep learning SDK, called cuDNN and TensorRT, basically frameworks of AI, and then on top of that, the actual algorithms for figuring out how to use that information from perception to localization to action planning. And then on top of that, we have an API and an SDK that is integrated into map makers, and we integrate into every single map, HD map service in the world, from HERE to TomTom to ZENRIN in Japan, to Baidu in China. So this entire stack is a ton of software. But your question specifically has to do with the perception layer. And that perception layer quite frankly is just a small part of the self-driving car problem. And the reason for that is because in the final analysis, you want to detect lanes. You've got video coming in, you want to detect lanes, you have video coming in, you want to detect the car in front of you. And all we have to do, it's not trivial, but it's also not monumental, we have to detect and sense the lanes and the cars and we train our networks to do so. And as you know very well now, that deep neural net has the ability to detect objects far better than any human engineer computer vision algorithms prior to deep learning. And that's one of the reasons why Tesla and others have jumped on top of the deep learning approach and abandoned traditional hand featured computer vision approaches. And so anyways, the answer to your question is that by working on self-driving cars, and we realized that this is a much more than computer vision, that the self-driving car platform is a stack of software and algorithms that's quite complex, and now we've had a lot of experience doing so. And then recently at CES, we announced partnerships with Audi, which we announced that we will have Level 4 self-driving cars on the road by 2020. We announced a partnership with Daimler, we announced a partnership with ZF and Bosch, two of the world's top Tier 1 suppliers. We also announced partnerships with all of the mapping companies. And so if you put all that stuff together, we have the processor, we have the tier one partnerships for the integration of the systems, we have all the software on top of it, the deep learning networks, the car partnerships of course, and integrated into maps around the world. And all that entire stack when you put them all together should allow us to have self-driving cars on the road.
Jen-Hsun Huang - NVIDIA Corp.: Yes. The inference market is going to be very large. And as you know very well, in the future almost every computing device will have inferencing on it. A thermostat will have inferencing on it, a bicycle lock will have inferencing on it, cameras will have inferencing on it, and self-driving cars would have a large amount of inferencing on it. Robots, vacuum cleaners, you name it, smart microphones, smart speakers, all the way into the data center. And so I believe that long-term there will be a trillion devices that has inferencing connected to edge computing devices near them, connected to cloud computing devices, cloud computing servers. So that's basically the architecture. And so the largest inferencing platform will likely be arm devices. I think that that goes without saying. Arm will likely be running inferencing networks, 1-bit XNOR, 8-bit, and even some floating-point. It just depends on what level of accuracy do you want to achieve, what level of perception do you want to achieve, and how fast do you want to perceive it? And so the inferencing market is going to be quite large. We're going to focus in markets where the inferencing precision, the inferencing, the perception scenario and the performance by which you have to do is mission-critical. And of course, self-driving cars is a perfect example of that. Robots, manufacturing robots, will be another example of that. In the future you're going to see in our GTC, if you have a chance to see that, we're working with AI City partners all over the world for end-to-end video analytics, and that requires very high throughput, a lot of computation. And so the examples go on and on, all the way back into the data center. In the data center, there are several areas where inferencing is quite vital. I mentioned one number earlier, just mapping the earth, mapping the earth at the street level, mapping the earth in HD, in three-dimensional level for self-driving cars. Now, that process is going to require, well, just a pile of GPUs running continuously as we continuously update the information that needs to be mapped. There's inferencing, which is called offline inferencing where you have to retrain a network after you deployed it, and you would likely retrain and re-categorize, reclassify the data using the same servers that you used for training. And so even the training servers will be used for inferencing. And then lastly, all of the nodes in cloud will be inferencing nodes in the future. I've said before that I believe that every single node in the cloud data center will have inferencing capability and accelerated inferencing capability in the future. I continue to believe that and these are all opportunities for us.
Jen-Hsun Huang - NVIDIA Corp.: It would have to be Tesla processors using in the cloud. There are several SKUs of Tesla processors. There's the Tesla processors used for high-performance computing, and it has FP64, FP32, ECC, it's designed, and has CUDA of course, and it has been optimized for molecular dynamics, astrophysics, quantum chemistry, fluid dynamics, the list goes on and on. The vast majority of the world's high-performance supercomputing applications, imaging applications, 3D reconstruction application, it has been ported onto our GPUs over the course of the last decade and some, and that's a very large part of our Tesla business. Then of course, we introduced on top of the architecture our deep learning stack. Our deep learning stack starts with cuDNN, the numerics kernels, a lot of algorithms inside them to be optimized for numerical processing of all kinds of different precisions. It's integrated into frameworks of different kinds. There's so many different frameworks, from TensorRT to Caffe to Torch to Theano to MXnet to CNTK, the work that we did with Microsoft, which is really excellent, scaling it up from one GPU to many GPUs across multiple racks, and that's our deep learning stack, and that's also very important. And then the third is GRID. GRID is a completely different stack. It's the world's first graphics virtualization stack, fully integrated into Citrix, integrated into VMware. Every single workstation and PC application has been verified, tested and has the ability to be streamed from a datacenter. And then last year, I think we announced it in â€“ we started shipping it in August, our DGX-1, the world's first AI supercomputer appliance, which integrates a whole bunch more software of all different types, and has the ability to â€“ we introduced our first NVIDIA docker. It containerizes applications. It makes it possible for you to have a whole bunch of users use one DGX. They could all be running different frameworks because most environments are heterogeneous. And so that's DGX-1. And it's got an exciting pipeline ahead of it, and it's really designed for companies and workgroups who don't want to build their own supercomputer like the hyperscalers, and aren't quite ready to move into the cloud because they have too much data to move to the cloud. And so everybody basically can easily buy a DGX-1. It's fully integrated, fully supported, and get to work on deep learning right away. And so each one of these are all part of our Datacenter business. But the largest, because it's been around the longest since our Tesla business, but they're all growing, every single one of them.
Jen-Hsun Huang - NVIDIA Corp.: We currently have DRIVE PX. DRIVE PX today is a one-chip solution for Level 3. And with two chips, two processors, you can achieve Level 4. And with many processors, you could achieve Level 5 today. And some people are using many processors to develop their Level 5, and some people are using a couple of processors to develop their Level 4. Our next generation, so that's all based on the Pascal generation. That's all based on the Pascal generation. Our next generation, the processor is called Xavier. We announced that recently. Xavier basically takes four processors and shrink it into one. And so we'll be able to achieve Level 4 with one processor. That's the easiest way to think about it. So we'll achieve Level 3 with one processor today. Next year, we'll achieve Level 4 with one processor, and with several processors, you could achieve Level 5. But I think that the number of processors is really interesting because we need to do the processing of sensor fusion, and we got to do perception. We have to do localization. We have to do driving. There's a lot of functional safety aspects to it, failover functionality. There are all kinds of black box recorders, all kinds of different functionality that goes into the processor. And I think it's really quite interesting. But in the final analysis, what's really, really hard, and this is one of the reasons why our positioning in the autonomous driving market is becoming more and more clear, is that in the final analysis, there's really a software problem. And it's an end-to-end software problem. It goes all the way from processing, in the perception processing in the car to AI processing to helping you drive, connected to HD clouds for HD map processing all over the world. And so this end-to-end stack of software is really quite a large undertaking. I don't know where anybody else is currently doing that with the exception of one or two companies. And so I think that that's really where the great complexity is. We have the ability to see and optimize across the entire range. Now, the other thing that we announced at CES that's worth mentioning is that we believe in a future, Level 4 means that you will have autopilot capability, hands-free autopilot capability in many scenarios. However, it's unlikely to ensure and to guarantee that in every scenario that you can achieve Level 4. It's just not practical for some time. However, during those circumstances, we believe that the car should still have an AI, that the car should be monitoring what's happening outside and it should be monitoring the driver. And when it's not driving for you, it's looking out for you. And we call that the AI co-pilot. Whereas AI autopilot achieves Level 4 driving, AI co-pilot looks out for you in the event that it doesn't have the confidence to drive on your behalf. And so I believe that that's a really big breakthrough, and we're just seeing incredible excitement about it around the industry because I think it just makes a lot of sense. And the combination of the two systems allows us to achieve, build a better car.
Jen-Hsun Huang - NVIDIA Corp.: Yeah, I appreciate that. I think, first of all, the PC gaming market is growing because of a dynamic that nobody ever expected, a dynamic that nobody ever expected 20 years ago. And that's basically how video games went from being a game to becoming a sport. And not only is it a sport, it's a social sport. And in order to play some of these modern eSports games, it's a five-on-five. and so you kind of need four other friends. And so as a result, in order to enjoy, to be part of this phenomenon that's sweeping the world, that it's rather sticky. And that's one of the reasons why Activision Blizzard is doing so well, that's one of the reasons why Tencent is doing so well. These two companies have benefited tremendously from the eSport dynamic, and we're seeing it all over the world. And although it's free to play for some people, of course, you need to have a reasonably good computer to run it. And that's one of the reasons why you need GeForce in your PC so that you can enjoy these sports. When it's also a sport, nobody likes to lose, and surely nobody likes to blame their equipment when they do lose. And so having GeForce, it gives you confidence and it gives you an edge, and for a lot of gamers it's just the gold standard. And so I think that number one, eSports is one the reasons why gaming continues to grow. And I think at this point it's fair to say that even though it's now the second most-watched spectator sport on the planet behind Super Bowl, it is also the second highest paid winning sport behind football. It will soon be the largest sport in the world, and I can't imagine too many young people long term not coming into this sport somehow and as this sport continues to expand in genres. And so that's one of the core reasons. Now, you asked a question about GeForce NOW, which I really appreciate. Now, the simple way to think about that is that there are many computers in the world that simply don't have the ability to enjoy video games, whether it's extremely thin and light notebooks, Apple Macs, Chromebooks, the integrated graphics that don't have very good capabilities, I think that the reasonable thing to do is to put the technology in the cloud, and it took us some five years to make this possible, to put the technology in the cloud and stream the video game experience with very low latency to the computer like Netflix does. And so we're basically turning the PC into a virtualized gaming experience and putting that into cloud. So I don't know exactly how big it's going to be yet, but our aspiration is that, that we would reach the parts of the markets where they're casual, or they just want to have another way, another device where they can game or somebody would like to come into the gaming world, and isn't quite ready to invest the time in building a computer or buying into a GeForce PC yet. So I'm anxious to learn from it, and when I learn more about GeForce, then I'll be more than happy to share it.
Jen-Hsun Huang - NVIDIA Corp.: I want to thank all of you guys for following us. We had a record year, a record quarter. And most importantly, we're at the beginning of the AI computing revolution. This is a new form of computing, new way of computing, where parallel data processing is vital to success, and GPU computing that we've been nurturing for the last decade and some is really the perfect computing approach. We're seeing tremendous growth and exciting growth in the data center market. Datacenter now represents, had grew 3x over year-over-year, and it's on its way to become a very significant business for us. Gaming is a significant business for us, and longer term, self-driving cars is going to be a really exciting growth opportunity. The thing that has really changed our company, what really defines how our company goes to market today, is really the platform approach, that instead of just building a chip that is industry standard, we created software stacks on top of it to serve vertical markets that we believe will be exciting long term that we can serve. And we find ourselves incredibly well positioned now in gaming, in AI and in self-driving cars. I want to thank all of you guys for following NVIDIA, and have a great year.
