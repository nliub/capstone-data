Mark Zuckerberg: I can take the first one. So I think the things that will drive the most results in 2025 and 2026 are actually the first category of things that I talked about in my comments which are the ways that AI is shaping the existing products. So the ways that it is improving recommendations and helping people find better content, as well as making the advertising experiences more effective. I think there is a lot of upside there. Those are already products that are at scale. The AI work that we are doing is going to improve that. It will improve the experience and the business results. The other areas that we are working on, I mean I think you all know this from following our business for a while, but we have a relatively long business cycle of starting a new product, scaling it to something that reaches 1 billion people or more and only then really focusing on monetizing at scale. So realistically, for things like Meta AI or AI Studio, I mean these are things that I think will increase engagement in our products and have other benefits that will improve the business and engagement in the near term. But before we are really talking about monetization of any of those things by themselves, I mean I don't think that anyone should be surprised that I would expect that -- that will be years, right? It's just -- I think that that's like what we've seen with Reels, it's what we saw with all these things. But I think for those who have followed our business for a long time, you can also get a pretty good sense of when things are going to work years in advance. And I think that the people who bet on those early indicators tend to do pretty well, which is why I wanted to share in my comments the early indicator that we had on Meta AI, which is I mean look, it is early. Last quarter, we -- I think it just started rolling it out a week or two before our earnings call. This time we are a few months later. And what we can say is I think we are on track to achieve our goal of being the most used AI assistant by the end of this year. And I think that is a pretty big deal. Is that the only thing we want to do? No. I mean we obviously want to kind of grow that and grow the engagement on that to be a lot deeper, and then we will focus on monetizing it over time. But the early signals on this are good and I think that -- that's kind of all that we could reasonably have insight into at this point. But I do think that part of what's so fundamental about AI is, it is going to end up affecting almost every product that we have in some way. It will improve the existing ones and will make a whole lot of new ones possible. So it is why there are all the jokes about how all the tech CEOs get on these earnings calls and just talk about AI the whole time. It is because it is actually super exciting, and it is going to change all these different things over multiple time horizons.
Mark Zuckerberg: I can start and Susan can jump in, if she has anything else that she wants to add. So the WhatsApp stat I think, is really important as a business trend just because the United States punches above its weight in terms of, it is such a large percent of our revenue. So before, WhatsApp was sort of the leading messaging app in many countries around the world but not in the US. And I think now that we're starting to make inroads into leading in the US as more and more people use the product and realize that, hey, it was a really good experience, the best experience for cross-platform communication and groups and on all these different things. I think that -- that's going to just mean that all of the work that we are doing to grow the business opportunity there over time is just going to have a big tailwind if the US ends up being a big market. So that's one reason why it's really relevant. It is obviously also personally somewhat gratifying to see all the people around us starting to use WhatsApp, so I think that is pretty fun but maybe somewhat less relevant from a business perspective. Threads, I think it is another example of something that it got off to about as good of a start of any app that I can think of. I think, it was the fastest growing app to 100 million people. And it is a good reminder that even when you have that start, the path from there to 1 billion people using an app is still multiple years. And that's our product cycle. And I think that -- that's something that is a little bit different about Meta in the way we build consumer products and the business around them than a lot of other companies that ship something and start selling it and making revenue from it immediately. So I think that's something that our investors and folks thinking about analyzing the business, if needed to always grapple with, is all these new products, we ship them and then there is a multiyear time horizon between scaling them and then scaling them into not just consumer experiences but very large businesses. But the thing that I think is just super exciting about Threads is that we've been building this company for 20 years, and there are just not that many opportunities that come around to grow 1 billion person app. I mean, there are -- I don't know, maybe a dozen of them in the world or something, right? I mean, there are certainly more of them outside the company than inside the company, but we do pretty well and being able to add another one to the portfolio if we execute really well on this is just really exciting to have that potential. Now obviously, there is a ton of work between now and there. I mean, we are almost at 200 million. So it is a really good milestone, I'm excited about that. A lot of work between this and it being a large part of the business. But I do think that these kind of opportunities are pretty rare and that's something that we are just really excited about. I think the team is doing great work on it.
Mark Zuckerberg: Yes. I'm very excited with how Llama 3.1 landed. I think the team there is doing really great work going from the first version of Llama, the Llama 2 last year that was a generation behind the frontier and now Llama 3.1, which is basically competitive and in some ways, leading the other top-closed models. Meta AI uses a version of Llama 3.1 as well as a bunch of other services that we've built to kind of build a cohesive product. And when I was talking before about we have the initial usage trends around Meta AI but there is a lot more that we want to add. Things like commerce and you can just go vertical by vertical and build out specific functionality to make it useful in all these different areas are eventually, I think what we're going to need to do to make this just as -- to fulfill the potential around just being the ideal AI assistant for people. So it is a long road map. I don't think, that this stuff is going to get finished in the next couple of quarters or anything like that. But this is part of what's going to happen over the next few years as we build something that will I think, just be a very widely used service. So I'm quite excited about that. And we are going to continue working on Llama 2. So I mean, you mentioned Llama, and I think the question was a little more about Meta AI but they are both -- I mean, they're related Llama is sort of like the engine that powers the product and it's open source, and I'm just excited about the progress that we are making on both of those. On the smart glasses, EssilorLuxottica is a great partner. We are now in the second generation of the Ray-Ban Meta glasses. They are doing well, better than I think we had expected, and we expected them to grow meaningfully from the first generation so that's been a very positive surprise. And I think part of that is that it is just well-positioned to dovetail well with the AI revolution that we are seeing and offering all kinds of new functionality there. So that was great. But EssilorLuxottica is a great company that has a lot of different products that we hope to be able to partner with to just continue building new generations of the glasses and deepen the AI product and make it better and better. I think there is a lot more to go from here. And compared to what we thought at this point, it's doing quite well compared to, I think what it needs to be, to be like a really leading piece of consumer electronics, I think we are still early but all the signs are good.
Mark Zuckerberg: So Llama is the foundation model that people can shape into all kind of different products. So whether it's Meta AI for ourselves or the AI Studio or the business agents or like the assistant that's in the Ray-Ban glasses, like all these different things are basically products that have been built with Llama. And similarly, any developer out there is going to be able to take it and build a whole greater diversity of different things as well. Like I talked about, I think -- the reason why open sourcing this is so valuable for us is that we want to make sure that we have the leading infrastructure to power the consumer and business experiences that we are building. But the infrastructure, it's not just a piece of software that we can build in isolation. It really is an ecosystem with a lot of different capabilities that other developers and people are adding to the mix, whether that's new tools to distill the models into the size that you want for a custom model, or ways to fine-tune things better or make inference more efficient or all different other kinds of methods that we haven't even thought of yet, the silicon optimizations that the silicon companies are doing, all the stuff. It is an ecosystem. So we can't do all that ourselves. And if we built Llama and just kind of kept it within our walls, then it wouldn't actually be as valuable for us to build all the products that we are building as it is going to end up being. So that's the business strategy around that. And that's why we don't feel like we need to necessarily build a cloud and sell it directly in order for it to be a really positive business strategy for us. And part of what we are doing is working closely with AWS, I think, especially did great work for this release. Other companies like Databricks, Nvidia, of course, other big players like Microsoft with Azure, and Google Cloud, they are all supporting this. And we want developers to be able to get it anywhere. I think that's one of the advantages of an open source model like Llama is – it is not like you're locked into one cloud that offers that model, whether it's Microsoft with OpenAI or Google with Gemini or whatever it is, you can take this and use it everywhere and we want to encourage that. So I'm quite excited about that. The enterprise and business applications that we are going to be most focused on, though, in addition to just optimizing the advertiser experience like I talked about in my comments earlier, it is the business agent piece. I just think that there is a huge potential like I said earlier. I think pretty much every business today, it has an e-mail address. They have a website. They have social media accounts. I think in the future, they are going to have at least one, if not multiple business agents that can do the whole range of things from interacting to help people buy things to helping support the sales that they've done, if they have issues with the product, if they need to get in touch with you for something. And we already see people interacting with businesses over messaging working quite well in countries that have low cost of labor. But the thing is that in order to have someone answering everyone's questions is quite expensive in a lot of countries. And I think that this is like a thing that AI, I think is just going to be very well suited towards doing. And when we can make that easy for the hundreds of millions of businesses that use our platforms to pull in all their information and their catalogs, and the history and all the content that they've shared and really just quickly stand up an agent, I think that's going to be awesome. So we can combine Llama with a lot of custom work that we're doing in our business teams and couple that with all the other investment that the rest of the ecosystem is doing to make Llama good. And I think that's going to be huge, but that's just one area. I mean, this really goes across all of the different products that we are building, both consumer and business. So it is a lot of exciting stuff.
Mark Zuckerberg: I can start with the first one, and then I'll let Susan answer the second one. It is an interesting question. It is a little hypothetical because I mean, I do think it's true that if, let's say, there were no future foundation models. I think there would just be a huge amount of product innovation that the industry would bring to bear, and that just takes time. But then at the same time there are going to be future foundation models, and they are going to be awesome and unlock new capabilities and we are planning our products around those. So I'm not really planning our product road map assuming that there isn't future innovation. On the contrary, we are planning what's going to be in Llama 4 and Llama 5 and beyond based on what capabilities we think are going to be most important for the road map that I just laid out for having the breadth of utility that you're going to need in something like Meta AI, making it set businesses and creators and individuals can stand up any kind of AI agents that they want, that you are going to have these kind of real-time, multimodal glasses with you all the time that will just be increasingly useful for all the things that you're doing. And that -- I guess this kind of dovetails what I'd expect Susan to talk about next. And we do have this huge set of use cases already about people wanting to discover content and interact with their friends and businesses reaching people, and all that stuff is getting better with this, too. So there is -- I guess my point there was its just – there is some lag between the technology becoming available and the products becoming kind of fully explored in the space. And I just think that -- that was kind of my way of saying that I think that this is just a very exciting area where there's just going to be a lot of innovation for a long time to come. I'll let Susan take a stab at the numbers around the GPUs and all that.
Susan Li: And Brian, I can take the second question. On the ROI part of your question, I’d broadly characterize our AI investments into two buckets; core AI and Gen AI. And the two are really at different stages, as it relates to driving revenue for our businesses and our ability to measure returns. On our core AI work, we continue to take a very ROI based approach to our investment here. We are still seeing strong returns as improvements to both engagement and ad performance have translated into revenue gains and it makes sense for us to continue investing here. Gen AI is where we are much earlier, as Mark just mentioned in his comments. We don't expect our Gen AI products to be a meaningful driver of revenue in 2024. But we do expect that they are going to open up new revenue opportunities over time that will enable us to generate a solid return off -- of our investment while we are also open sourcing subsequent generations of Llama. And we've talked about the four primary areas that we are focused here on the Gen AI opportunities to enhance the core ads business, to help us grow in business messaging, the opportunities around Meta AI, and the opportunities to grow core engagement over time. The other thing I’d say is, we are continuing to build our AI infrastructure with fungibility in mind, so that we can flex capacity where we think it will be put to best use. The infrastructure that we build for gen AI training can also be used for Gen AI inference. We can also use it for ranking and recommendations by making certain modifications like adding general compute and storage. And we are also employing a strategy of staging our data center sites, at various phases of development, which allows us to flex up to meet more demand and less lead time if needed while limiting how much spend we are committing to in the outer years. So while we do expect that we are going to grow CapEx significantly in 2025, we feel like we have a good framework in place in terms of thinking about where the opportunities are and making sure that we have the flexibility to deploy it, as makes the most sense.
Susan Li: Hi, Mark. We are continuing to see healthy global advertising demand, and we are also delivering ongoing ad performance improvements just related to all of the investments that we've continued to make over time. And improving the sort of ads, targeting ranking, delivery, all of the fundamental infrastructure there. And we expect that all of that will continue to benefit ad spend in Q3. We do expect year-over-year growth to slow in Q3, as we are lapping strong growth from China-based advertisers, as well as strong Reels impression growth from a year ago. And we also expect modestly larger FX headwinds in Q3 based on current rates.
Susan Li: Eric, I would just add to that in terms of [nearer-term] (ph) sources of impression growth, we really expect that video is going to remain a source of impression growth for us in the second half. On Instagram, we expect Reels to continue to drive growth, while on Facebook, we expect to grow overall video time, while increasing the mix of short-form video, which creates more impression growth opportunities. And generally we expect continued community growth foracross our apps.
Susan Li: Thanks, Doug. I can go ahead and talk about both of those. So your first question was sort of about the longer-term CapEx outlook. We haven't really shared an outlook sort of on the longer-term CapEx trajectory. In part infrastructure is an extraordinarily dynamic planning area for us right now. We are continuing to work through what the scope of the Gen AI road maps will look like over that time. Our expectation obviously again, is that we are going to significantly increase our investments in AI infrastructure next year, and we'll give further guidance as appropriate. But we are building all of that CapEx, again with the factors in mind that I talked about previously thinking about both how to build it flexibly, so we can deploy to core AI and Gen AI use cases as needed. And making sure that we both feel good about the returns that we're seeing on the core AI investments, which we are able to measure more immediately. And then we feel good about the opportunities in the gen AI efforts. Your second question was about the Q3 revenue outlook. Again I mentioned this earlier. We have seen healthy global advertising demand on our platform. We are delivering ongoing ad performance improvements, which again we feel like is a result of many, many quarters of effort that have accrued and will continue to accrue value to our platform. And we saw basically in Q2 where revenue grew 22% that there was broad-based strength across regions and verticals including particular strength among smaller advertisers, and we expect that generally to continue into Q3.
Susan Li: Thanks, Justin. So building products with young adults in mind has been a core priority area for the Facebook team in recent years, and we've been very encouraged to see these efforts translate into engagement growth with this cohort. We have seen healthy growth in young adult app usage in the US and Canada for the past several quarters. And we have seen that products like Groups and Marketplace have seen particular traction with young adults. Posting to groups in the US and Canada has been growing. That's been boosted mainly by young adults. And we also see that they are active users of Marketplace, which has benefited from product improvements and strong demand for second-hand products in the US.
Susan Li: Thanks Mark. On your first question about Marketplace, again we are obviously excited that it's been one of the drivers of strength in young adults. I would probably just say that more generally, Marketplace is one prong in a broader commerce strategy that we have which continues to be focused on basically creating the best shopping experience on our platform. Marketplace is obviously consumer oriented. The broader part of the commerce strategy is about making it easier for businesses to advertise their products, for buyers to find and purchase relevant items on our platform. And to that end, I’d say that we feel quite happy with also the investments we've been making in Shops ads. Shops ads revenue is growing at a strong year-over-year pace. We are seeing Shops ads drive incremental performance for advertisers, and it's also working well in combination with some of our other products like Advantage+ shopping. Your second question was about headcount. We continue to be disciplined about where we are allocating new headcount to ensure that it's really focused on our core company priorities, but we are also working down a prior hiring underrun. And as we further close that hiring underrun over the course of this year, I do expect that we will end 2024 with in-seat reported headcount that is meaningfully higher than where we ended 2023. We aren't providing sort of 2025 headcount growth expectations yet as we haven't started our budgeting process yet. But again, I expect that we’ll primarily target our hiring to focus on priority areas, and we will be running a very disciplined headcount process.
Susan Li: Thank you. We are clearly in the process of building out a lot of capacity, and Mark has alluded to that in his comments about what we have needed to train prior generations and the next generation of Llama. And we are -- and that's driving sort of what we've talked about in terms of the significant growth in CapEx in 2025. And we aren't really in the position now to share a longer-term outlook. When we think about sort of any given new data center project that we are constructing, we think about how we will use it over the life of the data center. We think about the amount of capacity we would use in terms of training whatever the subsequent generations of Llama are and it is architected around that. But then we also look at how we might use it several years into its lifetime towards other use cases across our core business, across what we think might be future needs for inference, for generative AI-based products. So there is sort of a whole host of use cases for the life of any individual data center ranging from gen AI training at its outset to potentially supporting gen AI inference to being used for core ads and content ranking and recommendation and also thinking through the implications, too, of what kinds of servers we might use to support those different types of use cases. So we are really mapping across a wide range of potential use cases when we undertake any given project. And we are really doing that with both a long time horizon in mind, again, because of the long lead times in spinning up data centers, but also recognizing that there are multiple decision points in the lifetime of each data center in terms of thinking through when to order servers and what servers to order and what you will put them towards. And that gives us flexibility to make the sort of the best decisions based on the information we have in the future.
