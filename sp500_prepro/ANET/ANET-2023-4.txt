Liz Stine: Thank you, operator. Good afternoon, everyone, and thank you for joining us. With me on today's call are Jayshree Ullal, Arista Networks' Chairperson and Chief Executive Officer; Ita Brennan, Arista's outgoing Chief Financial Officer; and Chantelle Breithaupt, Arista's incoming Chief Financial Officer. This afternoon, Arista Networks issued a press release announcing the results for its fiscal fourth quarter ending December 31st, 2023. If you'd like a copy of this release, you can access it online from our website. During the course of this conference call, Arista Networks' management will make forward-looking statements, including those relating to our financial outlook for the first quarter of the 2024 fiscal year, longer-term financial outlooks for 2024 and beyond, our total addressable market and strategy for addressing these market opportunities, including AI, customer demand trends, supply chain constraints, component costs, manufacturing output, inventory management and inflationary pressures on our business, lead times, product innovation, working capital optimization and the benefits of acquisitions, which are subject to the risks and uncertainties that we discuss in detail in our documents filed with the SEC, specifically in our most recent Form 10-Q and Form 10-K and which could cause actual results to differ materially from those anticipated by these statements. These forward-looking statements apply as of today, and you should not rely on them as representing our views in the future. We undertake no obligation to update these statements after this call. Also, please note that certain financial measures we use on this call are expressed on a non-GAAP basis and have been adjusted to exclude certain charges. We have provided reconciliations of these non-GAAP financial measures to GAAP financial measures in our earnings press release. With that, I will turn the call over to Jayshree.
Liz Stine: Thank you, Chantelle. We will now move to the Q&A portion of the Arista earnings call. To allow for greater participation, I'd like to request that everyone please limit themselves to a single question. Thank you for your understanding. Operator, take it away.
Liz Stine: Thanks, Karl. This concludes the Arista Networks Fourth Quarter 2023 Earnings Call. We have posted a presentation, which provides additional information on our results, which you can access on the Investors section of our website. Thank you for joining us today, and thank you for your interest in Arista.
Jayshree Ullal: Thank you, Ita, first of all, for an incredible eight and a half years as our Chief Financial Officer. We're going to miss you a lot and wish you all the best in your next innings. And if you ever miss an earnings call, please come, we'll invite you for one. Now, to describe our Q1 2024 guidance, it's my pleasure to introduce our incoming Chief Financial Officer, Chantelle Breithaupt for her very first earnings call at Arista. Welcome, Chantelle.
Jayshree Ullal: Thank you, Aaron. And yes, we will all miss, Ita. So our AI performance continues to track well for the $750 million revenue goal that we set last November at Analyst Day. To give you some color on the last three months, I would say, difficult to project anything in three months. But if I look at the last year, which may be - the last 12 months, is a better indication we have participated in a large number of AI bids. When I say large, I should say they're large AI bids, but they're a small number of customers actually to be more clear. And in the last four out of five AI networking clusters we have participated on Ethernet versus InfiniBand, Arista has won all four of them for Ethernet, one of them still stays on InfiniBand. So these are very high-profile customers. We are pleased with this progress. But as I said before, last year was the year of trials. This is the year of pilots. And true production truly sets in only in 2025.
Jayshree Ullal: Yeah. So, Tal, first of all, as you know, Ita and I, or Chantelle and I, would never really comment on bookings, orders. We find these all to be kind of useless metrics, because ultimately what matters is what we ship, which is revenue. But just to sort of answer your question on ratio of CPUs, or for that matter, GPUs in the future to the network, typically, we have to have the CPUs or GPUs come in before we can outfit the network. They kind of go hand in hand, but as you know, in AI, we've been waiting for the GPUs and in the last couple of years, they've been waiting for everything with a long lead time. But I would say generally in the leaf architecture, they go hand in hand where you have to create a rack of 1,000 servers or whether they're CPUs and GPUs. And generally they look to rack and stack the cable, the CPUs and the network together. On the spine, which connects all of our leaf, that decision can be made independently even if the processors are not available. So on the leaf, it's more correlated, on the spine it's not.
Jayshree Ullal: It's a good question, Sebastian, Thank you. Look, I think white box is here to stay for a very long time if somebody just wants a throwaway commodity product. But how many people want throwaway commodity in the data center? They're so mission critical. And they're even more mission critical for AI. If I'm going to spend multi-million dollars on a GPU cluster, then the last thing I'm going to do is put a toy network in, right? So to put this sort of in perspective, we will continue to coexist with the white box. There will be use cases where Arista's blue box or a standalone white box can run either SONiC or FBOSS, but many times the EOS software stack is really, really something they depend on for availability, analytics, automation. And there's -- you can get your network for zero cost, but the cost of downtime is millions and millions of dollars. So we have always embraced white box, we coexist with it, but it continues to be a relatively small use case in the larger mission critical data centers for enterprise and cloud companies.
Jayshree Ullal: Yeah, no, but Matt, that's a good question. I think on the cloud and AI, we feel pretty bulked up to deal with those customers because they don't look for size and bulk, they look for, as you know, networking innovation capabilities and this has been Arista's heritage for 10 years and will continue to be with the AI cycle for the next foreseeable 10 years. On the enterprise there are multiple markets and size helps. I think if you are targeting the early adopters, Arista has traditionally done very, very well there. And the last three years is a good example of how well we've done there, both in the data center and in the campus. If you look at the next category of sort of the, not necessarily the screaming early adopters, but maybe the fast followers, I think Arista will continue to do well there in the large enterprise. We are so underserved and under penetrated in both the Fortune 1000 and the Global 2000. We got a long, long ways to go. We probably have 20% of those customers. We've got 80% of them left to go. And I'm not even talking about the mid-market and the SMB, which is a whole other market that we are underserved in. So absolutely, we need to make more investments in enterprise there. When I look at what Anshul, Chris Schmidt, Ashwin are doing, this is exactly where we're doubling down. This is exactly where we doubled down in the last three years post pandemic. And we have more than doubled our revenue and increased our logo presence because of this investment in the enterprise. I can't comment about consolidation of vendors, but when vendors don't grow, five plus five sometimes is 10. But to be careful on integration, five plus five can sometimes be seven too. So that's somebody else's responsibility, not mine. I think we can get a lot of organic growth.
Jayshree Ullal: And, Meta, to answer your question on enterprise and AI activity, I think Arista continues to drive the concept of EOS, multi-domain routing, campus, high availability, mission-critical enterprises for multiple verticals. We're making good progress there and this is going to be the part of our mainstream innovation and go-to-market. On the AI side, we continue to track well. I think we're moving from what I call trials, which is connecting hundreds of GPUs to pilots, which is connecting thousands of GPUs this year, and then we expect larger production clusters. I think one of the questions that we will be asking ourselves and our customers is how these production clusters evolve? Is it going to be 400, 800 or a combination thereof? The role of Ultra Ethernet Consortium and standards and the ecosystem all coming together, very similar to how we had these discussions in 400 gig will also play a large part. But we're feeling pretty good about the activity. And I think moving from trials to pilots this year will give us considerable confidence on next year's number.
Jayshree Ullal: That's a good question, Alex. I certainly talk to a lot of CIOs and CEOs. And if I rewind the clock to January last year, I think price was a lot spookier then. We were going through this whole financial crisis, Silicon Valley Bank, this, that, the other. And if I now fast forward to a year later, our momentum in the enterprise is actually stronger now than it was a year ago. So all this [Technical Difficulty] customers are looking for that innovation, modern network model, CI/CD principles, bringing DevOps, NetOps, SecOps, all of this together. And so Arista continues, in my view, with the large TAM we have in the enterprise of at least $30 billion out of that $60 billion to find the opportunity to really deliver that vision of client to cloud, break down the operational silos. And I would say today, the CIOs recognize us as the pure-play innovator more than any other company.
Jayshree Ullal: Yeah. I don't understand the announcement as well as probably my competitor does. I think it has more to do with UCS and Cisco validated designs. Specific to our partnership, you can be assured that we'll be working with the leading GPU vendors. And as you know, NVIDIA has 90% or 95% of the market. So, Jensen and I are going to partner closely. It is vital to get a complete AI network design going. We will also be working with our partners in AMD and Intel. So we will be the Switzerland of XPUs, whatever the GPU might be, and we look to supply the best network ever.
Jayshree Ullal: Yeah. Thanks, Tim. Okay. So let me just step back and say the first real consultative approach from Arista is to provide our expertise on how to build a robust back-end AI network. And so the whole discussion of Ethernet become -- versus InfiniBand becomes really important because as you may recall, a year ago, I told you we were outside looking in, everybody had an Ethernet -- everybody had an InfiniBand HPC cluster that was kind of getting bundled into AI. But a lot has changed in a year. And the popular product we are seeing right now as the back-end cluster for our AI is the Arista 7800 AI spine, which in a single chassis with north of 500 terabits of capacity can give you a substantial number of ports, 400 or 800. So you can connect up to 1,000 GPUs just doing that. And that kind of data parallel scale-out can improve the training time dimensions, large LLMs, massive integration of training data. And of course, as we shared with you at the Analyst Day, we can expand that to a two-tier AI leaf and spine with a 16-way CMP to support close to 10,000 GPUs nonblocking. This lossless architecture for Ethernet and then the overlay we will have on that with the Ultra Ethernet Consortium in terms of congestion controls, packet spring and working with a suite of UEC mix is what I think will make Ethernet the default standard for AI networking going forward. Now will it be sole source [indiscernible], I would be remiss if I didn't tell you that our cloud networking isn't sole sourced. So probably our AI won't be too. But today's models are moving very rapidly, relying on a high bandwidth, predictable latency, the focus on application performance requires you to be sole sourced initially. And over time, I'm sure it'll move to multiple sources, but I think Arista is very well positioned for the first innings of AI networking, just like we were for the cloud networking decade. And one other thing I want to say is, although a lot of these customers are doing AI pivots, these AI pivots will result in revisiting the front-end cloud network, too. So this AI anatomy is being really well understood. And if you take a deep look at the center piece of it, which is all the GPUs, they have to connect to something very reliable and this is really where we come in. And so this -- being actively involved has -- is going to pay a lot of dividends, but we're still very much in our first innings of AI.
Jayshree Ullal: And look, if our conservatism changes to more optimism in the second half or more likely in 2025, we'll keep you posted.
Jayshree Ullal: Yeah. Thank you, Karl. Again, I'll step -- history is a good indicator of future. And if you look at our 400-gig, everybody asked me the same question. They said, how come 400 gig isn’t taking off in 2019 or '20? And it turned out it took our ecosystem several years and of course, the pandemic didn't help when it was optics or NICs for the whole entire thing to come together. And I don't doubt we will have trials for 800 gig this year, but I think real production, 800 gig will happen in 2025. I'd like to be proven wrong and maybe it'll come in sooner in which case, like I said, we'll let you know. But at the moment, this is our best case prediction.
Ita Brennan: Yeah, maybe I'll take that last one first. I mean a lot of the upside in the fourth quarter was really just customer mix, right? I mean we were weighted heavily towards enterprise in Q4, not for any particular reason. It just happened to be that way and that kind of dropped the margins higher.
Ita Brennan: Yeah, Jim, I think the deferred, if you think back to how this works, I mean obviously, it's been shipped for it to actually be in deferred, right? So I think that's -- it's just timing. And we've talked about this over the past. I'm sure Chantelle is going to talk about it again, in the future, right, is that it really is just purely timing of shipments and where we have some new type projects, new capabilities that we're trialing with the customer, that's causing it to get caught in the deferred. But it's not a fundamental underlying driver of the business. I think on pricing and the very little that's happening in terms of pricing adjustments, that's kind of out of the order, just normal pricing environment where we continue to compete for business. I don't think there's anything particularly different there that we've seen.
Ita Brennan: Yeah. I think that says it all. I mean, all the drivers that you mentioned are great drivers, the timing of everything that's always complex, right? So we'll take it a quarter at time and see how things play out.
