Pat Gelsinger: Yes. Thanks, Ross, and thanks for the congrats on the quarter as well. I’m super proud of my team for the great execution this quarter, top, bottom line, beats, raise, just great execution across every aspect of the business, both financially as well as road map execution. With regard to the data center, obviously, the good execution, I’ll just say we executed well, winning designs, fighting hard in the market, regaining our momentum, good execution. As you said, we’ll see the Sapphire Rapids at the 1 millionth unit in the next couple of days, our Xeon Gen 4. So overall, it’s feeling good. Road map’s in very good shape, so we’re feeling very good about the future outlook of the business as well. As we look to 5th Gen E-core, P-core with Sapphire and Granite Rapids, so all of those, I’ll just say we’re performing well. That said, we do think that the next quarter, at least, will show some softness. There’s some inventory burn that we’re still working through. We do see that big cloud customers, in particular, have put a lot of energy into building out their high-end AI training environments. And that is putting more of their budgets focused or prioritized into the AI portion of their build-out. That said, we do think this is a near term, right, surge that we expect will balance over time. We see AI as a workload, not as a market, right, which will affect every aspect of the business, whether it’s client, whether it’s edge, whether it’s standard data center, on-premise enterprise or cloud. We’re also seeing that Gen 4 Xeon, and we’ll be enhancing that in the future road map has significant AI capabilities. And as you heard in the prepared remarks, we expect about 25% today and growing of our Gen 4 is being driven by AI use cases. And obviously, we’re going to be participating more in the accelerator portion of the market with our Gaudi, Flex and MAX product lines. Particularly, Gaudi is gaining a lot of momentum. In my formal remarks, we said we now have over $1 billion of pipeline, 6x in the last quarter. So, we’re going to participate in the accelerator portion of it. We’re seeing real opportunity for the CPU as that workload balances over time between CPU and accelerator. And obviously, we have a strong position to democratize AI across our entire portfolio of products.
Pat Gelsinger: Yes. And as we said, Joe, -- thanks for the question. As we said in the prepared remarks, we do expect to be seeing the TAM down in Q3, somewhat driven by all of it. It’s a little bit of data center digestion for the cloud guys, a bit of enterprise, so weakness, and some of that is more inventory. And the China market, I think, has been well reported, hasn’t come back as strongly as people would have expected overall. And then the last factor was one of the first question from Ross around the pressure from accelerator spend being stronger. So, I think those four somewhat together, right, are leading to a bit of weakness, at least through Q3. That said, our overall position is strengthening and we’re seeing our products improve, right? We’re seeing the benefits of the AI capabilities and our Gen 4 and beyond products improving. We’re also starting to see some of the use cases like Graph Neural Networks, Google’s AlphaFold showing best results on CPUs as well, which is increasingly gaining momentum in the industry as people look for different aspects of data preparation, data processing, different innovations in AI. So all of that taken together, we feel optimistic about the long-term opportunities that we have in data center, and of course, the strengthening accelerator road map of Gaudi2, Gaudi3, Falcon Shores being now well executed. Also, our first wafers are in hand for Gaudi3. So, we see a lot of long-term optimism even as near term, we’re working through some of the challenging environments of the market not being as strong as we would have hoped.
Pat Gelsinger: Yes. And thanks, C.J. And generally, there are great analogies here that from history we point to. Cases like virtualization was going to destroy the CPU TAM and then ended up driving new workloads, right? If you think about a DGX platform, the leading edge AI platform, it includes CPUs, right? Why? Head nodes, data processing, data prep, dominate certain portions of the workload. We also see, as we said, AI as a workload where you might spend 10 megawatts and months training a model but then you’re going to use it very broadly for inferencing. We do see with Meteor Lake ushering in the AI PC generation, where you have tens of watts being responding in a second or two. And then, AI is going to be in every hearing aid in the future, including mine, where it’s 10 microwatts and instantaneous. So, we do see as AI drives workloads across the full spectrum of applications. And for that, we’re going to build AI into every product that we build, whether it’s a client, whether it’s an edge platform for retail and manufacturing and industrial use cases, whether it’s an enterprise data center where they’re not going to stand up a dedicated 10-megawatt farm, but they’re not going to move their private data off-premises, right, and use foundational models that are available in open source as well as in the big cloud and training environments as well. We firmly believe this idea of democratizing AI, opening the software stack, creating and participating with this broad industry ecosystem that’s emerging. It was a great opportunity and one that Intel is well positioned to participate in. We’ve seen that the AI TAM, right, is part of the semiconductor TAM. We’ve always described this trillion-dollar semiconductor opportunity and AI being one of those superpowers, as I call it, of driving it. But it’s not the only one and one that we’re going to participate in broadly across our portfolio.
Pat Gelsinger: Yes. Thank you. And we continue to make good progress on our 5 nodes in 4 years. And with that, that culminates in 18A. And 18A is proceeding well and we got a particularly good response this quarter to PowerVia, the backside power that we believe is a couple of years ahead as the industry measures it against any other alternative in the industry. We’re very affirmed by the Ericsson announcement, which is reinforcing the strong belief they have in 18A. But over and above that, I mentioned in the prepared remarks the two major significant opportunities that we made very good progress on as a big 18A foundry customers this quarter and an overall growing pipeline of potential foundry customers, test chips and process as well. So we feel 5 nodes in 4 years is on track. 18A is the culmination of that and good interest from the industry across the board. I’d also say that as part of the overall strength in the foundry business as well and maybe tying the first part and the second part of your question together is that our packaging technologies are particularly interesting in the marketplace, an area that Intel never stumbled, right? This is an area of sustained leadership that we’ve had. And today, many of the big AI machines are packaging limited. And because of that, we’re finding a lot of interest for our advanced packaging, and this is an area of immediate strength for the foundry business. We set up a specific packaging business unit within our foundry business and finding a lot of great opportunities for us to pursue there as well.
Pat Gelsinger: Yes. And just maybe to pile on to that a bit, obviously, getting EU Chips Act approved, we’re excited about that for the Germany and Poland projects, which are -- will go for formal DG comp approval. We’re also very happy, we submitted our first proposal, the on-track Arizona facility, but we’ll have 3 more proposals going in for U.S. CHIPS Act this quarter. And so we’re now at pace for those. So everything there is feeling exactly as we said it would and super happy with the great engagement, both in Europe as well as with the U.S. Department of Commerce as we’re working on those application processes.
Pat Gelsinger: Yes. And let me take that and Dave can add. Overall, as we said, the accelerator pipeline is now well over $1 billion and growing rapidly, about 6x this past quarter. That’s led by but not exclusively Gaudi but also includes the Max and Flex product lines as well. But the lion’s share of that is Gaudi. Gaudi2 is shipping volume product today. Gaudi3 will be the volume product for next year and then Falcon Shores in ‘25, and we’re already working on Falcon Shores 2 for ‘26. So, we have a simplified road map as we bring together our GPU and our accelerators into a single offering. But the progress that we’re making with Gaudi2, it becomes more generalized with Gaudi3, the software stack, our One API approach that we’re taking will give customers confidence that they have forward compatibility into Gaudi3 and Falcon Shores. And we’ll just be broadening the flexibility of that software stack. We’re adding FP8. We just added PyTorch 2 support. So every step along the way, it gets better and broader use cases. More language models are being supported. More programmability is being supported in the software stack. And we’re building that full, right, solution set as we deliver on the best of GPU and the best of matrix acceleration in the Falcon Shores time line. But every step along the way, it just gets better. Every software release gets better. Every hardware release gets better along the way to cover more of the overall accelerator marketplace. And as I said, we now have Gaudi3 wafers. First ones are in hand, so that program is looking very good. And with this rapidly accelerating pipeline of opportunity, we expect that we’ll be giving you very positive updates there in the future with both customers as well as expanded business opportunities.
Pat Gelsinger: Yes. And I think the real question is what applications are going to become AI-enabled? And today, you’re starting to see that people are going to the cloud and goofing around with ChatGPT, writing a research paper and that’s like super cool, right? And kids are, of course, simplifying their homework assignments that way. But you’re not going to do that for every client becoming AI-enabled. It must be done on the client for that to occur, right? You can’t go to the cloud. You can’t round trip to the cloud. All of the new effects, real-time language translation in your Zoom calls, real-time transcription, automation, inferencing, relevance portraying, generated content and gaming environments, real-time creator environments being done through Adobes and others that are doing those as part of the client, new productivity tools being able to do local legal brief generations on clients, one after the other, right, across every aspect of consumer, of developer and enterprise efficiency use cases. We see that there’s going to be a raft of AI enablement and those will be client-centered. Those will also be at the edge. You can’t round trip to the cloud. You don’t have the latency, the bandwidth or the cost structure to round trip, let’s say, inferencing in a local convenience store to the cloud. It will all happen at the edge and at the client. So with that in mind, we do see this idea of bringing AI directly into the client immediately, right, which we’re bringing to the market in the second half of the year, is the first major client product that includes native AI capabilities, the neural engine that we’ve talked about. And this will be a volume delivery that we will have. And we expect that Intel is the volume leader for the client footprint, is the one that’s going to truly democratize AI at the client and at the edge. And we do believe that this will become a driver of the TAM because people will say, "Oh, I want those new use cases. They make me more efficient and more capable, just like Centrino made me more efficient because I didn’t have to plug into the wire, right? Now, I don’t have to go to the cloud to get these use cases. I’m going to have them locally on my PC in real time and cost effective. We see this as a true AI PC moment that begins with Meteor Lake in the fall of this year.
Pat Gelsinger: Yes. Let me start on that and Dave can jump in. The biggest change quarter-on-quarter that we see is that we’re now at healthy inventory levels. And we worked through inventory Q4, Q1 and some in Q2. We now see the OEMs and the channel at healthy inventory levels. We continue to see solid demand signals for the client business from our OEMs and even some of the end-of-quarter and early quarter sell through are clear indicators of good strength in that business. And obviously, we combine that with gaining share again in Q2. So, we come into the second half of the year with good momentum and a very strong product line. So, we feel quite good about the client business outlook.
Pat Gelsinger: Yes. Thank you, Srini. And the simple answer is yes, and I have multiple ways to play in this market. Obviously, one of those is foundry customers. We have a good pipeline of foundry customers for 18A, foundry opportunities. And several of those opportunities that we’re investigating are exactly what you described, people looking to do their own unique versions of their AI accelerator components, and we’re engaging with a number of those. But some of those are going to be variations of Intel standard products. And this is where the IDM 2.0 strength really comes to play where they could be using some of our silicon, combining it with some of their silicon designs. And given our advanced packaging strength, that gives us another way to be participating in those areas. And of course, that reinforces some of the near-term opportunities will just be packaging, right, where they already have designed with one of the other foundry, but we’re going to be able to augment their capacity opportunities with immediately being able to engage with packaging opportunities and we’re seeing pipeline of those opportunities. So overall, we agree that this is clearly going to be a market. We also see that some of the ones that you’ve seen most in the press are about particularly high-end training environments. But as we said, we see AI being infused in everything. And there’s going to be AI chips for the edge, AI chips for the communications infrastructure, AI chips for sensing devices, for automotive devices, and we see opportunities for us, both as a product provider and as a foundry and technology provider across that spectrum, and that’s part of the unique positioning that IDM 2.0 gives us for the future.
Pat Gelsinger: Simple answer. Yes. Right? And everyone is looking for alternatives. Clearly, the MLPerf numbers that we posted recently with Gaudi2 show very competitive numbers, significant TCO benefits for customers. They’re looking for alternatives. They’re also looking for more capacity. And so, we’re definitely engaged. We already have Gaudi instances on AWS as available today already. And some of the names that we described in our earnings calls, Stability AI, Genesis Cloud. So, some of these are the proven, I’ll say, at scale Tier 1 cloud providers but some of the next-generation ones are also engaging. So overall, absolutely, we expect that to be the case. We’re also on our own dev cloud, we’re making it easier for customers to test Gaudi more quickly. And with that, we now have 1,000 customers now who are taking advantage of the Intel Development Cloud. We’re building a 1,000-node Gaudi cluster so that they can be at scale with their testing a very large training environment. So overall, the simple answer is, yes, very much so, and we’re seeing a good pipeline of those opportunities.
Pat Gelsinger: So with that, let me just wrap up our time together today. Thank you. We’re grateful that you would join us today, and we’re thankful that we have the opportunity to update you on our business. And simply put, it was a very good quarter. We exceeded expectations on top line, on bottom line. We raised guidance and we look forward to the continue opportunities that we have of accelerating our business and seeing the margin improvement that comes in the second half of the year. But even more important to me was the operational improvements that we saw, a good fiscal discipline, cost saving discipline and best of all, the progress that we’ve made, right, on our execution, our process execution, product execution, the transformational journey that we’re in. And I just want to say a big thank you to my team for having a very good quarter that we could tell you about today. We look forward to talking to you more, particularly at our Innovation in September. We’ll be hosting an investor Q&A track and we hope to see many, if not all of you there. It will be a great time. Thank you.
David Zinsner: Yes. Good question, Ross. So in the second quarter, just to repeat what I said in the prepared remarks, that was largely a function of revenue. We had obviously beat revenue significantly and we got a good fall-through, given the fixed cost nature of our business. And so that really was what helped us really outperform significantly on the gross margin side in the second quarter. In the third quarter, we do, obviously, at the midpoint, see revenue growth sequentially. And so that will be helpful in terms of gross margin improvement. We expect, again, pretty good fall-through as we get that incremental revenue. We’re also going to see underloadings come down, I would say, modestly come down for two reasons: one, we get that period charge for some of our underloading, but some of our underloading is actually just a function of the cost of the inventory. And so that takes some time to flow through. So, it will be more -- it will be a modest decline but nevertheless helpful on the gross margin front. And then as you point out, we will have pre-PRQ reserves in the third quarter but they’re meaningfully down from the second quarter. Meteor Lake will not be a pre-PRQ reserve in the third quarter because we expect to launch that this quarter. But we have Emerald Rapids, that will certainly have some impact and then some of the other SKUs will also impact it. So, coming down but not to zero. So we have an opportunity actually to perform better in the fourth quarter, obviously dependent on the revenue and so forth, given that pre-PRQ reserves are likely to come off again in the fourth quarter. We should improve on the loading front in the fourth quarter as well. So, there’s some, I think, some good tailwinds on the gross margin front. I’ll just take an opportunity to talk longer term. We will continue to be weighed down for some quarters on underload because of the nature of just having it cycle through inventory and then come out through cost of sales. So for multiple quarters, we’ll have some underloading charges that we’ll see. And then as we talked about for -- since really, Pat joined and we kind of launched into the 5 nodes in 4 years, we’re going to have a significant amount of startup costs that will hit gross margins that will affect us for a couple of years. But we’re really optimistic about where gross margins are going over the long term. Ultimately, we will get back to process parity and leadership and that will enable us to not have these start-up costs be a headwind. And of course, as you bring out products at a high performance in terms of process and in terms of product, that shows up in terms of our margins. And then, as Pat mentioned, he went through a laundry list in the prepared remarks of areas of benefit that the internal foundry model will give us. We expect a pretty meaningful amount of that to come out in -- by the time we hit 2026. But we won’t be done there. I mean, I think there will be multiple opportunities over the course of multiple years to improve the gross margin. So, Pat has talked about a pretty significant improvement in gross margins over time. And I think what we’re seeing today is the beginnings of seeing that improvement show up in the P&L.
David Zinsner: Platform costs, okay. Well, first of all, ASP is obviously improving as we increase core count and as we get more competitive on the product offerings, that enables us to have more confidence in the market in terms of our pricing. So that’s certainly helpful. Obviously, with the increase in core count, that affects the cost as well. So, cost obviously goes up. But the longer -- the larger drivers of our cost structure will be around what we do in terms of the internal foundry model as we get up in terms of scale and get away from these underloading charges, and as we get past the start-up costs on 5 nodes in 4 years, which data center is certainly getting hit with. And so those things, I think, longer term will be the biggest drivers of gross margin improvement. And as we get -- launch Sierra Forest in the first half of next year and Granite later thereafter and start to produce products on the data center side that are really competitive, that enables us to even be stronger in terms of our margin outlook and should help improve the overall P&L of data center.
David Zinsner: Yes. So we did manage CapEx a bit better than I was hoping. We thought it would be more front-end loaded. It’s looking -- look it’s going to be a lot more evenly distributed first half versus the second half. And we managed CapEx in particular this quarter really well, which I think obviously helped on the free cash flow side. It’s kind of a when you manage the CapEx, you get less offsets. And so that kind of drove the lower capital offsets for the quarter. But for the year, we’re still on track to get the same amount of capital offsets through SCIP that we had anticipated. And that’s really where most of the capital offsets have come so far. Now obviously, as we get into CHIPS incentives that should be coming here in the not-too-distant future, that will add to the offsets that we get. We go into next year, we start getting the investment tax credit that will help on the capital offsets. So, there’ll be more things that come in the future. But right now, it’s largely SCIP and it’s SCIP1, and that’s a function of where the spending lands quarter-to-quarter.
David Zinsner: I’d just add, normally over the last few quarters, you’ve seen us identify in the 10-Q strategic sales that we’ve made where we’ve negotiated kind of attractive deals which have accelerated demand, let’s call it. When you look at our 10-Q, which will either be filed late tonight or early tomorrow, you’ll see that we don’t have a number in there for this quarter, which is an indication of how little we did in terms of strategic purchases. So to your question of did we pull in demand, I think that’ll probably give you a pretty good assessment of that.
David Zinsner: Okay. So, let me just take a moment just to give the team credit on the second quarter in terms of working capital because we brought inventory down by $1 billion. Our days sales outstanding on the AR front is down to 24 days, which is exceptional. So, a lot of what you saw in terms of the improving free cash flow from Q1 to Q2 was working capital. So, I think the team has done an outstanding job just really focusing on all the elements that drive free cash flow. Our expectation is still by the end of the year to get to breakeven free cash flow. There’s no reason why we shouldn’t achieve that. Obviously, the net CapEx might be a little different this year than we thought coming into the year. But as we talked about, there’s just a focus on free cash flow, the improved outlook in terms of the business. We think we can get to breakeven by the end of the year. As it relates to pre-PRQ reserves in the fourth quarter, we’re likely to have some, but it should be a pretty good quarter-over-quarter improvement from the third quarter, which was obviously a good quarter-over-quarter improvement from the second quarter.
David Zinsner: Yes, they were largely as expected, although it was off of a lower revenue number. So, the absolute dollars were as expected. They had a little bit of less of an impact, given the revenue was higher. And both of those numbers, like I said, will be lower in the third quarter.
