Patrick Gelsinger: Yes. Starting out, so Ross, thanks for the question. I'll just say the market was weaker. You've seen that in a number of others that have commented as well. So I'll say somewhat across the board a bit. We've seen that, cloud customers, enterprise, across geos. So I'll just say a bit weaker demand, right, we'll just say at the low end of seasonality Q1 to Q2 that we saw. And as we go into the second half of the year, we're engaging deeply with our customers today, our OEM partners, and we just see strength across the board, right?  Part of that is driven by our unique product position, some of it driven by the market characteristics and client, AI PC and a second half Windows upgrade cycle, we believe, underway and Core Ultra is hot. And as we said, even in Q2, we're racing -- we're meeting all of our commitments, but not all of the upside requests that we're seeing from customers. So we see a very strong AI PC outlook in the data center. As we bring in our new products, we're seeing ASPs increase very healthy on our data center products and with products like CR4 that we just went to production with this week on Intel 3, we're seeing improved product position as well for competitiveness.  We have the $0.5 billion of Gaudi, right? And most of that is second half loaded. And the All Other businesses coming out of inventory positions in Altera and Mobileye and NEX, all of those improved first half to second half as well. And then incremental, I'll just say, Intel Foundry, every quarter from here until the decade and we're seeing improvement in the Intel Foundry. And one by one, we're seeing all of those business improvements both on revenue and margin improvements over time. So we feel very comfortable that the second half outlook is quite strong for the business, a first half a bit weaker, but we think it's very understandable, very explainable, and a second half outlook that will be very comfortable for every business across Intel growing and a lot of momentum as we go into '25. 
Patrick Gelsinger: Yes. Thank you, Ben. And obviously, as we look at our position in the data center, I'll just say we're stabilizing. And with that, we're improving our competitiveness. We also see, as I mentioned in the comments, that the ASPs are going up comfortably as well. So socket fairly stable through the year, but the ASP per socket with increased core count improves our position. And then new products like Sierra Forest or Xeon Gen 6 product, definitely gives us power performance capabilities. So overall, we're seeing a very healthy growth rate, mid-20s as we go through the year. We're also seeing increasing interest in the AI capabilities of Xeon. And we're winning head node positions, and we're seeing pretty extraordinary performance at Vision.  We talked about the ability to now run 70 billion parameter models directly on Xeon. And these type of capabilities, say, for a lot of enterprise use cases, Xeon is a very strong product. And as we laid out at Vision, the ability for Xeon plus Gaudi to start positioning this open platform for enterprise AI is a very strong position for us. So overall, we feel like we're on a solid trajectory into a market that even though it's been dominated by the gen AI theme as enterprises, our OEMs and ODMs are communicating, there's growth here in servers. And we now have a much better product position, improving ASPs and a better overall positioning in AI for a lot of these use cases where it's Xeon CPU plus GPU and accelerator. 
Patrick Gelsinger: Yes. Thanks, Ben. And obviously, pipeline converting into revenue, revenue is much more meaningful and as we said, greater than $500 million for the year, and that's obviously quarter-on-quarter accelerating rapidly, which also gives a great indication for the business in '25 as well. At our Vision event, we had over 20 customers publicly describing their embrace of Gaudi 2 and Gaudi 3. And I was super pleased to see the breadth of those customers. It was CSPs like Naver and Ola and IBM Cloud. It was ISVs like Zeekr, right, coming on board, but maybe most importantly, enterprise customers.  And ultimately, gen AI training, okay, creating models, but enterprises are going to use models, and that's where our TCO benefits. The ability for us to action customers' data in their enterprise environment is so powerful and customers like Bosch were coming forward and Roche to be able to demonstrate the true benefits of Gaudi and Xeon plus Gaudi. The road map is in good shape. The Gaudi 3 Falcon Shores in '25. We're also seeing that the industry wants to open alternatives. And we announced our AI networking initiative, Ultra Ethernet Consortium standardizing on scale up and scale out to Ethernet, increasing work for abstract levels of AI development with PyTorch and the embrace of the open platform for enterprise AI that we rolled out. All of those taken together, the industry is looking for open enterprise alternatives for regenerative AI deployment and Intel are quite well positioned, and we're starting to really see that uptake in our Accelerator and Xeon pipeline now. 
Patrick Gelsinger: Yes. So Sierra Forest, our first Xeon 6 product on Intel 3, and I'm super proud, right? Now we have a leadership process technology back on American soil for the first time in a decade. This is really exciting. And Sierra Forest, high core count, 144, 288 core product, very focused on power, performance, efficiency, and we do see a good pipeline of customers and a good pipeline of, I'll say, socket win backs because the area of power performance has been an area that we've been carrying a deficit, being on an older node. And now that we're on leadership nodes, we definitely see share gains for that.  Of course, Granite Rapids, which will come in Q3, the Xeon 6 P-Core part is much more the bread and butter of the Xeon family. So we do see that being a stronger element to the portfolio this year as we haven't been participating in the power performance sockets as aggressively lately, and Sierra Forest gives us that tool. So it really is a one-two punch, as we've described. With Granite coming in Q3 and a volume ramp on Intel 3 with that, we feel we have a very good product line.  Next year is Clearwater Forest, the second generation of the E-core part, the leadership position on 18A in the server market, a very strong product for us, unquestioned leadership and power performance, so I believe that's a great opportunity for us to gain share again in the data center. So the road map is healthy. The execution is strong, and we're rebuilding customer trust. They're looking at us now and saying, "Oh, Intel is back." And we're quite excited by that. And then beyond that, building the volume, building the confidence and the momentum for traditional use cases as well as the AI use cases, as I just referred on Ben's question as well. 
Patrick Gelsinger: Yes, Joe, thank you. And servers always just take a while to ramp. Customers bring them in, they qualify them, they test them because they're generally putting these things at scale. So there's just an adoption cycle for server products. And the numbers that I'm holding my team accountable for are some of the most aggressive volume ramps that we've ever achieved on server products. So we're driving them very hard. That said, in terms of the total wafer volume this year, right, it's dominated by Intel 7. And the Intel 4 and 3 wafer volumes become much more prominent next year, and that's what I was communicating on the webinar.  But as we go through the year, you're going to start to see the wafer ASPs pick up as a result of Intel 4, 3 ramping at much better ASP points, better margins associated with those, and they will become much more prominent in the foundry P&L next year. But these are production ramps that are already underway on Intel 3. The Intel 4 ramp already underway. We began that second half of last year. So these wafer ramps are underway with volume productions, volume products that we're bringing to the marketplace, very confident in our ability. And then, of course, 18A as we deliver the PDK for that in Q2, the 1.0 PDK and we'll begin the volume ramps on Clearwater Forest and Panther Lake in the first half of next year for those products coming out. So we feel very comfortable with that overall picture that we've laid out. So thank you, Joe. 
Patrick Gelsinger: Yes. Thanks, Vijay. I'm building a little bit on the last question. Granite Rapids will come in Q3 of this year when we'll have the production release of that product. Same as -- it just takes some time for customers to get comfortable, qualify, and bring those products to marketplace. But Sierra Forest, Granite Rapids, these are much more competitive power performance products on Intel 3. So we see them stabilizing and then giving us opportunity to regain share. And as we go into next year, we expect that we're regaining share as we end this year and go into next year. These are great products and we're going to be ramping them very aggressively with our customers. 
Patrick Gelsinger: Yes. And Gaudi 3 announcement this quarter, extremely well received. And as I mentioned already, 20-plus customers for Gaudi 2, 3, so we're seeing that build. Obviously, Falcon Shores will build on that momentum. We'll be bringing that late next year when Falcon Shores when we combine the great systolic performance of Gaudi 3 with a fully programmable architecture, and all of that comes together with Falcon Shores. And then we have a rich -- a very aggressive cadence of Falcon Shores products following that. We also added the Gaudi 3 PCIe card to it. This use case of Xeon plus an accelerator or Gaudi accelerator is getting very good response from customers as well. So we'll be bringing that out later this year. But the real story is delivering the TCO value, delivering the enterprise use cases. Falcon Shores will just build on the momentum that we're establishing with Gaudi 2 and 3. We also described customers coming on the Intel Developer Cloud, where we're getting these products very early in their life available for developers and enterprise customers. And customers like Zeekr, now our biggest Intel Developer Cloud win to date, are seeing the benefits. But the bigger story is how do we unleash the data assets of our enterprise customers, and that's things like the open platform for enterprise AI that we launched at Open Summit. So overall, a lot of good things happening to unleash the gen AI cycle for Intel. And of course, right, as we're doing this, AI is a hot market. We're participating across all of our segments, whether that's client, edge, enterprise or our foundry opportunities as well, delivering AI everywhere. 
Patrick Gelsinger: Well, overall, I like to say it's hard to predict, right, exactly how these will play out in light of the overall gen AI surge that we've seen. That said, products are good, right? We came into the year improving our market share position in the first quarter of the year. It does take time to ramp these new products. But better products, rebuilding trust with our customers that we're delivering on these and now hitting the, what we would call the early end of the cycles on these new products is giving us a lot of interest with the market and the customer. New use cases also demonstrated a 70 billion parameter model running natively on Granite Rapids at our Vision event, all of these just make us more and more confident in our business execution.  We're also seeing that we don't need SoC account to increase. The ASPs are going up with the core counts on our new leadership products as well. So all of those in a fairly optimistic view that we're getting from our OEMs and our channel partners for their view of upgrade cycles, building momentum from customers across the industry.  We feel very comfortable that we're stabilizing our position. We have been improving our road map, and we do expect to see share gains as we end the year and go into '25. 
Patrick Gelsinger: Yes. Thank you. And overall, as we've seen, this is a hot product. The AI PC category, and we declared this as we finished last year, and we've just been incrementing up our AI PC or the Core Ultra product volumes throughout. We're meeting our customer commitments that we've had, but they've come back and asked for upside on multiple occasions across different submarkets. And we are racing to catch up to those upside request, and the constraint has been on the back end. Wafer-level assembly, one of the new capabilities that are part of Meteor Lake and our subsequent client products. So with that, we're working to catch up and build more wafer-level assembly capacity to meet those.  How does it help us? Hey, it's a new category. And that new category of products will generally be at higher ASPs as your question suggests. But we also think it's new use cases, and new use cases over time create a larger TAM. It creates an upgrade cycle that we're seeing. It creates new applications, and we're seeing essentially every ISV AI-ing their app, whether it's the communications capabilities of Zoom and team for translation and contextualization, whether it's new security capabilities with CrowdStrike and others finding new ways to do security on the client or it's way other creators and gamers taking advantage of this.  So we see that every PC is going to become an AI PC over time. And when you have that kind of cycle underway, Srini, everybody starts to say, "Oh, how do I upgrade my platform?" And we even demonstrated how we're using AI PC in the Intel factories now to improve yields and performance inside of our own factories. And as I've described it, it's like a Centrino moment, right, where Centrino ushered in WiFi at scale. We see the AI PC ushering in these new use cases at scale, and that's going to be great for the industry. But as the unquestioned market leader, right, the leader in the category creation, we think we're going to differentially benefit from the emergence of the AI PC. 
Patrick Gelsinger: And others have commented on their inventory cycles as well in the FPGA category. We have good products in the second half of the year, with Agilex starting to ramp as well. 
Patrick Gelsinger: Yes. And also in NEX, the AI networking products are strong, our IPU products, we're seeing strength in that area. So it's inventory as well as products. Even though, as your question suggests, the communication sector and the service providers, that is weaker through the year, but pretty much every aspect of their business in edge AI, as Dave said, is seeing strength as we go into the second half of the year and into '25. 
Patrick Gelsinger: Yes. Thanks, Vivek. And we spoke at our Vision event about use cases like RAG, retrievable augmented generation, where the LLMs might run on an accelerator, but all of the real-time data, all of the databases, all of the embedding is running on the CPU. So you're seeing all of these data environments, which are already running on Xeon and x86 being augmented with AI capabilities to feed an LLM. And I believe this whole area of RAG becomes one of the primary use cases for enterprise AI. And if you think about it, an LLM might be trained with 1-, 2-year old data, right? But many of the business processes and environment are real time, right?  You're not going to be retraining constantly. And that's where this area of the front-end database becomes very prominent. All of those databases run on x86 today. All of them are being enhanced for use cases like RAG. And that's why we see this unlock occurring because the data sits on-prem, the data sits in the x86 database environments that are all being enhanced against these use cases. And as we've shown, we don't need accelerators in some cases. We can run a 70 billion parameter model natively on Xeon with extraordinary TCO value for customers. And furthermore, all of the IT environments that enterprises run today, they have the security, they have the networking, they have the management technologies in place.  They don't need to upgrade or change those from any of those use cases. So we see a lot of opportunity here to build on the enterprise asset that we have with the Xeon franchise, but we're also going to be aggressively augmenting that. And we're commonly the head node, even when it's other accelerators are being used or other GPU is being used. And as we've described, Xeon plus Gaudi, we think is going to be a very powerful opportunity for enterprises.  So in many of those cases, we see this as a market lift, new applications, new use cases, new energy coming to the enterprise AI. Here we are in year 23 of the cloud, and while 60% of the workload has moved to the cloud, over 80% of the data remains on-prem under the control of the enterprise, much of that underutilized in businesses today. That's what gen AI is going to unlock. And a lot of that is going to happen through the x86 CPU and we see a powerful cycle emerging. And I would just point you back to what we described at Vision. This was a great event and many customers are seeing that value today. 
Patrick Gelsinger: Yes. Thanks, Matt. And largely, those decisions are made when the product decisions are made. So there's limited flexibility to move them around. And if you pick a process node for a certain tile, generally, that's the process node that it's on. So there's limited flexibility there. And many of those decisions, as we've highlighted before, Matt were literally made years ago, right? And those choices were made.  That said, we see the peak of our external tiles being this year and next year. And then the road map and the movement of those coming back begins to quite accelerate, even starting late next year. So the plan is clearly laid out. As we said, we see a couple of fabs' worth of capacity coming back into the Intel factory network as we move into '26 and beyond. So this becomes a significant driver.  We've also driven significant road map decisions against that improving profile of our products. And I'll say that begins in a very powerful way next year with Panther Lake and Clearwater Forest. Unquestioned, the best products in clients, the best products in server are now being built on Intel 18A. And as the question suggests, we see customers seeing that. Every foundry customer that we speak to, right, understanding where we are in our product and process cycle and the ability for them to essentially benefit from Intel as customer 0 in the foundry network.  So overall, this is feeling very good. We're on track to go accomplish that and the business model that we've laid out and Dave and I presented as we go through the decade shows a very healthy improvement in wafer ASP, wafer volume, foundry and these decisions are made, right? We're on track to both have the wafer foundry capabilities, have the process technology and the products to fill those factories. And that's why Dave and I have such confidence in the business model that we've laid out and the improvements that it will deliver as we go over the next several years together. 
Patrick Gelsinger: Yes. Maybe 3 different points there. The first one is for inferencing, you need a whole lot less software compatibility, right? And as the market is more focused on inferencing going forward, if you can run the models, right, in the context of the databases and the other, so that portends and that's why we're seeing the strength that we're seeing right now, Matt, in these use cases. And clearly, some of the software compatibility issues of a GPU have led to the training environments that have been challenging for us. But now as customers get much more focused on enterprise use cases, inferencing TCO, we're finding a lot of strength in the offerings that we have. And as we've matured a number of customers now, we've worked through many of those use cases and getting quite a lot of acceptance of the software stack that we have with Gaudi 2 and 3.  We will have a very smooth and seamless upgrade from Gaudi 3 into Falcon Shores. But the powerful thing that will come with Falcon Shores is the full programmability that you'll see with the complete instruction set capabilities of Falcon Shores. And at that point, we will have no deficits for any of the use cases and much greater compatibility for the full range of AI capabilities.  The other thing that I emphasize is Xeon is a powerful capability with incredible programmable capabilities and we're finding these use cases like I described with the open platform for enterprise AI, RAG use cases is clearly beneficial there for us. So overall, we're feeling like the software story is coming together very nicely. And the entire industry is moving to higher level software abstraction such as Python and Triton. So they're moving away from any of these dependencies to an open software or platform. So the industry trends are in the right direction. Our maturity is in the right direction, and our software stack has gotten much more mature, and we'll have a very smooth upgrade to Falcon Shores.  So let me just close our time together and say thank you for the questions. Thanks for joining our call. We appreciate the update to give you on a very solid Q1. And we got a lot done in Q1 that gives us a great foundation for the future. We continue to drive our process and products and AI innovations and delivering on our process technology and leadership road map. If any of you were at COMPUTEX in a few months, I look forward to seeing you there. We have a number of products and offerings that we'll be announcing there as we continue our AI momentum and competitiveness. And as always, we look forward to talking to you next quarter. Thank you very much. 
David Zinsner: Yes. Good. Thanks, Ross. Maybe start with Q1 because it somewhat explains Q2. We had better sell-through of product. I hadn't even mentioned Meteor Lake strength. That better sell-through was on previously reserved material. And so we just saw some upside in gross margins because of that. We had a little bit more of a flattish plan between Q1 and Q2 in terms of how that would flow through. And so it kind of pulled some of the benefit of gross margin improvement we would have seen in Q2 and kind of pulled it into Q1. So that was part of it.  The second part is, as we talked about, this year was going to be a heavy year for start-up cost for us. And it really shows up more meaningfully in the second quarter versus the first quarter. And so that puts a little added pressure on gross margins. As you point out, the upside in the revenue, we will have good fall-through in Q3 and Q4, that will help lift the gross margins from where they are today. And then on top of that, we'll see some areas which have high gross margins, helping us like, for example, Mobileye, we get good gross margin for Mobileye and the strength that we'll see through the year there and products like that will also help drive better gross margins in the back half of the year.  As we look into '25, I think we'll have better gross margins than '25 than we had in '24. So this should be an ongoing story for us on the gross margin front. And as you know, we're driving to get to kind of mid-50s gross margins by the midpoint between now and 2030 and ultimately getting to 60%. Of course, revenue will be part of that. But a lot of that is within our control. It's things like 18A wafer pricing growing at 3x the cost of 18A that will help drive margins. The pull-in of tiles, as Pat mentioned, internally is going to drive better gross margins for us over time. All of what we're doing in terms of resegmenting new businesses to drive better decision-making, that better decision-making will translate into significant cost improvements for us, which should also be a meaningful driver for gross margins over time as well. And of course, as Pat mentioned, we're happy to get the CHIPS announcement out. And of course, that, coupled with what we expect from the EU and the investment tax credit will also be major tailwinds on gross margins over a long-term basis. 
David Zinsner: Yes. Good question. So there will be additional start-up costs next year. We do think it on a percent of revenue basis, it will be lower. So that should help lift the margins. Of course, the expectation would be we see growth in revenue. That also should help. On top of that, we already are seeing good decision-making and changing decision-making around how we operate now under this new different business structure that we have at this point. A lot of that stuff doesn't actually show up in the P&L. We have all these decisions get made this year, but a lot of the decisions made -- sorry, a lot of the benefits to those decisions don't show up until next year and the year after. So we should see some benefit from that as well.  The other thing that kind of has whipped this -- our margins around a bit over the last few years has been this notion where we reserve material all the way up until the PRQ Pat just mentioned that Sierra Forest just PRQ-ed. So ordinarily, we take a whole bunch of reserves on Sierra Forest and then we would release them as we started shipping beyond the PRQ date. We won't be doing that going forward. So that should help adjust the volatility of the gross margin. So it will be more a function of revenue growth spending profile in the fabs, start-up costs that we have and the mix. 
David Zinsner: Yes. On Altera, and this is not unprecedented when you see a massive work down of inventory, of course, that significantly impacts the revenue. But as that normalizes, then you start shipping to end consumption. So it's actually a pretty easy lift to get to the $2 billion mark once we're through the inventory digestion period. So I think we have high confidence on that. 
David Zinsner: And then on NEX, of course, that business also has gone through its own inventory adjustment. So we have good confidence around that reversing, which will help drive strength. And then some of the products that are more tailored to the AI space, of course, we'll see like, at NEX, for example, we'll see strength through the year. And so that should drive good revenue growth through the year as well. 
