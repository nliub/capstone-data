Satya Nadella: Thank you, Keith, for the question. The fundamental guidance and conversation that we have with customers is twofold. One is the easiest path to value out of generative AI is to adopt certain solutions, for example, GitHub Copilot. In some sense, it's sort of a no-brainer to add productivity leverage for all of the software developers in any organization. Whether you're a bank, you're a retailer or you're a software company, it applies to everyone. So that's probably one of the things that we have seen very good -- even productivity data and great adoption. And then obviously, the excitement that there is already around the M365 Copilot. So first thing we sort of talk about is how we ourselves are deploying all these Copilots across, whether it's Sales Copilot or M365 Copilot or GitHub Copilot, how do you get maximum value out of these horizontal tool chain? And then on top of that, we have taken what we did underneath these products and built it out as a first-class tech stack, right, which we talked at our developer conference, called the Copilot Stack, and then with Azure AI tooling, made it possible for a someone like Moody's to build their own Copilot for their people. So to us, we want to be able to help customers build their generative AI applications on top of Azure AI, and with speed, if you will. And so those are the 2 things that we ask them to identify where they can get the maximum productivity leverage. And then we even swung with our own resources to help them get those things done. And the last comment I'd make is the cloud and data in the cloud enables all this because I think the diffusion cycle here, in some sense, we have a new set of cloud meters that are getting adopted faster because of everything else that came before it in the cloud. So those would be the observations.
Satya Nadella: Sure, Brent. Thank you for the question. Yes, a couple of observations. One is, I think, overall in the cloud, you do see new project starts and then those project starts get optimized and then you sort of time-series all of that, and that's sort of what you see in the normal course. What happened here was during the pandemic, obviously, there were lots of new project starts and optimization in some sense was postponed, and that's where you're seeing, I'll call it, catch-up optimization. And that's something that, to your point, we will lap. Going into the next couple of quarters, I think, it will come down. And we are seeing new project starts, both traditional type of project starts, even cloud migrations, data applications and, of course, obviously, the AI applications. But we'll get back to I'll call the normal pace of new project starts and optimizations going forward, that we will cycle through, I think, in the next couple of quarters, what is the last catch-up optimization.
Satya Nadella: Yes. And I think just for perspective, I think it's sort of always good to think about it, right, where we have, what, 111 [bill] (ph) commercial cloud business growing at, what, 22% year-over-year. And then you had a CapEx growth, which is around the same number, 23%, 24%. So in some sense, it's sort of replacement capital plus some new capital that is going to drive new growth. So that's, I think, the scale. And we feel good about that structure of overall growth rates and how it translates into future TAM opportunity for us. And then to your other question on how all this translates into project starts effectively, the Copilot stack is available today on Azure. So we have everything from Azure AI tool chain where you can use obviously, Azure OpenAI or even you can use open models from Llama and Hugging Face models. You have all the Fabric and all of our operational data stores for what is one of the most useful patterns around generative AI as what is called Retrieval Augmented Generation, which is you take the data that you have in the data stores, use it in a prompt to generate completions, summaries, what have you. And so that's something that we've seen a lot of and the Copilots are fundamentally orchestrations of that. And so we have all of these services available. The thing that's fascinating is when you use something like Power Virtual Agent, you have a low-code, no-code tool to build effectively these AI products or full-fledged Copilots like we've built. And all the underlying primitives for that are available on Azure. The tool chain is available on Azure and the speed with which customers are able to deploy them, ISVs are able to build them, is pretty impressive.
Satya Nadella: Sure. Kash, thanks for the question. So maybe I'll start and then, Amy, you can add because I think -- we do think about what's the long-term TAM here, right? I mean this is -- you've heard me talk about this as a percentage of GDP, what's going to be tech spend? If you believe that, let's say, the 5% of GDP is going to go to 10% of GDP, maybe that gets accelerated because of the AI wave. Then the question is how much of that goes to the various parts of our Commercial Cloud and then how competitive are we in each layer, right? So if you sort of break it down, you sort of talked about how Microsoft 365, we think of this Copilot as a third pillar, right? We had the creation tools. We then had all the communication and collaboration services, and we think the AI Copilot is a third pillar. So we are excited about it. Amy talked about how we want to get it out first and part of this preview. And then in the second half of the next fiscal year, we'll start getting some of the real revenue signal from it. So we're looking forward to it. But we think of it long term as a third pillar, like we thought about something like, say, Teams or SharePoint back in the day, or what have you. Then Azure, the way I think about it is we still are, whatever, you're inning 2 or inning 3 of even the cloud migration, especially if you view it, right, whether by industry moves to the cloud, segment move to the cloud as well as country adoption of the cloud, right? So there's still early innings of the cloud migration itself. So there's a lot there still. And then on top of that, there's this complete new world of AI driving a set of new workloads. And so we think of that, again, being pretty expansive from a TAM opportunity and we'll play it out. But at the same time, we are a $111 billion commercial cloud that has grown in 20s, and so therefore, we do hit law of large numbers. But that said, we do think that this is a business that can have sustained high growth, which is something that we are excited about.
Satya Nadella: Yes. If I could just add to what Amy said, the platform effect here is really all about the extensibility of the Copilots. You see that today when people build applications in Teams that are built on Power Apps and those Power Apps happen to use something like SQL DB on Azure. That's like a classic line of business extension. So you'll see the same thing. When I have a Copilot plug-in, that plug-in uses Azure AI, Azure meters, Azure data sources, Azure semantic search. So you'll see, obviously, a pull through not only on the identity or security layer, but in the core PaaS services of Azure plus the Copilot extensibility in M365.
Satya Nadella: Yes. Judson Althoff would love you for having used his metaphor of remodeling every room of the house with AI because you're absolutely right. I mean that's the opportunity we see. I think what you're also referencing is now there's good empirical evidence and data around the GitHub Copilot and the productivity stats around it. And we're actively working on that for M365 Copilot, also for things like the role-based ones like Sales Copilot or Service Copilot. We see these business processes having very high productivity gains. And so yes, over the course of the year, we will have all of that evidence. And I think at the end of the day, as Amy referenced, every CFO and CIO is also going to take a look at this. I do think for the first time -- or rather, I do think people are going to look at how can they complement their OpEx spend with essentially these Copilots in order to drive more efficiency and, quite frankly, even reduce the burden and drudgery of work on their OpEx and their people and so on. So therefore, I think you're going to see all of that translated into productivity stats, and we're looking forward to getting that data out.
Satya Nadella: Yes. I mean the thing that we are both seeing and excited about is both the new workloads. I mean if you think about Azure, we have grown Azure over the years coming from behind. And here we are as a strong #2 in the lead when it comes to these new workloads. So for example, we are seeing new logos, customers who may have used out of the cloud for most of what they do, or for the first time, sort of starting to use Azure for some of their new AI workloads. We also have even customers who've used multiple clouds who use that for a class of sort of workloads also start new projects when it's transferred in data and AI, which they were using other clouds. So what I think you will see us is more share gains, more logo gains, reducing our CAC even. And so those are the things of points of leverage. But at the same time, we are not a small business anymore in any of these things. We're significantly -- we have significant scale. And so, yes, we celebrate. That's why we're even giving you the visibility at 1 point of it showing up this quarter, a couple of points showing up next quarter. And those are material numbers. And so that's kind of what I think will track. And I think Amy mentioned it because we want -- there are 2 parts to even AI, right? There's the models themselves with our partnership with OpenAI. That's sort of one type of spend on compute. And the other is much more revenue-driven, right, which is we will track the inference cost to the revenue and demand. And you're already seeing both of those play out.
Satya Nadella: Yes, sure. Thank you for the question. Yes, absolutely. I think having your data, in particular, in the cloud is sort of key to how you can take advantage of essentially these new AI reasoning engines to complement, I'll call it, your databases because these AI engines are not databases, but they can reason over your data and to help you then get more insights, more completions, more predictions, more summaries, and what have you. So those are the things when we say Copilot design pattern, that's sort of what that design pattern is all about. The thing that perhaps even in the last quarter, and I had that in my remarks, that's most exciting is how with Microsoft Fabric, especially for the analytics workloads, we brought together compute, storage, governance with a very disruptive business model. I mean to give you a flavor for it, right, so you have your data in an Azure data lake. You can bring SQL Compute to it. You can bring Spark to it. You can bring Azure AI or Azure OpenAI to it, right? So the fact is you have storage separated from all these compute meters, and they're all interchangeable, right? So you don't have to buy each of these separately. That's the disruptive business model. So I feel that we are well -- Microsoft is very well positioned with the way our data architecture lays out our business model around data and how people will plan to use data with AI services. So that's kind of what I mean by getting your data estate in order. And it's just not getting data estate in order but you have to have it structured such that you can have the flexibility that allows you to exercise the data and compute in combinations that makes sense for this new age.
Amy Hood: And to your question, Keith, on gross margins and how I think about those going forward, the first thing I would say is that I expect gross margins here to transition over time, just like they did in the prior cloud transitions. I would also say I expect workloads and the gross margins of the workloads to be different, just like they are in the cloud today. I would also add one thing that's different than last time, we talked a bit about this before, is that we start out in a different place with more of a shared platform, which allows us to scale those gross margins a bit faster than last time. And we do expect, as you asked and Satya talked about, the pace of this adoption curve, we do expect to be faster. So you're seeing the CapEx spend accelerate in Q4 and then again in Q1, and we've talked about what it should look like the rest of the year. Now that being said, we're talking about all that and going through that transition while delivering in FY '24 over FY '23, effectively 1 point higher operating margins. Because if it's flat year-over-year, as we guided, with the headwind from the useful life change, when you correct for that, it's about 1 point higher. So I think the real focus here is being able to be aggressive in meeting the demand curve and focusing on the transition and growth in gross margins and delivering the operating leverage.
Amy Hood: I would just add, Brent, I think to Satya's point and maybe to build a bit of a line for you, I think it felt very similar to last quarter where we made the same comments, which is we're seeing sort of the normal optimization plus we're seeing new workload starts across these workloads Satya talked about. And I think that's what we're saying going forward and really what the change is just that lapping of, I think, a bit of a catch-up from a year ago. And you're right, we'll continue to do that through H2.
Amy Hood: Why don't I start on the CapEx question, Satya, then I'll turn it over to you. Mark, really, first of all, both in Q4 and then talking about Q1, the acceleration is really quite broad. It's both on -- both the data centers and a physical basis plus CPUs and GPUs and networking equipment, think of it in a broad sense as opposed to a narrow sense. So it's overall increases of acceleration of overall capacity. And I think if you look back over really FY '23, you wouldn't have seen some of the pace on normal, what I would say, capacity adds, even for the normal Azure workload. So you're seeing both accelerations, the normal Azure workloads plus some of the AI workloads, is partially the reason. So it's why I do comment quite often that it's both overall Commercial Cloud demand and building out capacity for AI. It's both.
Amy Hood: And I think the only thing, Kash, I would add is, I think in some ways, what we're really pointing to is there's a process here. We see the demand signal is quite strong. It remains strong. I'm thrilled with all the product announcements we've made. I'm thrilled with them moving to paid preview and then moving to GA. They absolutely are expansive in terms of addressable market. They reach new budget pools is almost the way I talk about it a lot in terms of how CIOs or CFOs that I talk to think about that investment. So a growing opportunity. And as you know, we're focused on executing against that. And then revenue is an outcome. But it certainly does require -- the demand signal requires the capital expense and then creates the opportunity. And that's why I think, in some ways, we're spending a little more time talking about some of that investment is because it is the demand signal.
Amy Hood: Thanks, Karl. I think maybe I'll first start with the process we have when we release new products. And I absolutely understand we are excited, too, by the demand signal, the customer reaction, really the requests we're getting to be in the paid preview. It's all encouraging. As you know, we've -- last week, we announced pricing, then we'll continue to work through the paid preview process get good feedback. Then we'll announce the general availability date, then we'll get to the GA date. Then we'll, of course, be able to sell it and then recognize revenue. And that is why I continue to say that I am just as excited as everyone else about this, and it should be more H2 weighted. And we've, I think, given you some sizing opportunities. And I think I would use all that. But I do think this is really about pacing. And of course, we've still got to get our Security Copilot and some of the Dynamics workloads priced and released. And we'll continue to work toward that. And of course, I think one of the things that people often, I think, overlook is, and Satya mentioned it briefly when you go back to the pull on Azure, I think in many ways, lots of these AI products pull along Azure because it's not just the AI solution services that you need to build an app. And so it's less about Microsoft 365 pulling it along or any one Copilot. It's that when you're building these, it requires data and it requires the AI services. So you'll see them pull both core Azure and AI Azure along with them. And I think that's an important nuance as well.
