Jeremy Cox: The only thing I would just add to that is the supercomputing piece, specific to your question, is less than 10% in the total APU orders in FY '23. The other interesting point to add on to the journey towards inferencing that Antonio mentioned is within compute, although against a very small base, we did see non-Tier 1 customer orders around GPU or APUs for compute increased about 100% in the quarter. So again, against a small base, but an interesting point to see the focus start moving towards that realm.
Jeremy Cox: Right. Yes. We -- as Antonio mentioned, we did, as Sam mentioned, a slight growth we're expecting year-over-year on a full year basis for Edge. As I think about that, I'd almost break that down into two halves. The first-half, as we mentioned, we do still benefit from a backlog position or an order book position that will go into the first half and help support that revenue performance. And then the second half will be more dependent on demand improvements. and in the areas that Antonio mentioned and the investment areas that were helping drive that expectation. From an operating margin perspective, I would say that I would expect the first half to still benefit from higher operating margins as again, the order book consumption has been at higher price with lower cost. So that's helped drive our operating margin performance, which again this quarter at 29.5% is exceptional. But we would expect to probably more in the second-half, you'll start seeing that operating margin rate get more back towards the mid-20s that we had mentioned at SAM is our expectation for the long-term in this business.
Jeremy Cox: Toni, this is Jeremy. I'll take those two for you. So you're spot on as we think about next year, we will have a seasonal drop in HPC and AI. That's largely as Q4 really benefited from a meaningful amount of Cray Ex acceptances. And as you know, the time between order and acceptance can be a long period of time and Q4 saw a larger number of acceptances, which helped drive the revenue performance. We'll see a bit of a dip back down in Q1 and then Q2 and the second-half really benefiting from the acceleration in AI, as well as some additional supercomputing business. And so you'll see a pretty significant ramp as we go from Q1 to Q2 and then sustaining at or ramping beyond that in the second-half of the year. And HPC and AI will be a big part of the revenue growth story for FY '24. Your question on the order book total, it landed at just over $3.2 billion, which was slightly above where we landed in Q3. And that really came off the back, though of Q4 revenue performance in HPC & AI up about $350 million on a quarter-over-quarter basis. And so what happened is you had a runoff of order book from revenue performance in Q4 and then how to rebuild of that order book coming largely from AI demand in Q4 that took it back up to its historical high level of just over $3.2 billion.
Jeremy Cox: Sure. I can take that particularly towards the latter part of that. I think Antonio already hit on some of the demand dynamics, again, where we've seen three quarters of flat to increasing demand, and so some positive trends from that perspective. I think from an operating margin perspective, certainly, we saw a reduction in Q4. That was driven off a combination of several things, including a higher third-party mix that you mentioned. As well as the fact that we see -- we saw some incremental OpEx in this segment and that OpEx as a comparison to the revenue performance in the quarter also put pressure onto that operating margin. However, we do expect a pretty quick recovery there. We -- as we look into Q1, in particular, revenue is not expected to accelerate meaningfully, but we think the mix will improve as far as towards our IP product. And the -- we should see some OpEx moderation and favorability as we go into the quarter coming out of Q4 and some of the investments that we made there. And so I expect to see that get back into a low double-digit kind of area. And then as we work through the quarter, and that IP mix starts to improve more on demand acceleration, then we should start seeing us working back towards our mid-teen target that we identified at SAM for this segment.
Jeremy Cox: I'll take that. So just on the last point, no, there wasn't any meaningful AI impact, but we do expect that to be an accelerator, particularly in FY '24 as we go to Q2 and towards the second half. That will be a big part of our ARR story, and we expect that to be an accelerator for us in FY '24. On the quarter-over-quarter, this business, similar to what I mentioned on the supercomputing area does have some time between order to revenue recognition. In this case, when ARR begins to be reported. And so I think the sequential story was more about. Early in the year, we had seen more as the backlog had been burning down and some of those deals that have been waiting in the pipeline turning into -- and converting that helped drive and accelerate the ARR through the first 3 quarters. We saw a little bit less of that in Q4. But I don't think that it all as an indication of a slowdown in this space. In fact, between the 35% and 45% kind of CAGR or annual growth, I expect us in FY '24 to see the higher end of that range.
Antonio Neri: Yes. Thanks, Jeremy. And again, only 10% of the POs were consumed in Supercompute rest was all in AI. Okay, thank you, Mike.
Antonio Neri: Yes. Thanks, Wamsi. I'm going to talk about demand and then Jeremy can talk about revenue margin, which we were very clear that right, what to expect. Obviously, we have driven a significant growth over the last two years. I think it was the 12th consecutive quarter of year-over-year revenue growth. That's very impressive, we added $2 billion of revenue in the last 2 years. And obviously, that came with an expanded set of gross margins because of our software and subscription-based models that we have been driving. Traditionally, we think about that has been in the campus and branch, where in our switching or Wi-Fi. But more and more lately, obviously, it's all software-driven and as well as expansion into the new times we discussed at the Security Analyst Meeting, including SD1 and security to create the SSC framework or the SASE framework we talked about it. And going forward, we are also going to add the private 5G, which we discussed. And let's not forget, we have been also gaining momentum in the data center with our offers, which are an extension of our switching portfolio in the data center. So definitely was a quarter-over-quarter slight decline in orders for demand for products in the campus and branch, but we saw strong demand in the software in the security space. And that's why at the securities and analyst meeting with Phil, we talked about this multiple ad adjacency we have add to the platform, and they are all incorporated into the HPE Aruba Central platform, which is part of HPE GreenLake. So again, we are committed to grow revenues next year on the higher pace that we created, again, on the $5.2 billion we just delivered. Albeit you should not expect a 40% growth, obviously. And that's why I want to have Jeremy talk about what we are affirming here in terms of revenue and as well as margins.
Antonio Neri: Cannibalization. Sorry, Jeff, remind me, cannibalization. We have no evidence of that yet. I think that will become clear when the traditional compute CPU-driven returned to some normal levels. But remember, not every customer has deployed cloud across that enterprise. Still quite a bit of journey to go. And there are clear customers assessing what is the best place to deploy that, whether it's in a power cloud or whether it's repatriating on-prem because of the cost or because of data. I think AI is a huge driver of repatriation in my mind because if you have data distributed across multiple states, it's very hard to really train and fine-tune the models when you have data everywhere. And our focus there is really providing them an automated data pipeline with our unified analytics platform. So fundamentally, it's early to say. But so far, in the traditional compute business, we have not seen evidence of cannibalization at this point in time.
Antonio Neri: Yes. Thanks, Simon. Again, maybe I will elaborate a little more to the comments I made before. So we saw Q4 over Q3 and Q3 over Q2 improvement in demand in units. And a lot of that was CPU-driven. Although there is a small base of AI accelerated kind of APUs, if you will, that we saw an increase in Q4. But I will say the unit growth in Q4 was not driven by the APUs, it was driven by a combination of CPUs, the vast majority and some APUs because the base is still very, very small. So definitely, customers are preparing for that. Again, they are all assessing what is the best place to deploy this model. That's why I do believe the inferencing side will accelerate over time, where we have to do some pre-training or POCs or really deploying in production. And I think many customers also will accelerate deployments of tuning solutions on-prem because of the data aspect I talked before. No question is still digesting what they bought last time on the CPU side of the house. But again, we saw some improvements in demand sequentially in units. And then let's remind ourselves that we also, for us, in the industry. We are going to the transition of Sapphire Rapids. And ultimately, we call that the Gen 11 platform. That became now, what, Jeremy? 25% of the mix which...
Antonio Neri: 53% of the orders in Q4, 25% of the revenue mix. And so that's good for us because, obviously, it drives higher density and obviously, we can attach more options to the same platform. And customers like the sustainability piece of that and the hybrid by design nature of that, which is actually well optimized. And Gen 11, by the way, was conceived to accept any type of processing unit, whether it's a CPU, but it's an APU, including ARM-based solutions or GPU-based solutions. Whether it's in tail on the X86. So that gives us tremendous amount of flexibility. But ultimately, it's not just about the server. It's the software that comes with it. And this is where we spend a lot of time building the partnerships and relationships with NVIDIA. So now you can deploy a tuning or inferencing with the NVIDIA stack and our software as well, all part of HPE GreenLake.
Antonio Neri: I will say also, if you look at our HP Electra product, it's the fastest ramp we ever had in the history of the company. This quarter, this past quarter grew another 50%. But also there is some short-term impact because a portion of that revenue gets deferred because the subscription is softer on the platform. And so that was an intentional strategy because ultimately, the infrastructure is one piece of it, but the operating system and the cloud services that comes with it are actually a subscription to HPE GreenLake. So while we're growing 50%, we are not materializing the full revenue because a portion of that gets deferred at least to over three years. And that's good because ultimately it comes to a significant higher margins for us. But our strategy is to dramatically improve the mix to IT. And you will see more announcement this week in the storage portfolio, all geared to the AI opportunity. We file an object and that will accelerate some of the momentum we have in the storage portfolio.
Antonio Neri: Yes. I think overall it was more back ended, I would say, in the quarter, we saw strengthening as we went through the weeks. As always said, we have 13 weeks in the quarter, and we saw stronger momentum as we built along the way. And remember what we said the same, right? So as SAM as said year-to-date to October '19, I think, was the sun date. We had $3 billion in cumulative orders both between supercomputer and AI specifically and we ended the year at 3.6%. So in the last 12 days with $600 million in incremental AI orders. That tells you the strong. It was through also for compute and storage. By the way, the last few weeks, call it, three, four, five weeks were stronger than the beginning of the quarter. So I would not make much out of that. Sometimes customers take the time. We still actually live in elongated flow cycles. That's for sure. Customers taking more time to make those decisions. and ultimately issue the POs. But what really is giving me the confidence is the strong pipeline we have ahead of us. That's obvious. And clearly, in AI is significantly stronger than we ever imagined. And the only challenge we have there, then as Jeremy said, right, so it's time to revenue. We really recognize very little revenue in AI in Q4. That's why we expect the acceleration starting in Q2 and beyond as lead times improve and some of the supercomputing also gets accepted. But the reality, 2024 will be the year of AI revenue growth. And then in the edge, obviously, we have the momentum that we talked about in the subscription, the scale of our software and the incremental engines that we have. So overall, it was a typical quarter, but stronger on the back versus the front. Yes. I think we have time for one more.
Antonio Neri: No, great question. And I will say, overall, there is a lot of complementary and there are some places overlap, obviously. But with Jens and the team, we have a clear joint plan to win together in different segments of the market. But let me break it out because we talk about software in general terms, but let's start first at the infrastructure level. we have unique software that allows us to run these supercomputers and AI system, which are cloud native by nature at massive scale. Think about when you run a model you need to start and complete the mobile training. And you have to have unique technologies for checkpoints and making sure that all the compute power is acting as unified system because unlike the public cloud or the cloud, as we know it, you are multiple loads on multiple nodes. In this case, you run one world nodes on multiple nodes. And that's parallel computing as we know it. And ultimately, you need the software to run this at scale. The magic around that is that checkpoint. And then the second piece of that is our networking interconnect fabric which allows us to really connect every accelerated unit to every accelerated unit in a cohesive approach. And that's our Slingshot contingent fabric as we know it. And then on top of that, we have our machine learning development environment. This is where developers and the like use our machine learning development services. to prepare the models to automate the data pipeline. One of the biggest challenges customers have is to prepare the data, data is everywhere, but ultimate bringing in terms sort of one place so you can use data to train the models. And then with NVIDIA, we use their AI enterprise software, including some of the foundation models that they provide order to provide a complete solution. And obviously, we leverage their APUs, call it, GPUs, whether it's H-100-L40-OL4S, A100s in the past and going forward as the announcement we made a supercomputing 2023 in Denver, we are leveraging the grace over Edge 200. So it's a combination, depending on the use case. And we feel pretty good about what we're doing and stay tuned because Thursday, we're going to make further announcements about our partnership with NVIDIA. But it's RAP and IP that makes us together unique and differentiated in the AI space. Okay. Well, thank you, everyone. I will appreciate always the time. I know you're busy cover in all the earnings, but I will say just to wrap in fiscal year 2023. Clearly, we demonstrated our strategic investments and the extraordinary innovation across the growth areas of edge, hybrid cloud and even compute for the matter are really resonating with customers. and is helping us tolerate revenue growth and profit diversification. That's why you see the growth in gross margin and profit. And I believe we will continue to capitalize on this growing market opportunities. And I'm confident to continue to increase the returns to our shareholders. And that's why we are raising the dividend for 2024. So thank you for your time today. I wish you all fulfilling end of the calendar year and a special holiday season. Talk to you soon.
