Marie Myers: Yeah, sure. Good afternoon, Meta, and thanks for your question on Server margins. First of all, as I said in my prepared remarks, we did, in fact, ship about $1.3 billion of AI servers in the quarter. So that constituted around about 30% of Server revenue. And despite that, our margins were at 10.8%. And to your point, what was it driven by? So, first of all, we're well on track on the shift to Gen11, and in itself, Gen11 has richer configurations and, therefore, comes with a higher margin profile. Also, I think we've been pretty successful at passing through those commodity costs, and despite the fact that we're in a pretty competitive both CPU and GPU environment. And then lastly, I'd say you would have seen that our OpEx was down sequentially and you're seeing the impact, frankly, of that OpEx discipline show up in the margins as well, Meta.
Marie Myers: Hey, Samik, good afternoon. So, I think I've got most of your questions. I'll hit it up in terms of gross margins and what we've seen. So first of all, I would say just if you step back and think about gross margins at a high level, from a year-on-year perspective, just to remind everybody that obviously the contribution from our networking revenue is lowest. Obviously, that's impacted gross margins from a year-on-year basis. Now, when you look sequentially, as I mentioned in prepared remarks, the AI mix of servers, we converted at a much faster pace. And obviously, that's really driven margin -- gross margin in the quarter. Now, I would add to your point, we've been offsetting it with prudency on OpEx. You've seen that we're going to continue to do that. I think I mentioned that in my guide comments. And then, also, we continue to have a mindset about being very disciplined on cost and price as we pursue profitable growth. I think we talked about the fact we're selective on deals. And you see that frankly, if you look at the quality of our receivables, you'll see it in our receivables. Now, a couple of things to sort of bear in mind as we go forward. As we see enterprise AI gain momentum, that's going to have a more favorable impact on gross margins. So, we do expect that we'll see improving profitability as the market moves in that direction. And then finally, Samik, just to sort of bear in mind that we're getting closer to the close of Juniper. We expect to see that the end of calendar '24, beginning of '25. In itself, that transaction is going to have a significant impact on both gross and operating margins. And we expect that more than 50% of the company's operating profit will come from networking. So that's how I'd sort of leave it with you in terms of thinking about margins. And as we said, we'll continue to focus on managing OpEx and being very prudent on deals.
Marie Myers: Yeah, sure. No worries, Amit. And so, yeah, I think you probably are -- just in terms of where we're at in cash flow, let me hit Q3 and then I'll go into Q4. So, from a Q3 perspective, it's really driven by a couple of things. Firstly, the timing of working capital, and also just some of the normal seasonality that we see. And then, as we get into Q4, we do expect to see some of the benefits of working capital. So, we'll see a reversal in CCC, and that will benefit free cash flow. And then, obviously, we're going to see that stronger conversion of AI revenue. I think I mentioned in my prepared remarks that we're going to see a sequential improvement in the shipment of AI revenue. So, you can see that will also have an impact on our free cash flow. So, for the full year, Amit, I'd just say we are still on track for $1.9 billion. It's just as you could imagine, we're in Q3 now, we're getting into Q4, we sort of tightened up the expectations given where we're at in the year. So, still on track for $1.9 billion, Amit.
Marie Myers: Yeah. No, just, Toni, I mean, I think in terms of your comments on free cash flow, from an FY '24 perspective, I mean, in terms of bridging net earnings to free cash flow, it's the normal puts and takes for the year, so working capital, CapEx, et cetera. and sort of employee benefits. So, there is no specific charges in there in terms of our working capital -- sort of our net earnings for the year to free cash flow. In terms of '25, what we said, Toni, I think in the transaction stays the same. And look, honestly, we'll be guiding '25 when we do our next earnings call. So, I'll provide more color around free cash flow for '25 as we get into the next call.
Antonio Neri: Yeah, thanks, Mike. Yeah, listen, we are very pleased with the services attached momentum on the AI systems portion of our business, which I believe will continue to grow as we grow the enterprise segment of the market, because that segment of the market comes with more rich services day zero, day one and day two services like we call it. And yesterday was the first day it became available out of HPE Private Cloud AI, and that has quite a bit of services component with it. And so -- but right now, as we started disclosing last quarter, the services component of that which you saw in one of the slides, as Marie was providing her remarks, much of that is pretty much all deferred. So, unless we are doing an installation and that gets recognized immediately, most of that is the maintenance that gets recognized over the length of the contract. And therefore, over time, we expect that will be contributing positive to our gross margins in the segment that we recognize that revenue, which obviously is the Server segment of the market. So, yes, but I'm positive on both gross margin accretion as we recognize the revenue and more services as we start selling the HPE Private Cloud in the enterprise space.
Antonio Neri: Yeah. Thank you, Simon. We have seen no signs of cannibalization into the traditional server market. And remember, I always try to bring a segment point of view, right? So, the segment point of view in the AI space, you have three segments. You have the service providers, model builders, which obviously include the hyperscalers, and there we have not sold traditional servers in a long time once we made the decision in 2017 to not participate in that market. And then, you have the sovereign space, which is now going up in term of interest, but the sales cycles are longer because of the government engagements and the procurement, but there, generally speaking, there is no traditional service per se. It's a combination of architectures and GPUs and CPUs in a unique form factor. And then last but not least, we have the enterprise. And the enterprise, while it's growing, has been very much focused on the AI applications. And for customers to move a traditional workload, call it, legacy workloads and the like, to a accelerated compute, the question is why you will do that when, A, you need to use the accelerated compute to either fine-tune the model or to do inferencing; and second, from a PCO perspective, there is no clear view that, that will be cost less. And so that's why when I think about workloads and customer segments, we don't see signs of cannibalization from the AI deployments into the traditional workloads.
Antonio Neri: Yeah. So, first of all, the pipeline we have in front of us is multiples of the current backlog, which is a positive news, because that tells you the momentum will continue in the next few quarters. Second is that the backlog composition, as I said, in the mid-teens is the enterprise space and the rest is the traditional service provider space. On the service provider space is basically compute capacity to train models or to do hosting for that matter, in large colos. And then, on the enterprise space is really focused on the use cases where they see clear line of sight for the return on that investment, and there are several use cases by segment that customers by verticals that they are driving. Obviously, many of them are very obvious. And now we are seeing a little bit more sophistication in some of those use cases and the maturity of. And that's why our Private Cloud AI offering is targeting those type of customers, because ultimately comes with entire stack from the, what I call, the workloads at the top, specifically designed for the verticals, down into the training models, all the way down to the infrastructure. They are sized for that type of deployment. And then, on the sovereign AI, obviously, we see now a significant interest. We are working across multiple geos on several opportunities. A lot of them are basically to open AI clouds for sovereign reasons or privates and compliance reasons on data. And a lot of them actually want to look a little bit like supercomputers in many ways because many of those systems are designed to do both AI large language models, and that's very obvious with some of the deployments we have done in the European Union and the one we're going to do now for the U.K. And other ones are basically for traditional supercomputing. So, the infrastructure in the end is the same. All of these systems are very much liquid cooled systems. And so, that's an opportunity for us. But on the enterprise side, I think you can see now expansion from traditional bots and customer service into other areas in finance, manufacturing, marketing, where they can see the clear return on that investment. And we're helping them even upfront through a partner ecosystem to define those use cases, because ultimately, it goes beyond just deploying IT, but they're really to realize the business value.
Antonio Neri: Well, I think right now, one of the key sweet spots is we now have to build and deploy and run these large systems. That requires a unique expertise. That's why you see the services portion being attached to those assistants. And ultimately, you need expertise both in the manufacturing space. And again, we're going to host our AI Day in one of, what I believe is, the largest footprints in the world where you can see how this gets done. And then, on the services side, you should not underestimate the services expertise needed to run. But for enterprise, where is the next big thing is -- in my view, is all about the simplicity. And several of the patterns we are actually filing and getting done are actually in areas like ease of use, automation, obviously, security. These are all spaces where we are actually building all those capabilities in our offer. And remember, all of this gets built inside HPE GreenLake as we deploy these optimized infrastructure and configurations. And that's why for me, GreenLake is an important component of our AI strategy, because ultimately, we manage a lot of the deployment on-prem through enterprise customers, specifically, through HPE GreenLake. And that's an accelerator and a way to upsell, cross-sell, build, ultimately, customers' confidence and control of the data, which is the fundamental value when it comes down to AI. And then, next year, once we close the Juniper transaction, we're going to add another key component, which is the networking piece. And it's very important that we recognize that AI, A, is a hybrid workload. The core foundation of that across hybrid is the network. And HPE will have unique IP and capabilities in that space in addition to the traditional server storage, which is now certified for AI, and then the GreenLake software and services attached to it. And that's how I want to think about it. Independent businesses are all accretive to AI, but then when we get to a solution, HPE will have the full-stack solution to offer to our enterprise customers.
Antonio Neri: Yeah, no, thank you very much for the time. Again, I will say we delivered a strong quarter. We drove very strong revenue growth. We said what -- we did what we said. And honestly, I'm very confident about the next quarter and what comes next after the Juniper acquisition. I'm super-pleased that we also closed the first tranche of our H3C put option. Obviously, that took a lot of work in an environment that's complex. And as you think about our ability to deliver profitable growth is there. I understand the questions around margins, but when I think about margins, on the server side, we are consistently driving a stable around 11% or so operating margins. We think about that way more than gross margin because ultimately it's all about cash. And then, ultimately, on the networking and hybrid cloud is about both gross margin, because of our content is more software and services, while we'll deliver on the bottom-line. So, I think our strategy all coming together, but it's very competitive dynamic there and we have to execute every day with discipline, which is what we did again this quarter. And again, we raised guidance for the full year on the EPS side of the house. So, thank you very much for your time. And I look forward to hosting some of you at our facility in Wisconsin on October 10.
