Hock Tan: Yeah. Well, as we indicated in the last earnings call, for this past quarter, I think we're talking about two-thirds in compute and one-third in networking. And we kind of expect Q4 to run the similar trend. And as far to answer your second part, no, we don't guide – yet for fiscal ‘25, but we do expect fiscal ‘25 to continue to be strong, to show strong growth on our AI revenue.
Hock Tan: Okay. Well, it's an interesting question in terms of the shift. But see, we do not focus very much on enterprise AI market as you know well. Our products in AI are largely, very much largely focused, especially on the AI accelerator or XPU side, but even -- also just as much on networking side, on hyperscalers, on cloud, those three large platform and some digital natives, what you call, big guys. We don’t deal very much on AI with enterprise. So we obviously don’t see that trend.
Hock Tan: Well, as far as we indicated, the VMware business continues to book very well, as we convert our customers very much in two ways, one, from perpetual to a subscription license, but also those subscription license for the full stack of VCF. And that has been very successful, as I indicated, given the high ratio of VCF subscribers, new subscribers that we have achieved. And we see this trend continuing in Q4 very much so and also very likely through into '25. So in terms of directional trend, other than the indication I’m giving you – than the guidance I’m giving you in Q4 ‘24, directionally, we continue to see accelerated bookings and by extension, accelerated growth.
Hock Tan: Yeah. On the semi side, the answer is very simple. We have -- as you all know, we've gone through your typical down cycle of semiconductors. And I'm referring particularly to non-AI, and we have talked about that before many times. We've gone through a down cycle. And as the ecosystem as many of our customers, but the broad ecosystems work on an adjustment in inventory levels in all stages in the supply chain. And we're not totally -- we are not immune from it, obviously, as we try to insulate ourselves from it as much as possible. We've gone through it and our -- the signs on the indications we have seen very clearly is we have, in fact, passed through the bottom. The best indicator is the bookings we are receiving. In non-AI, our bookings in Q3 of non-AI semiconductor demand is up 20%. And so also this -- we are well on the way to recovery. Now by end markets, as I indicated, the level of the amount of recovery, the timing of recovery somewhat varies. But we're seeing largely on enterprise, enterprise data center, enterprise IT spending, we've passed the bottom. And we are, in Q3 was, in fact, sequentially, a recovery from the bottom of, we believe Q2 or Q1 this fiscal year. And we'll see Q4 continuing that recovery and obviously, in our view, into '25 in terms of the cycle. Broadband, we are not seeing it yet in terms of the bottom, but we see that as close to bottom in the sense that here again, bookings are up from where it used to be. And so we are very, very clear in our thinking that broadly, we have, as a whole, non-AI semiconductors, we've gone through the down cycle is on an uptick. And like, all previous cycles, my sense, Stacy, is we will get us back to the level we used to be. There's no reason at all why it doesn't and given the rate of bookings, it won’t go. I dare say even put a thought in your mind that as AI permeates enterprises all across and digital natives, you need to upgrade servers. You need to upgrade storage. You need to upgrade networking, connectivity across the entire ecosystem. And if anything else, we are headed -- we could be headed for up cycle. Timing precisely when, we’re not sure. But an up cycle, that could even meet or even surpass what our previous up cycles would be, simply because the amount of bandwidth you need, the amount of compete -- to manage store, manage all these workloads that come out of AI would just put -- need to refresh and upgrade hardware. So that’s my $0.02 worth on where we’re headed from this down cycle. So my belief in ‘24 was the lowest point for the uptick. As part of the reasons we are stating it very clearly here. On the software side, your question, no, I think we have reached a level of stability that puts and takes Brocade, one of those goes up and down very volatile, and that’s largely. But on the non-Vmware revenue, on software revenue, I think we’ve reached a level of very clear stability. And what we are looking towards more is how Vmware picks up over the next several a year and 1.5 years.
Hock Tan: Well, our number in third quarter is pretty much in line what we expect AI revenue to be. And our revenue in Q4 was -- forecast for Q4 is what's giving us the basis to a large extent to step up our guidance for AI revenue for the full year to over $12 billion. So if nothing else, that continues to indicate, I hope to us, that next year the trend will continue to be strong. And again, it's all largely hyperscalers, cloud, and digital natives. And it's again, a mix of AI accelerators and networking. And it's also largely based on backlog we have in place for that. Beyond that -- and it shows the growth. Beyond that, no, we're not guiding you beyond the backlog we have. So I kind of answer your question indirectly on, do I have any more customers? We shall see.
Hock Tan: That's a very difficult question for me to answer because it comes in two parts, right? In terms of GPU growth, you should ask the guys who does merchant GPU or GPU which is obviously, NVIDIA and ASD. And I don't see -- I don't play in the enterprise market at all. See, that's part of the market I don't see. Having said that, they do both play somewhat in the hyperscalers, where I'm totally focused on doing. So that's really very -- there's really no connection one with the other, that is indirect. But enough suffice for me to say long term, I’m saying actually and thoughtfully long term, the large hyperscalers, few and large hyperscalers with very large platforms, huge consumer platform subscriber base have the entire model predicated on running a lot of large language models, a lot of AI requirements, workloads out there. And it will drive, matter of time, towards creating as much as possible their own compute silicon, their own custom accelerators as a matter of time. And we are in the midst of seeing that transition, which may take several – a few years for that to happen. So that is on a different trajectory, a different path, and I’m in that path of doing this, enabling custom accelerators. I’m in that that. I’m not in a path of, in the meantime, a different trajectory of enabling enterprises to do AI on their own workloads. That’s more the merchant guys. Some of the merchant guys obviously also in the – in the hyperscaler today, but there’s a process, obviously, of a transition going on. So one doesn’t really connect with the other theme in that regard. But I would likely say obviously, as the transition occurs, we have a good tailwind in the business model we have of providing accelerators and networking to the AI data centers of those large hyperscalers.
Hock Tan: Well, it's, for us, software gross margin is actually direct, it's not that relevant. You know that, right? So unless I'm running SaaS big time, now a lot of our products on subscription but they're not SaaS. We have some products on SaaS cloud-based, but most of them are not. And our gross margin will be around 90% at least.
Hock Tan: Well, I know we're dancing around the thing, as I indicated, with three customers now going on and they're all three of them are meaningful. Otherwise, we won't call them customers as the criteria we've used. Until we get meaningful shipments out to them on AI accelerators, we do not really consider that as a customer. Simply because it's a new -- this is an emerging trend. It's not an easy product to deploy for any customer. And so we do not consider proof of concepts as production volume. These are all production accelerators deployed in AI data centers of those three customers.
Hock Tan: Well, this is more of a partnership than anything else. Basically, it's what we essentially created in that transaction was to begin with, we actually believe long term in the sustainability of hard disk drive media as a great long-term sustainable storage, alternative storage or medium for those hyperscalers. It makes sense. One way to think eventually, everything goes to flash, don't think so. Hard disk drive storage will still be meaningful. And the technology, which is most interesting for us, has a lot of ways to go. As hard disk goes on to -- from where it is today, which is 22, 23, 24 terabytes to going to 30, 40, and even 50 terabytes. A lot of technology along the way and one -- and a lot of that resides in silicon. So what we're doing, in effect, is a collaboration more than anything else, though structured, obviously, as a purchase of intellectual property. But we're also taking engineers, designers, combining it with the designers we have and basically enabling Seagate and eventually the entire industry to continue a road map that goes towards 50 terabytes. That's our ambition, that's our vision, and to be able to do that within 5 years or less. So that's pretty much what it is. It's a statement of our belief that hard disk drives, hard disk drive storage will sustain very well over the next five years, if not longer.
Hock Tan: Joe, that's a beautiful question. I'll tell it is bluntly so they're not disappointed. Right now, I'm having my hands really full and enjoying myself doing is on really turning, transforming the business model of VMware. It's a great experience and you're feeling great about it when you do and when you're doing it pretty much running way beyond expectation as we indicated in that side. So no, I'm very focused on getting VMware continue -- as it continues to accelerate in getting private cloud deployed in the largest enterprises in the world. And you know what, might another year, two years to go to make that transformation totally complete.
Hock Tan: Yeah. We continue to see orders. We continue to see upside. And you're right in the pattern of that behavior that is going because it's -- as our customers, these are hyperscalers trying to deploy more and more capacity of AI data centers -- in AI data centers. And you start to hear them talk in terms of power. They don't even talk in terms of how many XPU or GPU plus they found in the 500 megawatt, 1 gigawatt was no but people that. So we are as they get this enable, we're getting, we're getting upsides. And I expect that to happen a lot more in 2025. We're not putting that in any guidance or indication we're giving you. But I what you say is exactly right on. We do expect to see upside as we've been seeing recently. We continue to see that probably going forward over the next 12 months, especially related to XPUs getting deployed and getting infrastructure available and rushing to deploy them. We see quite a bit of that.
Hock Tan: You're right, and you're correct in pointing out to me that, hey, I used to think that general purpose merchant silicon will win at the end of the day. Well, based on history of semiconductors mostly so far, general purpose, small merchant silicon tends to win. But like you, I flipped in my view. And I did that, by the way, last quarter, maybe even 6 months ago. But nonetheless, catching up is good. And I actually think so because I do think there are two markets here on AI accelerators. There's 1 market for enterprises of the world, and none of these enterprises are incapable nor have the financial resources or interest to create the silicon, the custom silicon, nor the large language models or the software and going maybe to be able to run those AI workloads on custom silicon. It's too much and there's no return for them to do it because it's just too expensive to do it. But there are those few cloud guys, hyperscalers with the scale of the platform and the financial wherewithal for them to make it probably rational, economically rational, to create their own custom accelerators because it's all -- right now, not going to -- not trying to emphasize it, it's all about compute engines. It's all about especially training those large language models and enabling it on your platform. It's all about constraint, to a large part, about GPUs. Seriously, it came to a point where GPUs are more important than engineers, these hyperscalers in terms of how they think. Those GPUs are much more -- XPUs are much more important. And if that's the case, what better thing to do than bringing the control and the control of their own destiny by creating your own custom silicon accelerators. And that's what I'm seeing all of them do. It's just doing it at different rates and do -- and they're starting at different times but they all have started. And obviously, it takes time to get there. But they're all -- a lot of them, there are a lot of learning in the process versus what the biggest guy of them who had longer have been doing for seven years. Others are trying to catch up and it takes time. I'm not saying you'll take seven years. I think you'll be accelerated, but it will still take some time step by the time to get there. But those few hyperscalers, platform guys will create their own if they haven't already done it and start to train them on the large language models. And that is, yes, you're right, they will on go in that direction totally into ASIC or, as we call it, XPUs, custom silicon. Meanwhile, there's still a market for in enterprise for merchant silicon.
Hock Tan: It's an accelerating curve. It may take longer than we all want it to happen but definitely accelerating because the size of those -- and the size of the demand from those hyperscalers will totally rival that in the enterprise.
