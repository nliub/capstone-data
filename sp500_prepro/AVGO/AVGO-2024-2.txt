Hock Tan: Thank you, Ji. And thank you everyone for joining today. In our fiscal Q2 2024 results -- consolidated net revenue was $12.5 billion, up 43% year-on-year as revenue included a full quarter of contribution from VMware. But if we exclude VMware, consolidated revenue was up 12% year-on-year. And this 12% organic growth in revenue was largely driven by AI revenue, which stepped up 280% year-on-year to $3.1 billion, more than offsetting continued cyclical weakness in semiconductor revenue from enterprises and telcos. Let me now give you more color on our two reporting segments. Beginning with software. In Q2 infrastructure software segment revenue of $5.3 billion was up 175% year-on-year and included $2.7 billion in revenue contribution from VMware, up from $2.1 billion in the prior quarter. The integration of VMware is going very well. Since we acquired VMware, we have modernized the product SKUs from over 8,000 disparate SKUs to four core product offerings and simplified the go-to-market flow, eliminating a huge amount of channel conflicts. We are making good progress in transitioning all VMware products to a subscription licensing model. And since closing the deal, we have actually signed up close to 3,000 of our largest 10,000 customers to enable them to build a self-service virtual private cloud on-prem. Each of these customers typically sign up to a multi-year contract, which we normalize into an annual measure known as Annualized Booking Value, or ABV. This metric, ABV for VMware products, accelerated from $1.2 billion in Q1 to $1.9 billion in Q2. By reference, for the consolidated Broadcom software portfolio, ABV grew from $1.9 billion in Q1 to $2.8 billion over the same period in Q2. Meanwhile, we have integrated SG&A across the entire platform and eliminated redundant functions. Year-to-date, we have incurred about $2 billion of restructuring and integration costs and drove our spending run rate at VMware to $1.6 billion this quarter, from what used to be $2.3 billion per quarter pre-acquisition. We expect spending will continue to decline towards a $1.3 billion run rate exiting Q4, better than our previous $1.4 billion plan, and will likely stabilize at $1.2 billion post-integration. VMware revenue in Q1 was $2.1 billion, grew to $2.7 billion in Q2, and will accelerate towards a $4 billion per quarter run rate. We therefore expect operating margins for VMware to begin to converge towards that of classic Broadcom software by fiscal 2025. Turning to semiconductors, Let me give you more color by end markets. Networking. Q2 revenue of $3.8 billion grew 44% year-on-year, representing 53% of semiconductor revenue. This was again driven by strong demand from hyperscalers for both AI networking and custom accelerators. It's interesting to note that as AI data center clusters continue to deploy, our revenue mix has been shifting towards an increasing proportion of networking. We doubled the number of switches we sold year-on-year, particularly the PAM-5 and Jericho3, which we deployed successfully in close collaboration with partners like Arista Networks, Dell, Juniper, and Supermicro. Additionally, we also double our shipments of PCI Express switches and NICs in the AI backend fabric. We're leading the rapid transition of optical interconnects in AI data centers to 800 gigabit bandwidth, which is driving accelerated growth for our DSPs, optical lasers, and PIN diodes. And we are not standing still. Together with these same partners, we are developing the next generation switches, DSP, and optics that will drive the ecosystem towards 1.6 terabit connectivity to scale out larger AI accelerated clusters.
Hock Tan: Very interesting question, Vivek. On AI accelerators, I think we are operating on a different -- to start with scale, much as a different model. It is -- and on the GPUs, which are the AI accelerator of choice on merchant -- in a merchant environment is something that is extremely powerful as a model. It's something that NVIDIA operates in, in a very, very effective manner. We don't even think about competing against them in that space, not in the least. That's where they're very good at and we know where we stand with respect to that. Now what we do for very selected or selective hyperscalers is, if there's a scale and the skills to try to create silicon solutions, which are AI accelerators to do particular very complex AI workloads. We are happy to use our IP portfolio to create those custom ASIC AI accelerator. So I do not see them as truly competing against each other. And far for me to say I'm trying to position myself to be a competitor on basically GPUs in this market. We're not. We are not a competitor to them. We don't try to be, either. Now on networking, maybe that's different. But again people may be approaching and they may be approaching it from a different angle. We are as I indicated all along, very deep in Ethernet as we've been doing Ethernet for over 25 years, Ethernet networking. And we've gone through a lot of market transitions, and we have captured a lot of market transitions from cloud-scale networking to routing and now AI. So it is a natural extension for us to go into AI. We also recognize that being the AI compute engine of choice in merchants in the ecosystem, which is GPUs, that they are trying to create a platform that is probably end-to-end very integrated. We take the approach that we don't do those GPUs, but we enable the GPUs to work very well. So if anything else, we supplement and hopefully complement those GPUs with customers who are building bigger and bigger GPU clusters.
Hock Tan: Well, to answer your question on the mix, you are right. It's something we don’t really predict very well, not understand completely except in hindsight. Because it's like, to some extent, to the cadence of deployment of when they put in the AI accelerators versus when they put in the infrastructure that puts it together, the networking. And we don't really quite understand it 100%. All we know, it used to be 80% accelerators, 20% networking. It's now running closer to two-thirds accelerators, one-thirds networking and we'll probably head towards 60%-40% by the close of the year.
Hock Tan: Because I guided just over $11 billion, Stacy could be what you think it is. It's -- quarterly shipments get sometimes very lumpy. And it depends on rate of deployment, depends on a lot of things. So you may be right. You may estimate it better than I do, but the general trajectory is getting better.
Hock Tan: Harlan, you're pretty insightful there. Yes, we launched Tomahawk 5 in 2023. So you're right, by late 2025, the time we should be coming out with Tomahawk 6, which is the 100 terabit switch, yes.
Hock Tan: Well, you know what, sometimes you have to let things take its time. But it's two-year cadence so we're right on. Late 2023, once when we shoot it out to a Tomahawk 5 and adoption. You're correct with AI has been tremendous because it ties in with the need for a very large bandwidth in the networking, in the fabric for AI clusters, AI data centers. But regardless, we have always targeted Tomahawk 6 to be out two years after that, which should put it into late '25.
Hock Tan: Thanks, and thanks for your kind regards on the quarter. But it's -- as far as VMware is concerned, we're making good progress. The journey is not over by any means, but it is pretty much very much to expectation. Moving to subscription, well, in VMware we are very slow compared to, I mean a lot of other guys, Microsoft, Salesforce, Oracle, who have already been pretty much in subscription. So VMware is late in that process. But we're trying to make up for it by offering it and offering it in a very, very compelling manner because subscription is the right things to do, right? It's a situation where you put out your product offering, and you update it, patch it, but update it feature-wise, everything as capabilities on a continual basis, almost like getting your news on an ongoing basis, subscription online versus getting it in a printed manner once a week. That's how I compare perpetual to subscription. So it is very interesting for a lot of people to want to can't get on. And so to no surprise, they are getting on very well. The big selling point we have as I indicated, is the fact that we are not just trying to keep customers kind of stuck on just server or compute virtualization. That's a great product, great technology, but it's been out for 20 years. Based on what we are offering now at a very compelling price point, compelling in a very attractive price point, the whole stack, software stack to use vSphere and its basic fundamental technology to virtualize networking, storage, operation and management, the entire data center and create this self-service private cloud. And thanks for saying it, you're right, and we have priced it down to the point where it is comparable with just compute virtualization. So yes, that is getting a lot of interest, a lot of attention from the customers. We have signed up who would like to deploy -- the ability to deploy private cloud, their own private cloud on-prem. As a nice complement, maybe even alternative or hybrid to public clouds, that's the selling point, and we are getting a lot of interest from our customers in doing that.
Hock Tan: Well, I didn't give a specific time frame, did I? But it's on track as we see this process growing towards a $4 billion quarter.
Hock Tan: Interesting question. And you're right. As I indicated in my remarks, even we found the contribution from VMware this past quarter where we have AI helping us, but we have non-AI semiconductor sort of bottoming out. We're able to show 12% organic growth year-on-year. So almost have to say, so do we need to rush to buy another company? Answer is no. But all options are always open because we are trying to create the best value for our shareholders who have entrusted us with the capital to do that. So I would not discount that alternative because our strategy, our long-term model has always been to grow through a combination of acquisition, but also on the assets we acquire to really improve, invest, and operate them better to show organic growth as well. But again, organic growth often enough is determined very much by how fast your market would grow. So we do look towards acquisitions now and then.
Hock Tan: We see it behaving. I didn't particularly call it out, obviously because more than anything else, I kind of link it very much to server storage, non-AI that is. And we call server storage as at a bottom Q2, and we call it to recover modestly second half of the year. We see the same thing in networking, which is a combination of enterprise networking, as well as the hyperscalers who run their traditional workloads on those, though it's hard to figure out sometimes. But it is. So we see the same trajectory as we are calling out on server storage.
Hock Tan: There is, but it's so complex, I stopped creating such a model, Tim. I've said it. But there is because one would say that for every -- you almost say, for every $1 billion you spend on GPU, you probably would spend probably on networking, and if we include the optical interconnects as part of it, though we are not totally in that market, except for the components like DSPs, lasers, PIN diodes that go into those, high-bandwidth optical connect. But if you just take optical connects in totality, switching, all the networking components, it goes into -- attaches itself to clustering a bunch of GPUs, you probably would say that about 25% of the value of the GPU goes to networking, the rest on networking. Now not entirely all of it is my available market. I don't do the optical connects, but I do the few components I talked about in it. But roughly, the simple way to look at it is probably about 25%, maybe 30% of all these infrastructure components is kind of attached to the GPU value point itself. But having said that, it's never – we are never that precise that deployment is the same way. So you may see the deployment of GPU or purchase of GPU much earlier. And the networking comes later or sometimes less the other way around, which is why you're seeing the mix going on within my AI revenue mix. But typically, you run towards that range over time.
Hock Tan: Let me take the second part first, which is our AI -- custom AI accelerator business. It is a very profitable business, and let me put to scale -- look examine from a model point of view. I mean, each of these AI accelerators no different from a GPU. The way these large language models get run computing, get run on these accelerators, no one single accelerator, as you know, can run these big large language models. You need multiple of it no matter how powerful those accelerators are. But also, and the way the models are run, there is a lot of memory access to memory requirements. So each of this accelerator comes with a large amount of cache memory, as you call it, what you guys probably now know as HBM, high-bandwidth memory specialized for AI accelerators or GPUs. So we're supplying both in our custom business. And the logic side of it, where the compute function is on doing the chips, the margin there are no different than the margin in any -- in most of any of a semiconductor silicon chip business. But when you're attached to it, a huge amount of memory, memory comes from a third-party. There are a few memory makers who make this specialized thing. We don't do margin stacking on that part. So by almost buying basic math will dilute the margin of these AI accelerators when you sell them with memory, which we do. It does push up revenue somewhat higher but it has diluted the margin. But regardless, the spend, the R&D, the OpEx that goes to support this as a percent of the revenue, which is higher revenue, so much less. So on an operating margin level, this is easily as profitable, if not more profitable, given the scale that each of those custom AI accelerators can go up to. It's even better than our normal operating margin scale. So that's the return on investment that attracts and keeps us going at this game. And this is more than a game. It is a very difficult business. And to answer your first question, there is only one Broadcom, period.
Hock Tan: Well, on the second one, I don't know about any crowding out, to be honest. It's not. What we are offering, obviously, is not something that they would like to use themselves, to be able to do themselves, which is they're already spending on building their own on-prem data centers. And typical approach people take, a lot of enterprises take historically continue today than most people do a lot, people do is they have best of breed. What I mean is they create a data center that is compute as a separate category, best compute there is and they often enough use vSphere for compute virtualization due to improved productivity, but best of breed there. And best of breed on networking and best of breed on storage with a common management operations layer, which very often is also VMware we realize. And what we're trying to say is this mixed bag, and what they see -- is this mixed bag best of [big] (ph) data center, very heterogenous, is not driving that, is not a highly resilient data center. I mean, you have a mixed bag. So it goes down. Where do you find quickly root cause? Everybody is pointing fingers at the other. So you got a problem, not very resilient and not necessary secure between bare metal in one side and software on the other side. So it's a natural thinking on the part of many CIOs we talk to, to say, hey, I want to create one common platform as opposed to just [best-of-breed of age] (ph). So that gets us into that. So it is a greenfield that’s not bad, they started from scratch. If it's a brownfield, that means they have existing data centers trying to upgrade. It's -- that sometimes that's more challenging for us to get that adopted. So I'm not sure there's a crowding out here. There's some competition, obviously, on greenfield, where they can spend their budget on an entire platform versus best-of-breed. But on the existing data center where you're trying to upgrade, that's a trickier thing to do. And it cuts the other way as well for us. So that's how I see it. So in that sense, best answer is I don't think we're seeing a level of crowding out that is -- any and that very significant for me to mention. In terms of the revenue mix, no, Brocade is having a great, great field year so far and still chugging along. But will that sustain? Hell no, you know that. Brocade goes through cycles like most enterprise purchases. So we're enjoying it while it lasts.
Hock Tan: Yes, thank you. That's a great question. Yes, VMware taught me a few things. They have 300,000 customers, 300,000. That's pretty amazing. And we look at it. I know under CA, we took a position that let's pick an A-list strategic guy and focus on it. I can't do that in VMware. I approached it differently. And I start to learn the value of a very strong bunch of partners they have, which are a network of distributors and something like 15,000 VARs, value-added resales supported with these distributors. So we have doubled down and invested in this resale network in a big way for VMware. It's a great move, I think but six months into the game. But we are seeing a lot more velocity out of it. Now these resellers, having said that, tend to be very focused on a very long tail of their 300,000 customers. The largest 10,000 customers of VMware are large enterprises who tend to -- they are very large enterprises, the largest banks, the largest health care companies. And their view is I want very bespoke service, support, engineering solutions from us. So we've created a direct approach, supplemented with the VAR of choice where they need to. But on the long tail of 300,000 customers, they get a lot of services from the resellers, value-added resellers, and so in their way. So we now strengthen that whole network of resellers so that they can go direct, manage, supported financially with distributors. And we don't try to challenge those guys unless the customers. On the end of the day, the customer chose where they like to be supported. So we kind of simplify this together with the number of SKUs they have. In the past, unlike what we're trying to do here, everybody is a partner. I mean, you're talking a full range of partners. And whoever makes the biggest deal gets the lowest. The partner that makes the biggest deal gets the lower -- biggest discount, lowest price. And they are out there basically kind of creating a lot of channel chaos and conflict in the marketplace. Here, we don't. The customers, I am aware. They can take it direct from VMware to their direct sales force or they can easily move to the resellers to get it that way. And as a third alternative which we offer, if they chose not -- they want to run their applications on VMware and they want to run it efficiently on a full stack. They have a choice now of going to a hosted environment managed by network of managed service providers, which we set up globally, that will run the infrastructure, invest and operate the infrastructure. And these enterprise customers just run their workloads in and get it as a service, basically VMware as a service. That's a third alternative, and we are clear to make it very distinct and differentiated for our end-use customers. They're available to all three is how they choose to consume our technology.
