Greg Smith: Thank you, Traci. Good morning, everyone, and thanks for joining us. Today, I will summarize our second quarter results and discuss the trends we are seeing in the semiconductor and Advanced Robotics industries. Then Sanjay will go into more depth about our second quarter results and forward looking guidance. At a high level the market dynamics that we identified in our April earnings call have continued through the second quarter. Cloud AI is driving strong demand across the SoC and memory test markets. We have accelerated engineering and sales investments to continue to improve our market position, drive share and increase our ability to deliver long-term sustainable growth. Outside of compute and memory, all other major test markets, including mobile, continue to be soft. Robotics has delivered on-plan results in a weak macro environment and we continue to expect incremental growth each quarter of this year. Focusing in on Q2, we delivered second quarter financial results above our revenue, gross margin and earnings guidance ranges. Memory and SoC delivered above our plan and showed strong performance in the quarter, primarily driven by AI applications. Continuing the trend we noted in the first quarter, Cloud AI demand drove compute revenue with considerable strength in networking devices. AI enabled data centers have a very high number of network connection points to support training large language models, which is changing the mix in this segment to include more networking silicon. Our historic strength in networking combined with shipments to support a vertically integrated producer or VIP resulted in compute revenue in the first half of 2024, exceeding all of our compute revenue in 2023. We currently expect that Teradyne's SoC revenue from the compute end market will be on par with mobile revenue this year. In memory AI driven HBM DRAM demand remains strong. We are now seeing AI driven servers pulling demand across a broader range of memory, including enterprise SSD NAND flash. We are also seeing memory demand for the mobile market with strength in LPDDR and continuing retooling to support the latest protocol based mobile flash memory technologies. As a result, our memory business has grown nearly 30% in the first half of 2024 compared to the first half of 2023. While we are not changing our estimated memory tam expectation for the year, we expect that the market is trending towards the upper end of our $1.2 billion to $1.3 billion forecast. Moving on to Q3, the positive impact of AI on test is expected to continue into the third quarter. However, a meaningful uptick in other end markets, including legacy auto and industrial, may not occur until the 2025 timeframe. As a result, at the company level for the full year, we continue to expect low single digit revenue growth from 2023. As a reminder, excluding the impact of the sale of DIS to Technoprobe, our 2024 revenue growth would have been a couple of percentage points higher. Now, turning to Robotics, despite a weak macro environment, our Advanced Robotics business grew sequentially from Q1 to Q2. Looking at the first half of 2024, we grew 11% compared to the first half of 2023. We estimate that traditional players in the automation space have seen sales actually decline in the range of 5% to 7% over the same period. We are executing a three-pronged growth strategy for our Advanced Robotics business; SAM expansion, channel transformation and recurring services and software. In the second quarter, we have made progress in all three areas.
Greg Smith: Hey CJ, this is Greg. Basically, we are pretty bullish on 2025. The Semi Test market in 2024, we're seeing strength in computing and we're also seeing fair amount of upgrade business where people are converting testers that were underutilized in mobile to use for compute and VIP applications, so that's soaking up some of the excess in that market. We expect that to really sort of accelerate business. As mobile returns in 2025, it won't have that capacity to grow into. On HBM, I think we continue to expect that we are going to make progress in two directions on HBM. One is that our share has primarily been in the pre-stack wafer test of HBM, and we believe that we're going to be gaining share in performance tests of the HBM memory after it's been stacked. And so we're hoping that we can expand both our market share within the account where we are participating in HBM and then also break into additional accounts for HBM and that would be more of a 2025 thing. So I think overall, our outlook for 2025 and into 2026 is in line with what we talked about in January.
Greg Smith: Sure. So we, I think the way that we're looking at VIP is right now, because that growth has been happening at a time when there is a fair amount of capacity in OSATs to soak up. We're actually trying to keep track of the number of testers that are being used for these VIP customers. And right now it's hundreds of testers. There are currently hundreds of testers that are being used for VIP and we expect that to end. We have, I guess we should probably call it multiple VIP customers that are loading significant numbers of testers. We have additional VIPs where they've made plan of record decisions to put their parts on our testers and those parts are going to be released later in this year and into 2025. So we think that we'll probably exit this year with twice as many testers being used for these vertically integrated producers than we have right now.
Greg Smith: Sure, yes. So we tend to think of the process nodes not as, from our Business perspective, not as a driver, but as an enabler. So the 2 nanometer or Gate-All-Around, they're going to be enablers for higher device complexity. But the thing that really drives our Business is whether the end market is pulling for that complexity. And we're really optimistic that between cloud AI and especially for edge AI like in mobile, that that is going to be a major driver for companies to get into N2 even at a faster rate than they got into N3. So we think that it's a good thing that the capacity is being put in place for N2 because we think that it's going to be needed. In addition, the deployment of edge AI, it's really going to increase complexity of the application processors. It's also going to be pulling harder on the mobile part of the memory market. So we think that there's sort of a virtuous circle in terms of the capacity being put in place, the end market demand that's going to use that capacity, and then the pull effect on other parts of the market enabled by the features that are going into these products. So we think basically this is going to be a good demand driver really through the rest of this midterm, 2025, 2026, 2027.
Greg Smith: So that's a good question, Mehdi, because there's a little bit of subtlety to this. So you're right that one of the reasons that our mobile revenue and our compute revenue are going to be comparable in 2024 is because the mobile market is weak. But the other reason is, and I talked about this in my prepared remarks, that our compute revenue for the first half is bigger than all of our compute revenue for 2023 and we see good strength for compute in the second half of this year as well. So, like, things are going great in compute. Next year, we think that compute is going to remain strong, but the TAM sizes for compute are likely to be in the same range, maybe a little bit stronger than where they were. The mobile market really should come back pretty strongly, and so our mobile revenue will come back with that. So we anticipate that we'll have good revenue growth in compute, but it's very possible that mobile will outweigh it next year because of the strength of that recovery.
Greg Smith: That's a great question. So I think you are -- in terms of your hypothesis, you're hitting the nail on the head, that part of it is scale, part of it is channel. The thing that we are really -- we're actually really optimistic about our Robotics business right now, that the macro environment is really weak. Our automation peers are struggling with declining sales. We posted an 11% gain over the first half. And the thing that is encouraging to us is that that 11% gain is on the back of specific aspects of the strategy that we're executing. We were trying to expand our SAM [ph] by adding a high payload, high payload options for universal robots. And those robots are accounting for 20% of our sales in the quarter. We are trying to build additional channels, and our OEM channel grew by 70% year-on-year for the first half. We have additional irons in the fire to drive additional growth that have not yet paid off. And there are primarily other aspects of market expansion. So our Pallet Jack for the AMR business, additional products that are coming to market for UR as well. We have additional channels that we are building. We've been working for the last year and a half on building out a large accounts channel and we have significant pipeline for that, but we don't have significant revenue growth to see from it yet. And then finally, we think that there's a very significant revenue opportunity in service and recurring software. Right now, that's a vanishingly small part of our revenue in Robotics. But every business that has machinery in critical processes definitely needs to have a way to keep that stuff running. And we have an example in our semiconductor business, where service represents a significant portion of our overall revenue and we are trying to apply that same model of managed service plans in Robotics. And we're actually seeing good customer uptake, but not a lot of revenue yet. So we think that those three engines are going to be kicking in, in 2025, on top of growth that we're going to still get from the things that we've done in 2023 and 2024. So we're pretty optimistic that the end market is terrible, but we're actually doing what we said we were going to do in terms of the strategy.
Greg Smith: I'm really, really glad you asked that question. So there are a couple of things going on in the compute space around this topic of cloud AI and building large capabilities to do training of large language models. So the first is obviously huge demand for GPU's. That's why people have seen Nvidia run up as much. They are providing an incredibly valuable engine for all of this. But if you look at an AI enabled server, there is a much larger number of high speed data links within a server rack than there is for a traditional server. And so in more traditional accelerated computing, we were seeing a ratio of, within a specific account, it might be 90% GPUs, 10% networking, that's trending more towards 20% or even higher. So there's definitely a tailwind there that is beneficial. The other is, as these models become more sophisticated and the players in this space are trying to differentiate between these large language models, they're each trying to gain an advantage through architecture and that's driving this VIP design trend that we're seeing. So we think that there's enough end market demand to drive growth for both sort of traditional GPU based AI models and also drive even faster growth for the VIP or homegrown silicon that is being built into these large server firms.
Greg Smith: So, to answer the last part of your question first, I think we're very close to the point where the balance is going to tip back away from soaking up capacity to driving new system sales. The trends that we're seeing, third party data around test utilization are showing a good uptick, a little bit above sort of typical seasonality. Our own data is showing mixed utilization right now. We don't see a clear trend there, but we do have a fair amount of both systems that have already been converted and also upgrades that would be used as conversion kits. And so that is going to essentially occupy hundreds of testers that are underutilized now. So we are expecting utilization to tick up pretty strongly in the second half of this year, and for that to tip over to the point where it turns into real system demand. When you get to the IDM customers, especially in auto and industrial, there's an interesting, many of those customers are down significantly year-over-year from 2023 to 2024, but a lot of them are persisting in relatively aggressive capacity expansion plants. They see the same thing that we've been talking about in the automotive space, that there are going to be short-term fluctuations, but the crossover to EVs and hybrids is something that it's a question of like when, not if, that is going to happen and the amount of compute power in cars and other electronics in cars is going to continue to increase the attach rate of more chips per car shipped. So they have long-term plans to drive capacity and they have long-term plans for purchasing our equipment that we think is going to be important. So we are cautious about the current downturn that we're seeing in automotive, but we're really confident about the long-term potential in that space, especially parts of it where we have a ton of good share and great customer relationships like battery management, discrete in power and more and more importantly ADAS stuff. So right now I think the utilization in auto and industrial is down, but what the signals that we're hearing from those customers is that they expect that to be relatively short lived.
Greg Smith: Okay, so there's a lot to unpack there, so let's get down to it. So the story for MiR is pretty simple, that take a robot, add AI capability, and suddenly you have a robot that works better. That's our basic hypothesis behind the pallet jack, is that we're going to be able to have a higher success rate picking pallets than competing solutions. And so far, the customer reception is that they think that those claims have some merit. So we have a pretty strong backlog for a product that we're going to start shipping in Q4 of this year. So that's pretty simple. For UR, the story is a lot more complex because what we're really doing is creating a platform for our solution providers to build AI based solutions on. And there's actually like four chunks of an AI based solution on UR. At the bottom, you have our robot and the software that controls our robot. And then on top of that, there's AI toolkits that can come from Nvidia or can come from other providers that really give the primitives that allow people to use AI capabilities to solve problems. Then on top of that, there's usually a solution builder. And so what that solution builder will do is they'll take our robot and that toolkit and they will build a solution to do something like heterogeneous bin picking or vision based inspection or welding, and then they will take that solution and they will market it to their end customers. So the key thing that differentiates the UR platform from other robots is its features as a platform. So the APIs that people can use, the features that they need in order to build these solutions for, and that's what makes us sticky, is that once a solution provider builds a solution around a specific toolkit in our robot, it's tough for them to move off. The thing about that model for UR is that it's a slower burnt. That it's an indirect AI drives our business indirectly because we're not building the AI solution, our solution providers are. So I'll tell you that we have AI based solutions in the market. Right now, our estimate is that high single digits of UR sales are going into AI based applications that are in the market right now. So that's sort of our baseline and we intend to grow from there. These solution providers, it can take a while from when they begin building their solution to when they see a commercial inflection and that's often in excess of a year. So we have a great pipeline of partners that are using AI right now to try and build solutions and we would expect that to deliver material revenue in 2025, but not in 2024. So sorry for going deep, but you kind of hit a nerve.
Greg Smith: Okay. So on HBM, the primary difference from a test perspective, as you go from HBM3 to HBM3E to HBM4, is the data rates that are required in the performance test of the final HBM product and the capacity that's in place right now for HBM3, most of it, essentially all of it, is incapable of testing at the data rates required for HBM3E and HBM4. So the people that are building HBM3E are seeking additional capacity. They're essentially retooling to be able to test the HBM3E. Now, this is one of the areas where we believe we have an advantage that will allow us to gain share in HBM performance test, that we have a tester that is going to be effective for both HBM3E and HBM4. And so that essentially will give customers that adopt that solution longer asset life than if they were to adopt a competing solution. So we are pretty hopeful about our opportunity to gain share in HBM performance test and we're working on essentially benchmark competitions in multiple customers to try to prove that.
Greg Smith: So as you look into 2025, we don't think that we would see mammoth increases to the compute TAM. It is between 2x and 3x larger than it was in 2019 at this point in time. And for sure, people are trying to add capacity all through the production chain, but it's coming off of a really high base. So looking forward into next year, I would probably be looking at where we are this year, plus or minus something, versus a much -- a lot of increase in the compute space. Now, you asked about VIPs. Right now, VIPs are towards the low end of a $100 million to $200 million range. It could trend towards the high end of that by the end of this year. We think that by the time we get out to 2026, VIPs will be about $500 million of the overall compute spend. So I think that's a pretty exciting chunk. That could be a quarter to a third of the compute TAM could be driven by VIPs.
Greg Smith: So I guess the best thing to say is that at the point in time, there are two things that are going on since we set our plan. One is that the amount of underutilized capacity was larger than we thought at the point that we built our plan. The other thing that's happened since we built our plan is that even in 2024, compute has strengthened by a couple $100 million that the sort of the underlying demand drivers in the market are stronger than we were forecasting. So when you balance the deeper hole of utilization and the stronger end market demand then I think our hypothesis for 2026 holds.
Greg Smith: The mobility weakness is really both Android and iOS. If you look across the major suppliers for silicon for all of those ecosystems, it's generally pretty weak. Now, if you peel it back a little bit under the covers, there are some areas of the mobile space that have done better during this downturn than others. So one aspect of it is in image sensor, that the transition to, like 48 megapixel image sensors really put some pressure on the suppliers in that space, and they've added capacity both in iOS and Android land. The other is the improvements in wireless charging and other charging aspects that even now, when we've seen significant weakness in power and linear, we're still seeing some incremental demand as people always want their phones to charge faster. They want them to charge faster on wireless charging. So, we're seeing increased silicon content there. So it's been a little bit of a bright spot within that market. So, I think we've seen broad-based weakness in 2023 and continuing into 2024, and we expect to see relatively broad-based recovery in 2025.
Greg Smith: So, I will tell you that our OpEx acceleration is in both R&D and in our sales and marketing expenses. So you can infer from that that means that we're working on new products and we're working on building relationships with new customers and trying to capture. The key thing in semiconductors is that once customers make a platform decision, then it becomes very, very difficult to change their direction. And so we see a fleeting opportunity with all of the new VIPs to get in the door and influence that initial platform decision. So we're going to take those opportunities and we're going to make the investments to try to capture them while that share is available versus trying to move it after the cement sets. The one thing I will say is that the focus of our acceleration is really in our test business that we see that we have. We're confident in our strategy in Robotics, and we're confident for the OpEx plan that we put together. We saw no need to pour on more OpEx in our Robotics business. We're going to execute the plan that we set. But in the test business, especially in our semiconductor test business and in the system level test business, we saw an opportunity by accelerating our spend that we would be able to drive a better outcome long-term. So that's where that money's going.
Greg Smith: So it is mainly because the rollout of those programs. We're trying to make sure that we can walk before we run when it comes to these service programs. So we have essentially piloted the programs in a relatively small region and we're seeing good results in that region, but we have not deployed the program worldwide because we have to build out the infrastructure to support it. So that's why I say that we haven't seen material uptake is just because it isn't globally deployed at this point.
Greg Smith: Oh, definitely 2025. So in the back half of this year, we're going to be -- and also the sales cycle time for the service business is it's not terribly long, but it's probably a couple of quarters because you have to establish the value for the managed service plan. So we have a lot of interest. We are talking to a lot of customers, but we haven't closed the deals yet, because I think some of it is that it needs to be incorporated into their 2025 budgets. So, I'm very hopeful that we'll see an inflection in service revenue in 2025. I don't think we'll see much in terms of revenue in 2024.
Greg Smith: So our win rate on sockets, when we started describing our plans in VIPs, we said that we were trying to make sure that we got at least sort of an even split of sockets. And right now in 2024, that's kind of how it's playing out, that we're getting our fair share of wins. The other way that we're looking at this is in terms of testers loaded. So we're not looking at it in terms of tester purchases because of the underutilization, but we are trying to count noses in terms of how many testers are being loaded by our customers versus testers being loaded by our competition's customers. And right now I would say that we are kind of 60/40 in favor of Teradyne in terms of testers loaded for VIP customers.
Greg Smith: So right now it's not having a significant effect. The key thing that we are trying to do in the joint development projects that we have with Technoprobe is to take on relatively hard problems that required collaboration between us and Technoprobe that unless we had a firm partnership, we'd be unwilling to take that risk on speculation. We have initiated those projects, but they do require technology development on both sides. So right now, what we said at the point in time when we announced the deal is that we thought this would have a low-single-digit, long-term effect on market share in the Semi Test space. We still think that that's true and we think that we're on track to achieve those gains.
Greg Smith: So we haven't publicly announced sort of what segments of the market we are doing these joint development projects, because we think that we need to keep that relatively proprietary until we have demonstrated the success. But I will say that the key things that we believe are enabled by the projects that we're working on with Technoprobe are around devices that have very high power requirements and also devices that have very high parallelism. So the TPI probe technology is unlocking sort of the high end scalability of our test platforms in both SoC and memory. And we think that that's going to result in share gain by sort of opening up a place where both TPI and Teradyne are differentiated from their competition.
Sanjay Mehta: Yes. If I go back to 2023, it was about $100 million business. And $20 million to $25 million is roughly the number. And this quarter, with the sale occurring kind of end of the second month on May 27, it was $16 million. So I think that estimate you have is reasonable. And as I noted my prepared remarks, we expect growth year-over-year to be in the low single digits, but without DIS, you'd expect it, or that's a shortfall of roughly 3 points. So you would increase that by 3 points if there was no DIS in 2023 and 2024 from a growth perspective.
Sanjay Mehta: Sure. So, in 2024, we started the year with thinking that we'd be just a little bit above breakeven, low single digits. As we look to the year, and we see the range of 10% to 20% this year of growth, and we see that coming in more to the lower end of the range, we think that number is about breakeven. And in our earnings model, we had 20% to 30% growth. So with that incremental scale, we did build in a level of profitability in the outer years, and we still believe that that trajectory is going to occur as we move into the future.
Sanjay Mehta: Sure. So, this year at the midpoint, as we've noted, $800 million, and last year we noted approximately $900 million, and in 2022, it was roughly $1.6 billion. It peaked our view in 2021 at approximately $2 billion.
Sanjay Mehta: Hi Chris, it's Sanjay. At a top level, you're right, we did guide the full year consistently with the first half a little bit stronger than we anticipated. And what's happening under the covers is Semi Test is up, but our other test businesses are down a little bit in the way of in storage it's tied to the global market and SLT and the HDD. As that market returns, there is still underutilized capacity. In our Defense and Aerospace business, we had some projects push out and our production board business we had, it's tied to the automotive slowdown. And so overall Semi Test is stronger and the other test is lower. And then we did move to the lower end of our Robotics range. So at a top level we're calling the same year, but Semi Test stronger, other tests a little weaker, and Robotics is at the low end of the range.
Sanjay Mehta: Sure. So let me give some more context. So 2019, the compute TAM, our view was about $600 million. Fast forward, we went to nearly double that in 2021, between $1.1 billion and $1.2 billion. And then in 2022, it went to $1.3 billion and as you noted, 2023 at approximately $1.4 billion and this year at the midpoint, our view is $1.6 billion.
Sanjay Mehta: Maybe I'll just add a little bit. When we take a look at our model, as Greg noted earlier, mobility comes back. But let me remind also what he said. It doesn't come back to the peak levels, comes back to kind of a regular level, but mobility comes back. The trends in automotive, with more silicon going in, combustible engines, the conversion to EV and battery management systems is another tailwind and industrial comes back coupled with the compute. And I'll remind you that our Robotics business had a 20% to 30% growth in there as well. So that's kind of how you get there.
Sanjay Mehta: Yes, Brian, we did see acceleration from Q3 into Q2. Customers were pulling. And that's in my view we have a full year view and Semi Test is a little bit stronger, as I noted earlier. Customers are pulling and the demand is there. And we see a fairly strong backlog going into Q3 with kind of low turns. So we're in a, I think from a compute and memory perspective, yes we did see some acceleration.
Sanjay Mehta: Yes, so, rough numbers here, but we have on the order of 80,000 UR cobots out in the field, and probably on the order of 10,000 or more AMRs. The useful life of them is, we have cobots that were delivered before Teradyne bought Universal Robots that are still being used, but most of our customers will depreciate the asset over about a five-year period. So, I think if you're trying to model sort of installed base decay, it's not a bad idea to look at maybe a five to seven-year life. So, I think, and you're going at this exactly the same way that we're thinking about, that we look at the entire installed base, not just new equipment sales as our total available market service agreements. And we're also doing this service agreement build in alignment with the build out of our large account channel. So large accounts are the ones that are most likely to have large fleets and are most likely to see advantage from a managed service plan and that's another sort of aspect to the strategy that we're building out.
Sanjay Mehta: Yes, so we're happy with this year's gross margin performance kind of playing out as we expected. A little bit better though, in the first half, but 58% to 59% with continuous improvement. And I would say that, regarding next year, obviously, we'll provide a little bit more color in January. But the way I'd think about it is, we do expect revenues to grow, so we'll have a bit of a tailwind tied to volume. And it really depends in those segments you referred to as what specifically the customer is ordering. It depends on the configurations of the instruments. And so, I think, in my view, I think that we're exiting the year at our model. That's what we expect and look forward to giving you more of an update in January for 2025. But I would leave you with a higher volume level, it should help as tailwind.
