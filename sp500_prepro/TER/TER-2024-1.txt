Gregory Smith: Mehdi, this is Greg. I think you've got it right that utilization is continuing to increase. The equipment that is in place is being used quite efficiently through the year. So the loading is relatively constant. And we definitely believe that it's a matter of when, not if there's going to be a need for significant additional capacity to support that kind of product line. 
Gregory Smith: Interesting question. Thinking about the TAM, that is the overall size of the market, so what we would get, what our competitor would get. And the size of the accelerator market has gone up a lot this year. Most of the testers to support this year's revenue in accelerators was put in place last year. So if the TAM that was supported last year supporting that sort of big growth that we've seen in the end market this year, what's going to happen this year, the $1.5 billion that we talked about is going to support a significant increase again next year.  And this year, the primary beneficiary in terms of that end market is NVIDIA. What we're seeing now is that we are having some vertically integrated producers start to have significant ramps and they're already loading significant numbers of testers. The TAM in 2024 for compute is actually a little bit constrained below what it would otherwise be because these new entrants are actually able to work with their OSAT partners and convert idle testers that would have been in mobile into the compute space.   So right now, the loading of compute testers is higher than it was than what you'd see in terms of the buys in the market. As mobile starts to come back, that means that there's less idle capacity to fill. It also means that the compute market is going to be translated into more direct buys. 
Gregory Smith: Sure. So we are expecting to see some testers being used to support the engineering work in early parts in 2-nanometer probably towards the end of 2025. We don't expect any volume associated with 2-nanometer gate-all-around until 2026. And the way that we're looking at that right now is that there's nothing particularly idiosyncratic about that node in terms of tester demand.   So we're thinking of it primarily as an enabler to more complex parts. There are a lot of parts, for example, for cloud AI training that at this point are actually reticle limited, and so anything to allow increased complexity within the same die size is likely to be soaked up by AI. And so the faster that 2-nanometer comes online, the faster these more complex parts will be developed, and those will likely have longer test times, higher test intensity, which will drive the TAM. 
Gregory Smith: So in terms of competitive position, the share patterns that have existed for a few years are persisting. We have very high share in flash final test, we have strong share position in DRAM final test and we have a lower share position in both flat wafer sort and DRAM wafer sort. So what's happening in the memory market? Like last year, there was a lot of technology-driven buys that were pushing final test purchases. This year, the spark is coming back to the memory market, and that is driving the need for more capacity, and that is driving wafer sort purchases.   So there's no customer losses, but we are expecting to see our share come down a little bit this year as those wafer start capacity buys go in. Now the subtext underneath that is, HBM is a wafer-level technology, so all of the tests for HBM falls into that wafer sort space. And in HBM, last year, we had about 50% of the test TAM for HBM. This year, we're expecting that, that is going to come down modestly in terms of share. Our revenue is going to be up significantly, but the market is 5x bigger. So our share is probably going to float down a little bit as people begin to tool up next generation for the volume expansion in HBM.   At the same time, we think that our opportunities for share gain in terms of new test insertions for HBM are quite good. And so we're projecting that we're going to be penetrating new customers and new test steps for that this year. 
Gregory Smith: Well, from a vertically integrated producer perspective, it really kind of started back in like 2022, 2023. In 2024, like right now, there are hundreds of testers that are being used to test VIP source parts for us. And probably a similar number from our competitor. So it has happened. The thing that hasn't happened because of the -- the low utilization driven by the mobile slowdown, that hasn't translated into as much new tester purchases as we would have expected in a stronger market.  But we have multiple VIP sockets that are loading more than 50 testers each, and we have a pipeline of new design starts that we are plan of record for that will stretch out all the way into 2026. So this is real. It's happening now, but the impact on our financial results has been muted by the low utilization because of the mobile downturn. 
Gregory Smith: So we have limited visibility, so just bear in mind that I'm going into the realm of speculation here. The things that could drive a higher second half is the leading edge of some sort of a recovery in mobile. Right now, we have a pretty low baseline baked into our plan. So essentially any capacity shortfalls would immediately turn into business.   And then the other is, we've seen such a dramatic strengthening in the Compute segment with very short lead times in Q1. So that's what really drove our increased outlook for Q2. So we didn't see it coming. We had hints that it was coming. We thought it would be further out and smaller. It has come in bigger and faster than we expected. If that trend were to continue, then we'd see continued strengthening in the compute space, and that's another thing that could drive a second half up.   The other way to think about that is we don't really think that industrial and automotive is going to significantly strengthen in the year. That's more of a 2025 thing. 
Gregory Smith: Yes. So that's a great question. We've been having very rich discussions internally about this to try and figure out when you consider a smartphone to be AI-enabled. And we're thinking about it in terms of the complexity of the processor that goes into the phone. There have been neural processing units and AI features in phones for years. But now, the AI opportunity, the edge AI opportunity is driving things towards pushing the amount of silicon area used for AI up towards like 50% or 1/3 of the silicon area going into that.   So those types of processors are just starting to hit the market now at the premium tier. And I think we've got about a year of people trying to figure out what kind of customer features will actually be compelling using that. And right now, there aren't that many of them. I think that, that's what's going to happen during the rest of 2024, that there's some premium smartphones and some people that are trying to innovate the things to do with them. I think the processer generation that's really going to start having enough power to do LLM stuff on a phone is probably the stuff that would ramp towards the end of 2025, and it would become much more mainstream in the generation of silicon coming out in '26. 
Gregory Smith: I hope I caught all of your question. If I didn't, then please correct me. We don't comment about specific customers. I will share that we don't expect that our historically largest customer will be a 10% customer this year. I'll also share that we think that there is more of -- that we've gotten sort of the bottom dialed into our plan, that there's definitely more upside to downside in terms of the plan associated with mobile in general. 
Gregory Smith: So I'll start off with sort of a qualitative answer in terms of the drivers, but then I'll pass it off to Sanjay to give you more of the precise split first half, second half and the profitability. So what's going on right now is we have a plan for the year that's going to be essentially sequentially growing quarter by quarter. And the reason that the plan is laid out that way is because there are new growth drivers that are coming online throughout the year. There are drivers that are in place from last year in Q1, that's specifically the UR20 and UR30, the heavy payload cobots.   In Q1, we had the announcement of the MiR1200 pallet jack. That's going to start really impacting revenue in the back half, primarily in the fourth quarter, but we're already taking orders. We're building backlog for that product. We also announced the collaboration with NVIDIA. That's going to really drive business through our OEM solution channel. So we're going to be providing the platform tools to that channel, so that they can create stuff that goes to market. So that's stuff that will also be back half loaded.   The other thing that's driving through the year is we are continuing to build our OEM channel and our large accounts channel. So those are things that we started. We started OEMs back in '22, we started large accounts in '23, and they have a significant amount of gestation time before they deliver revenue. We're right at the point where OEMs are starting to really click. We talked about the 58% year-on-year increase in that space. I'm expecting to see growth above the aggregate growth for large accounts in 2024. So that's going to be a growth driver through the end of the year.   So with that, I'll pass it off to Sanjay to give you sort of the precise breakdowns. 
Gregory Smith: Yes. So Krish, one quick comment. The 5x comment about HBM was referring to the market size for HBM memory. So last year was about $100 million of TAM for HBM. This year, we think it's about $500 million worth of TAM for HBM. Our revenue is not going to go up by a factor of 5. It's going to go up. It's going to go up significantly. But we're not going to be able to hold sort of the 50-ish percent share of HBM that we had last year.  Are we over indexed to one customer? Well, the entire world is significantly over-indexed to one supplier in HBM. And that certainly has been driving our results to a great degree, both last year and will continue to drive our results this year. The other suppliers that are coming online. One of them is primarily internally based for test. We don't have any of that baked into our plan, although we think that they would be better off using our equipment, we haven't convinced them of that yet. And the other supplier in this space is a great customer of ours, although our share there is lower than our share in the leader in this space right now. So that's another reason that we expect to dilute our share a little bit this year.   The other point that I'll make is I was saying that we like our chances in terms of getting into new insertions for HBM memory this year. I think that, that's an important point. And we are hopeful that, that's going to be delivering significantly higher revenue for us through the midterm. 
Gregory Smith: This is Greg. Just one additional bit of color. If you think about the seasonality pattern that we developed really for a decade, 2010 through 2021, that seasonality, if you looked at all of our segments with the exception of mobile, there wasn't a really marked seasonality. Like those automotive, compute, industrial, they kind of chugged along. The seasonality was really driven by the mobile TAM, and that was driven by consumer buying behavior, right, that you needed to have things for the holiday season and for Lunar New Year. All of that inventory needed to be built up. And so there was a concentration of capacity that would go in, in Q2 and Q3, with mobile not driving right now, the seasonality is very, very muted. So I would expect to see that the seasonality will return once the mobile market is stronger, but I don't think you can use normal patterns to predict the way things will look in '24. 
Gregory Smith: Well, I think we certainly have optimism that it can get better. And that's basically because we've dialed in the bottom. And the way we do this is we typically will look at tester utilization numbers. And frankly, those numbers are all over the map. Some indicators show that capacity is tightening. Other indicators are showing that it's relatively -- utilization is tightening. Others show that it's relatively flat. Our qualitative checks, when we are talking to people in the ecosystem, they are telling us that capacity -- that utilization is getting tighter and it's forecast to go up from there.  So the thing that, that hasn't done is it hasn't turned into firm forecast for additional business. And there is a fair amount of -- I think the lack of visibility that we see, it runs all the way through the supply chain that people are wondering what's going to happen. People are wondering how well handset sales will recover? And I think it's really going to come down to the way that the holiday season demand is shaping up. That's the thing that's going to be the lever that either turns on some additional spot buys or we'll have people waiting until 2025. 
Gregory Smith: Yes. So in terms of the TAM increase, we moved the TAM up by $200 million. And I think -- I think your guess of $40 million is a bit low. I think we'll be up a bit more than -- we'll get a larger chunk of that up than that, probably in line with our historical share level, kind of 35% to 40% of that TAM increase should probably go to us. In terms of lumpy sales, no, I think actually the memory business is driving -- we have deliveries that will be stretching out through the year. And I think the demand is relatively steady and potentially increasing. So I think on a quarterly basis, we don't expect a lot of memory variation. 
Gregory Smith: Okay. So in terms of the macro environment, it's pretty weak. I mean it was weak throughout 2023, and we don't see a significant improvement right now in terms of the end market conditions. If you look at PMIs, some regions are clicking up slightly, but we haven't really seen that turned into like a hot market. Having said that, we're in a part of the robotics market that is very, very low penetration. And so we are not -- we have seen our business results vary with the macro conditions, and we think that, that is indicative of the -- that was one of the things that drove us to go and make the changes in terms of adding new products and driving channel development, because we think we're 5% of the way into something that could be huge.   And if that's the case, then we should be somewhat immune to these cycles. But we've been looking at like industrial robot competitors and their results this quarter have been pretty meager. Like especially if you look at their incoming order rates, which is more comparable, they have long lead times. We have short lead times. So it's better for us to compare their orders to our orders. We feel like we are doing far better than they are in these end market conditions. But we're really focused on kind of controlling our own destiny by finding the things that need support even when the end market is [indiscernible].   One thing that I'll say is looking at other sort of industrial analyst notes and talking to people in that space, they are expecting improved strength like they think that things are going to get better, not worse. So I'm optimistic that we're going to have some macro tailwinds in addition to the plan that we baked, that's kind of counting on things staying around where they are. 
Gregory Smith: Yes. So for sure, the great thing about AI, there are two primary benefits to AI. One is that it's far easier to design a solution that is able to deal with variation, whether it's part variation or location variation or other uncertainties that exist in normal manufacturing environments, the solutions end up being far more resilient. So that means that more people would be willing to adopt them.  People don't want to put fragile things into production and AI will help make things more robust. The simplicity of developing things is definitely a huge benefit of AI. So the demonstration that we did at GTC was a pretty sophisticated visual inspection application. And because we were leveraging a really powerful AI stack from NVIDIA, we were able to put that together in less than 2 weeks. It was a very fast turnaround to be able to build that solution. And we expect that both customers and customers and especially solution providers are going to be able to leverage that and create solutions to categories of problems that will help drive growth. 
Gregory Smith: Not really. Well, one thing is that most of the advanced packaging capacity in the world has been consumed by the people who are doing cloud AI, high-performance computing. So there's more demand than there is supply for it. So I think that's limiting it to the markets that are willing to pay the most for the ability to do it. I think that it's possible that chiplet technology will migrate out of high-performance computing potentially -- I mean it could potentially migrate into some mobile applications. I think that's going to be a relatively slow process because the price points are very, very different.   And then I think for industrial and automotive AI applications, it's likely to be a long time before you see chiplet technology in there because of the reliability and temperature range questions. It's a much more challenging environment to try and put packages. But that's kind of my view. I think that there are people that have a more aggressive view in terms of where chiplets will go. 
Gregory Smith: I think it's definitely the latter. So we believe we have a differentiated solution, both in terms of ability to support data rates out through HBM 4 and also in terms of being able to use same platform across multiple insertions. So we think that we have an ability to deliver more cost-effective performance test of HBM, and we believe that we're going to make some progress there. 
Gregory Smith: Yes. So let me take the large account question first. And I need to apologize to Brian because I didn't answer his question before. So the largest order that we've ever gotten from MiR, it came from an automotive customer. And it is also our historically largest customer for MiR. By no coincidence, it's also a significantly large customer for UR. So we have been selling them robots for a long time. The one thing that has happened since we established our large account effort is that we've been applying many of the strategic account management techniques that we've been using for decades in semiconductor test towards addressing those accounts and really organizing ourselves around the way that those large accounts acquire new equipment and also how to take care of the equipment that they have. So I think it's certainly an account that predated that effort, but I think our ability to serve that account has improved with this effort. 
Gregory Smith: I think actually, the large accounts may be the segment that has -- that will continue to be sensitive to end market conditions, because large accounts will work off of budgets. And if they don't provide budgets for automation, then those purchases won't happen. The thing that we're really trying to do is make sure that we are adding enough new opportunities to drive growth even if end market conditions are weak.   So a key part of this is being able to find and serve customers that have these problems. We have 95% of this market that is as yet unserved. So there is plenty of opportunity. And the key thing that we're trying to do is to pick our shots, pick the specific industry verticals and the specific applications that are likely to be driving growth independent of the aggregate macro conditions. 
Sanjay Mehta: And if I could add just a quick comment. In my prepared remarks, we noted that the -- our estimate was revised for 2023 for the compute market. When I do the math of our midpoint of $1.5 billion in '24 versus our old, you do get a 15% increase, but we revised that in my prepared remarks, I noted to $1.4 billion. So I think the growth is 7% versus 15%. I just wanted to point that out. 
Sanjay Mehta: Sure. Why don't I take the numbers, and maybe the competitive position, Greg, if you want to take? So the range that we provided was $1.2 billion to $1.3 billion, with the midpoint of $1.25 billion. And we think from a DRAM perspective, it's roughly 80% of that versus flash of 20%. Historically, I would say DRAM has been in the 40% and 50% of the overall memory market. So that's roughly the split. And then HBM we think is -- yes, we think that number is about $500 million. It's going to work upwards, but we think that number is above $500 million out of the $1.25 billion. 
Sanjay Mehta: So roughly the first half of the year -- well, first, as Greg noted, we expect to grow sequentially in Q2, and we expect to grow throughout the year for the reasons Greg just noted. But in the first half, we have 42%-ish plus or minus, and then 58% in the back half of the year. We do expect to be profitable this year. I would say, over the year, and I would say that, that would be single-digit profitability. I will comment, I think you asked about Q1. We were not profitable just given the seasonality of the quarter. That should give you the context, I think that you asked. 
Sanjay Mehta: I'll take the first one on the memory in the quarter. Yes. So I want to say roughly about 45% of the memory revenue that we had was tied in the first quarter to HBM. 
Sanjay Mehta: Yes. Interesting question. I'd say that I remember several years back when we talked about we were going into a downturn and that downturn was 4 to 6 quarters, and the downturn has gone a lot longer in the way of mobility. And as Greg noted, we believe that our forecast considers mobility at a point where we feel comfortable that it's going to be achieved. And so I think as things pick back up, the historical seasonality, I put it in the context of some segments are going to be recovering and we have some new segments that are -- or some segments that are growing fairly well. So I think the seasonality comment with regards to the test perspective, or test portfolio of businesses we have. It's a little bit off this year. 
Sanjay Mehta: Yes, I'll take the kind of the Q3 to Q2. It was, I'd say, mainly in compute and some ADAS that was accelerated and -- just looking up something. 
