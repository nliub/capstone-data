Shantanu Narayen: Thanks, Jonathan. Good afternoon, and thank you for joining us. Adobe had a strong first quarter. We achieved $5.18 billion in revenue in Q1, representing 12% year-over-year growth. GAAP earnings per share for the quarter was $1.36, and non-GAAP earnings per share was $4.48, representing 18% year-over-year growth. Our performance reflects the essential role that Adobe products play in driving the global digital economy. We're delivering on our strategy to unleash creativity for all, accelerate document productivity and power digital businesses. Adobe Creative Cloud, Document Cloud and Experience Cloud are more critical than ever to the success of creators, communicators, students, entrepreneurs, and businesses of all sizes with AI serving as an accelerant for all. We are a leader in delivering generative AI across all our clouds. We're taking a highly differentiated approach across data, models and interfaces. Our proprietary data is built on decades of deep domain expertise across creative, documents and customer experience management. We leverage large language models, as well as have invested in building and delivering our proprietary models in the creative document and marketing domains. Our IP-friendly approach is a differentiator for creators and enterprises. In addition, we've innovated by delivering generative AI directly in products with releases in Adobe Photoshop, Illustrator and Express across both desktop and mobile. AI Assistant in Acrobat and Reader unlocks the tremendous value of the trillions of PDFs around the world. We're bringing generative AI to Adobe Experience Cloud and will demonstrate our AI Assistant for Customer Experience Management at Adobe Summit. Every student, communicator, creative professional and marketer is now focused on leveraging generative AI to imagine, ideate, create and deliver content and applications across a plethora of channels. Adobe is uniquely positioned through the combination of Express, Firefly, Creative Cloud, Acrobat and Experience Cloud to deliver on this immense market opportunity. The success we are already seeing with our GenStudio offering in the enterprise is validation of our leadership, and we expect that success to translate into other segments as we roll out these solutions throughout the year. We are driving strong usage, value and demand for our AI solutions across all customer segments. We're successfully monetizing our innovations with particular strength in Q1 in the Enterprise segment across our Digital Media and Digital Experience businesses. This strength is reflected in our strong RPO growth of 16% year-over-year. We're pleased with a strong Q1. We have a phenomenal product roadmap that we're executing against to bring AI innovation across our global customer base and we're just getting started. I'll now turn it over to David to discuss the momentum in our Digital Media business.
Shantanu Narayen: Yeah. Happy to, Brent. And again, I'll reiterate that as it relates to us taking our targets pretty seriously. I mean, when we guided to $1.9 billion for the year, I mean, we had factored in both, as David mentioned, what was likely to happen in the pricing and how that rolls off, as well as the product roadmap, and when AI Assistant and Acrobat would be available, when Express, which is now in beta, would be available. So I think it factored in all of those. I guess if you are looking at it from accomplishment, we look at it and say hey, we did $410 million. I think last year we did $432 million. If we look at the guide and we're on track as it relates to the $1.9 billion, and to hopefully exceed that guide. And so from our perspective, it's playing out. Maybe the other color, Brent, that I would provide is given the desktop products are still in beta, and there we look at value and there we look at utilization. And so I think we gave you some numbers on the $6.5 billion generations that we're seeing, the really positive feedback that we're getting in Acrobat that continue to give us optimism associated with how that is. I think where there's tremendous interest and where if you look at it from an AI monetization, the two places that we're monetizing extremely in line with our expectations. The first is as it relates to the Creative Cloud pricing that we've rolled out. And as you know, the generative packs are included for the most part in how people now buy Creative Cloud, that's rolling out as expected. And the second place, where we are monetizing it is in the entire enterprise as it relates to Content and GenStudio. And I'm really happy about how that's monetizing it. I mean, that's a combination, Brent, of when we go into an enterprise for creation, whether we provide Creative Cloud or a combination of Express, what we are doing with asset management in AEM, workflow, as well as Firefly Services to enable people to do custom models as well as APIs. We're seeing way more monetization earlier, but again, very much in line with expected. So again, I look at the quarter and I feel really good, both about the product delivery as well as the way monetization is turning out. I mean, it's clear, I guess, a little bit from sort of what we've seen that expectations were perhaps a little higher, both in terms of what we would guide for Q2, but I'm really optimistic about what we have done.
Shantanu Narayen: And maybe just to add a little bit more of how we're thinking about it as it relates to the monetization of AI. I think we're in early stages as it relates to experimentation. So we're looking at both what the value utilization is as well as experimentation. The value utilization is actually really positive for us. I think, as it relates to the monetization and the experimentation, we have the generative packs, as you know, in Creative Cloud. I think you will see us more and more have that as part of the normal pricing and look at pricing because that's the way in which we want to continue to see people use it. I think in Acrobat, as you've seen, we are not actually using the generative packs. We're going to be using more of an AI Assistant model, which is a monthly model. As it relates to the Enterprise, we have both the ability to do custom models, which depends on how much content that they are creating, as well as an API and metering that we've rolled that out and we've started to sell that as part of our GenStudio solution. So I think it's fair to say, and I certainly monitor what everybody else in the industry is saying. The good news about this is the interface integration that we've done in all our apps and the utilization, and I think the experimentation will enable us to determine how we best attract the largest number of customers that we can who are new to Creative Cloud. We've talked about that as it relates to Firefly attracting new customers. Certainly, I think the number of Q1 commercial subscriptions was another record. So we're absolutely doing everything that we intended to experiment as we roll this out, Brad. So I wanted to accentuate that as well.
Shantanu Narayen: Sure. Saket. I mean, I'll start and then David can add. I mean, firstly, I think the advances, whether it's in OpenAI or our own models that certainly, David and I have the pleasure of looking at on a weekly basis, the advances are amazing because you have to -- when you're thinking about video solve some other fundamental problems like physics, right, I mean, if you have somebody walking on a street, how do you make sure that they don't go through a building or go through the floor? And so I think some of those video advancements that we have seen within Adobe have really addressed some of those hard problems. A big picture, though, video I think will be even more of an accelerant for editing applications. I think this notion that the next Oppenheimer will be done using a text-to-video prompt is just -- it's not going to happen for decades. And so I think actually more so in video, there's going to be an accelerant for people saying how do I get an on-ramp as it relates to using text to video and then edit that using our applications. And so I think I'm really particularly excited about what we can do with premiere as well as with After Effects as it relates to video. So net-net, I would say, Saket, the technology is impressive. We have our models, we have integrated into our interfaces. We're also partnering. I had a really great conversation with Jensen recently about what we can do as they are investing in video. Certainly, he would love to partner with us, and we're looking together to see how we can push the envelope on video as well using their models, whether it's Edify or Nemo. And so I think really early days, we're seeing a whole bunch. I hope -- and David mentioned this look at some of the lip sync stuff that we've done as well, which allows you to auto-dub and translate into languages. So we intentionally released a little bit of that demo. So really great advances. But net-net video is going to be even more of a need for editing applications in order to truly take advantage of generative AI.
Shantanu Narayen: Yeah. So we take our guide seriously. Q1 played out as expected. It was ahead of where we were last year. Our Q2 guide is ahead of where the guide was in Q2. We're talking about acceleration into the back half of the year. If I didn't feel like our full-year guide was achievable, we would have a different conversation. We're confident in the targets that we put out there, our ability to meet them. If there's an opportunity to do better, we certainly will. So we feel good about where we sit in the first half. And as we look forward into the second half, the momentum we see from an innovation standpoint integrating into our products, what we see going from beta to GA, we feel good about the momentum into the second half.
Shantanu Narayen: And let me tackle that, Keith, and maybe I'll just tackle it by taking a couple of the other questions as well, summarizing that and ending with your question associated with the financial results. I think the first question that I hear across many folks is, hey, with the advent of AI and the increase in the number of models that people are seeing, whether they be image models or video models, does that mean that the number of seats, both for Adobe and in the world, do they increase or do they decrease? To me, there's no question in my mind that when you talk about the models and interfaces that people will use to do creative content, that the number of interfaces will increase. So Adobe has to go leverage that massive opportunity. But big-picture models will only cause more opportunity for interfaces, and I think we're uniquely qualified to engage in that. So that's the first one. The second one, I would say, is that does Adobe innovate, and when we do that, do we only leverage the Adobe model, or is there a way in which we can leverage every other model that exists out there? Much like we did with plugins, with all of our Creative applications, any other model that's out there, we will certainly provide ways to integrate that into our application. So anybody who is using our application benefits not just from our model creation, but from any other model creation that's out there. The way we first started to execute against that is in the enterprise because for us, the enterprise and the ability to create custom models so people can tweak their models to be able to do things within Photoshop that are specific to a retailer or a financial service was where we focus. But long term, certainly, as I've said with our partnerships, we will have the ability for Adobe in our interfaces to leverage any other model that's out there, which again, further expands our opportunity. I think as we play out the year, when we gave our targets for the $1.9 billion in ARR and the $410 million in Digital Media ARR for Q1, it factored in both our product roadmap and how things would evolve in the year. All of the product roadmaps we knew whether it was Acrobat, whether it was Express, whether it was Firefly, whether it was Creative Cloud, or whether it's GenStudio that brings all of these together, we knew the product roadmap, which we're executing against. In the first half of the year, a lot of that was beta, and in the second half of the year, a lot of that's monetization. It's playing out as expected. If anything, I would say the excitement around that, and in particular, the enterprise is faster than expected. And so I think our ability to monetize it just -- not just through new seats but also through these new Firefly services is expanded as it relates to what we are doing. And then as it relates to your question around financial results and the go-forward execution, we gave a Q1 target, we beat the Q1 target. And that gives us confidence that the financial target that we gave at the beginning of the year, we're ahead of that. And that's how I'll play it out. You're right. You have to model it. You can look at last year's model and look at last year's model and say, hey, they got to $1.913 billion. If they're ahead, does that fundamentally change Adobe's thesis on why we get to $1.9 billion and beyond, and in my mind it doesn't. And so that's the way I would answer that question. We have to go execute against the opportunity that we have. I look forward to those who are at Summit. I'm sure we'll have a little bit more conversation. But Q1 was a strong start. It was a strong start against product execution. It was a strong start against the financial metrics that we outline, and we're going to go do it again, Keith. So that's how I'd answer your question. So thank you all for joining.
Dan Durn: Yeah. I'll start and others can go ahead and add on. First of all, we do -- as we look at the book of the business, it is a strong start to the year with Q1 coming in at a high watermark with $432 million across the entire business. As we look specifically at Creative Cloud, I just want to sort of make sure everyone takes a step back and looks at our strategy to accelerate the business because I think the growth drivers here are very clear. We are focused on expanding access to users with things like Express on mobile. We want to introduce new offers across the business with things like AI Assistant and also existing capabilities for Firefly coming into our core Firefly, our core Photoshop and Illustrator and flagship applications. We want to access new budget pools with the introduction of Firefly Services and GenStudio as we talked about. And the early signs, as you point out in Q1 results are really suggesting that those growth drivers are taking hold. As you talked about normalizing for FY '23, FY '24 pricing actions, we grew the CC business about 20% year over year. Other key things to look at is that we set another record for new commercial subscriptions in Q1, and the business growth remains stable at -- if you look back at revenue 12% -- if you look forward at ARR 12%. So the stability and the diversity of the business is strong. And as we enter the back half of the year, we have capabilities for Creative Cloud pricing with Firefly that have already started rolling out late last year, as we talked about, and we'll be incrementally rolling out throughout the year. We're ramping Firefly Services and Express and Enterprise. As we talked about, we saw a very good beginning of that rollout at the -- toward the end of Q1. We also expect to see the second half ramping with Express Mobile and AI Assistant coming through. So we have a lot of the back-end capabilities set up so that we can start monetizing these new features which are still largely in beta starting in Q3 and beyond. And as it relates to pricing, it's what we've talked about in the past. We had two pretty significant pricing actions that benefited FY '23, the first one being the Acrobat price increases that we had put out with the new value that we had introduced with sign capabilities, and also a CC price increase that we introduced in FY '22 that was rolling into FY '23. Both of those are rolling off as we have now introduced the new pricing for CC with Firefly, and overall, the roll-off of the prior pricing is more significant than the new pricing that we've introduced.
Dan Durn: Yeah. Thanks, Brad. I'll jump in on the first part, then toss it over to David for the second. So we're not updating the targets. What the targets we provided for the full year, they're, as of the December call. What we did share on the call was the material change that we saw in Q1 as a result of the Figma termination payment. We talked about the GAAP EPS impact. It rolls through Q1 and it'll certainly have an effect for the full year. And it's $2.19 as a result of the $1 billion payment. And I think with that, I think you have everything you need relative to where we set our targets, but we're not going to be updating them on this call.
Dan Durn: Yeah. So there was two pricing actions that we had taken in 2022. In May of 2022, we pushed forward a pricing action, and then October of 2022, we pushed forward the Doc Cloud line optimization, where we integrated Sign. The one-year anniversary of those pricing actions from May of 2022 and October of 2023, or -- I'm sorry, October of 2022 will be behind us on the one year anniversary. So you will still see some Q3 impact from pricing actions in the year-ago period. Q4 will be a clean look for the company, at least two months in Q4 will be a clean look. The actions that we're taking right now from both a pricing and a product standpoint on the Creative side will be more apparent in the back half of the year into the end of the year.
Dan Durn: And then as we think about the forward-looking, a couple of points I would turn to, just think about cash flow in Q1. Strength of our cash flow, once you normalize for the $1 billion termination payment, that's up 28% year-over-year. When you think about RPO, 3 point acceleration sequentially, and when I break that up on deferred revenue, unbilled backlog, you saw that acceleration in each of those subcomponents, which as you look through that acceleration, the near-term underscores the strength of the business and it underscores the longer term strength we have around the momentum of the business. When I think about individual product commentary, we talked about it a lot on this call. You see record commercial subscriptions in the Creative business. In Q1, you see engagement going up on the products. Usage of Firefly capabilities in Photoshop was at an all-time high. In Q1, Express exports more than doubling with the introduction of Express Mobile in beta now going to GA in the coming months, AI Assistant Acrobat, same fact pattern. You can see that momentum as we look into the back half of the year. And from an enterprise standpoint, the performance in the business was really, really superb in Q1, strongest Q1 ever in the enterprise. So there's a lot of fundamental components that we're seeing around performance of the business that give us confidence as we look into the back half of the year.
David Wadhwani: Yeah. And I'm happy to add a little bit. Yeah, in terms of the timing of the -- when we start enforcing credits, don't read anything into that other than right now, we are still very much in an acquisition mode. We want to bring a lot of users in. We want to get them using the products as much as possible. We want them coming back and using it. One thing I do want to state because I know there's a lot of energy around how do these credits play out over time. In the last few weeks, we've done a couple of sneaks that could also be instructive. Last month, we snuck music composition, where you can take any music track, you can give it a music type like hip hop or orchestral or whatever, and it will transform that initial track into this new type of music. Just this morning, we snuck our ability to do auto dubbing and lip-syncing, where you give it a video of someone talking and saying English, and then you can translate it automatically to French or Spanish or Portuguese or whatever. As you can imagine those actions will not take one credit. Those actions will be much more significant in terms of what they cost. So right now, Alex, the primary point is about proliferation and usage. We're going to be bringing in a lot more new capabilities throughout the tools that will drive more usage, and we're going to be bringing in more expensive capabilities as well. And as we've talked about, you should start to see that ramp through the year, and we feel very comfortable with the adoption we're seeing. Just one last thing to call out, as we mentioned on the call, highest number of users using generative AI in Q1 ever so we're very excited about the trajectory.
David Wadhwani: Yeah. Happy to talk about that. We were very -- and continue to be very happy with the performance of Document Cloud. If you really look at trying to understand sort of how that plays out Document Cloud, the growth is a combination of both our go-to-market efforts and our product innovation. On the go-to-market effort side, think about the fact that Reader continues to be a top-of-funnel for us and we continue to see Reader monthly active user growth. So the potential of people we can convert over to paid subscribers continues to grow. We also talked about the fact that Acrobat Web has been a major contributor to our growth. So we're seeing 70% year-over-year growth in terms of Web MAU, and we crossed 100 million monthly active users for the first time on the website. And of course, we're doing a lot of work with product-led growth to drive the Journey users to some of that value that drives conversion. So that's all we're doing on the go-to-market side. On the side of product innovation, our strategy over the last couple of years has been to make PDF the starting point of a workflow, right? And so that's why we integrated Sign directly into that so that people could use their PDFs and start a transaction for their business. And that continues to grow very nicely, and it's a great selling point for an integrated service. We also introduced link sharing a few years ago for commenting and reviewing with groups and teams. We saw that link sharing grow 300% year-over-year so that's a huge point of value, but it's also a huge point of viral growth. That's also what when someone receives that, it's another opportunity for us to bring them into the value of the broader offering. And you can expect to see that with AI Assistant as well. So obviously, everyone is looking at AI Assistant in Acrobat. I certainly hope all of you are using it, should make your lives more effective. Not just for insight. We think that there's a lot of opportunity for monetization of insight for AI Assistant on our core base of Acrobat users, but also for the first time doing consumption-based value. So the hundreds of millions of monthly active users of Reader will also be able to get access to AI Assistant and purchase an add-on pack there too. So it's a really broad base to look at how we monetize that, but it's also the start of the ability to take your conversation and generate emails and presentations and continue that process. So the combination of all of that is a really potent combination of go-to-market efforts and product innovation. So we continue to be bullish about this. So the second part of your question, we are -- as we've said multiple times on the call, we are very excited about all the innovation that's coming out that's just starting to ramp in terms of monetization and/or still in beta on the Creative Cloud side. We expect that to come out in Q3 and we'll start our monetization there. So we continue to feel very confident about the second half acceleration of Creative Cloud.
David Wadhwani: Yeah. And maybe I'll just add a few things. First of all, as Shantanu mentioned, the research in the industry and certainly with Sora is very impressive and exciting. It's also very consistent with the models that we're developing. So we think that there is -- there will be, as there was with video -- sorry, imaging, there will be multiple models that come out, including the Adobe model later this year, and we should start to see a lot of innovation there like we've seen in imaging. We've already started to sneak a couple of things that Shantanu talked about. So you will see text-to-video capabilities from us later this year. But you'll also see it with transparency around the training data that we have, you'll see it with more tool ability and controllability. You'll see it integrated into our tools as well. Now, all of that said, I do want to be very clear with what Shantanu said, which is that we see the proliferation of video models to be a very good thing for Adobe. And we're going to work with OpenAI around Sora. You're going to see us obviously, developing our own model. You're going to see others developing model. All of that creates a tailwind because the more people generate video clips, the more they need to edit that content, right? So whether its Premiere or After Effects, or Express, they have to assemble those clips, they have to color-correct those clips, they have to tone match, they have to enable transitions. So we're excited about what we're building, but we're just as excited about the partnerships that we see with OpenAI and others coming down this path. And if you take a step back, you should expect to see more from us in the weeks ahead with imaging and vector and design, text effects, and in the months ahead with audio and video and 3D. We're very excited about what all of this means, not just for the models, but also for our APIs and our tools.
David Wadhwani: Well, the way I would look at it, in terms of the rhythm of the numbers and how you've seen sort of what transpired in 2023, and how we look at 2024, and the path to $1.9 billion and beyond, the way I would look at it is we're ahead in Q1. We're ahead in Q1. We're giving you all the reasons why we think there's more product coming and more monetization coming in the rest of the year. And that's what gives us the confidence associated with the targets. I guess there's this question of every quarter, do we reiterate targets? Do we update targets? What does that mean? And the way we've always thought of it is, if it was a way -- if we didn't have confidence, we would give you that. We have confidence associated with the numbers, but we're not in the business of every quarter, looking at every number. And let's go down one other number, which was the GAAP EPS. Certainly, there's an impact, as you know, in the GAAP EPS associated with what we did as it related to the Figma sort of transaction, and therefore the impact to GAAP EPS in Q1. So I think, from my perspective, the quarter and the year is playing out just as we did, and I feel more confident now than I did when we gave you our annual targets. I'll leave it at that.
David Wadhwani: Yeah. Let me take the first one and then Anil can answer the question on sales. As it relates to the momentum we're seeing with Firefly, I think there are multiple layers of it. One is obviously, we're seeing the quality of the models. We're seeing a differentiated approach as it relates to the training data, as it approaches contribution of assets from our community and how we compensate those folks. And so that's not just an Adobe perspective, but it's playing out obviously, in enterprises as they look at what are the models that they can consider using for production workflows. We're the only one with the full suite of capabilities that they can do. It's a really unique position to be in, but it's also being noticed by the research community, right? And as the community starts looking at places as if I'm a PhD that wants to go work in a particular environment, I start to ask myself a question of which environment do I want to pick. And a lot of people want to do AI in a responsible way. And that has been a very, very good opportunity for us to bring in amazing talent. So we are investing. We do believe that we have the best -- one of the best, if not the best, research labs around imaging, around video, or around audio, around 3D, and we're going to continue to attract that talent very quickly. We've already talked about we have the broadest set of creative models for imaging, for vector, for design, for audio, for 3D, for video, for fonts and text effects. And so this gives us a broad surface area to bring people in. And that momentum that starts with people coming in has been great. The second part of this too is managing access to GPUs while maintaining our margins. We've been able to sort of manage our cost structure in a way that brings in this talent and gives them the necessary GPUs to do their best work.
David Wadhwani: And I don't know if Jay, you were asking for -- building your model, or if you were looking for a job? But if you're interested in any of these positions, let us know more.
David Wadhwani: Great. So maybe I'll take your first part, and Dan obviously, can take the second. So as it relates to generated content, I'm going to sort of break it up into two parts. One is around the tooling and how you create the content, and the second is around automation associated with the content. I think if you take a step back before we even get into either one of those, there is no question that there's a huge appetite because of personalization at scale, the need to engage users, the need to build your personal brand online. That content is going to explode in terms of the amount of content being created, and it's going to explode because of one of two things. The first is around the ability to create audio clips, video clips, images, vectors. These are things that get users started. It's a great for ideation. You'll see in a few weeks that some of the incredible work the team has been doing around ideation on Firefly.com. And once those things are created, they do flow into our tools for the production, work and process. We're clearly seeing a huge benefit from that because the more content that gets created, the more editing that's required, and that's what's driving more commercial CC subscribers this quarter than any other Q1 before. So that's the foundation of it. The second part of this, though, from an editing perspective is the controllability of -- and the editability of not just pixels and vectors and timelines, but also the editability of the latent space itself. The latent space being the core capability -- core model capabilities that actually generate the output. We have a lot of research that we've already started releasing, the first of which was Style Match, and you'll start to see more and more of that actually coming out at summit and beyond. But we are, in my mind, very, very clearly the leader in terms of creating models that can also be tooled on top of. So that combination of the models getting better and the controllability of those models, we're in a remarkable position for that. So we benefit from that. The second part, Kash, is around automation. So as people are generating more content, you clearly need to be able to automate that content and how it's created. And that's really where Firefly Services come in. First, it's built on the strength of our Firefly models, say for commercial use integrated into our tools, but it also adds the ability to have custom models so control what kinds of information or brand and content it's trained on for both brand styles and product replica, and it's also part of an ecosystem of API services, not just generate something which is a core part of it like text to image, or Generative Fill or Generative Expand, but also process. So once you generate some images through APIs and automation, you want to be able to remove the background, you want to be able to blur the depth, you want to auto tone, you want to apply actions to that image. And then the last is you want to be able to assemble that for delivery. Firefly services don't just generate something, but they let you have that entire ecosystem, and then you can embed that using low code, no code environments into your flows, and we are already embedding it into GenStudio and all of the capabilities that we're shipping. So I think the core part of this is that as more of this content creates, you need more tool ability. The best models are going to be the models that are safe to use and have control built in from the ground up. And I think we have the best controls of anyone in the industry, and they need to be able to be done in an automated fashion that can embed into your workflow. So I think all three of those vectors point to benefits for Adobe.
