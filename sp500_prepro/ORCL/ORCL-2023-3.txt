Larry Ellison: All right. I'd like to take a crack at that. So I'll start by check with Jensen over at NVIDIA. He and I had a very interesting conversation. Oracle's Gen 2 Cloud is quite different than the other hyperscalers. We have an RDMA network, a non-blocking RDMA network. Our network is very much faster than the other guys' network. What this means is if you're running a large group of NVIDIA GPUs in a cluster doing a large AI problem at Oracle, we can build these AI clusters, these NVIDIA GPU clusters and run them. We can build those things dynamically because we use -- our standard network supports the clustering, the large clustering of GPUs and allows them to communicate very quickly. So we can create these groups of GPUs. We can marshal them together. The other guys can't do that. They can build clusters, but they actually literally are physically building a new cluster. They're building new hardware. Our existing hardware, standard network, allows us to group these things together dynamically, these GPUs together dynamically, to attack AI problems. No one else can do that. So we have a lot of business, a lot of new AI companies coming to Oracle because we're the only ones who can run their workloads. And by the way -- and we are cheaper. But so we're faster and we're cheaper. Let me give you an example where we use it ourselves. We have a partnership in health care -- back to this health care thing. We have a partnership with health care with MD Anderson Hospital, and one of our independent software vendors called Ronan, where we built these AI -- disease-specific AI modules that make recommendations to doctors about care. And then what they really say at MD Anderson, if we see a patient with these symptoms, this is how we respond. And that's a big AI model that's built by MD Anderson working with Ronan running in the Oracle Cloud. And we've actually shown or I should say MD Anderson has actually shown, if you use the system, you reduce hospital admissions and readmissions by 30%. That's a stunning number. People talk about ChatGPT being really cool because they can write my high school essay for me. Well, how about reducing the hospital readmissions at MD Anderson by 30%? You decide which is more important. But AI is fabulous stuff, yes. And ChatGPT is very cool. There are other applications other than generative language in these large language models. We've really focused on on health care in the last year or so since the acquisition of Cerner and are working diligently with others to apply AI to health care and especially the management of the complex diseases like cancer. This is a cancer AI system. But we're also doing wellness, heart disease, et cetera, down the road. We think -- so our platform runs AI very, very well because we create these clusters of GPUs that we -- that can attack big problems very quickly. We do it economically, then we build the applications on top of that. We provide the service to a lot of the startups in the AI world. This is one example of where we're just way ahead of the other hyperscalers in terms of our network and our ability to do AI. Let me point out one last AI thing. The Oracle Autonomous Database doesn't have any database administrators. It's completely self-driving. The Oracle Autonomous Database is self-driving because it is driven by -- it is an AI module that is the DBA. We've replaced the DBAs with AI inside of our own cloud. The Oracle Autonomous Database actually it runs all the databases inside of the administrative part of our cloud, keeps track of all of our users, our billing, all of those things, recovery data sets, all of that stuff is now done using AI and our autonomous database. So we're a huge consumer of AI. We're a huge vendor of AI, GPU capacity, clustered capacity is -- we build AI modules in health care. And people are coming to us. NVIDIA is often recommending us as the best cloud for AI, and this is a good time to be there.
Larry Ellison: The answer is absolutely yes. There's actually more demand for AI processing than there is available capacity. So -- and we're the only ones, again, that can dynamically -- and by the way -- and we're short. We are expanding as fast as we can. It's really -- it's an exciting opportunity, but it's challenging when there's more demand than supply. But the great -- the difference with us is our standard network allows us to group together these GPUs and have them attack these problems. Whether it's a medical diagnostic problem or it's a generative language problem, a la ChatGPT. So we have a lot of ISVs seeking us out because we have the -- not only do we have the most cost-effective solution, we can make the solution available to them very quickly because it runs on our standard network. So they can -- we can create a cluster for them, they run their workload. And the moment their workload is through running, we can reallocate that cluster or break that cluster up and allocate it to other users. The other guys can't do that, they can't do it dynamically.
Larry Ellison: Well, I think there are two things. One is the system we're putting in for the DoD and for the VA is one patient, one record. So that's a model of it. The one going in, in Nova Scotia is the same. We are bidding on a huge contract for the NHS. Again, some of these contracts are enormous and the responsibility to go along with the contracts is also enormous. But our system, that's how our system works. Our standard system that we have built is one patient, one record in the database. So if you visit Stanford and UCLA and Mayo Clinic and Cleveland Clinic, even if you go to these four different providers for a variety of different issues, all of your data will be in one database. All your patient data will be in one place immediately accessible in a time of emergency or just a routine visit to the doctor. That's how our system is architected. That's how we're delivering it to us to customers right now. It's attracted a lot of attention. Actually, it's not only much better for the patient, helps deliver better -- gives doctors better information, deliver better outcomes, but it's also less expensive to do it that way than every hospital maintaining their own system to -- rather -- it's better that they should share a system in the cloud and integrate their data for the benefit of the patient. Saving lives is exactly what it's doing -- what's happening with our partner at Ronan and our partner at MD Anderson and other partnerships I could go into in more detail, and I'm happy to but not on this call, is these disease-specific AI modules where -- and the telemedicine modules that we're delivering, allows a patient in a community hospital in Montana to get the benefits of the wisdom of the best specialty cancer specialists at MD Anderson Hospital in Texas or a Memorial Sloan Kettering doc in New York or a Mass General doctor who's on faculty at Harvard Medical School. The fact that we're now using AI and telemedicine and instrumenting these diagnostic devices so the docs -- so -- in the community hospital, we have diagnostic devices that the Harvard faculty, then there at Mass General can look at and then they inspect the AI module to, a, gather much better information. And with that better information, have the best minds and AI -- real minds and artificial intelligence processing that information and prescribing, hopefully, the best procedure or the best medication for that particular patient, which translates into reducing readmission to the hospital as they did at MD Anderson and ultimately saving lives.
