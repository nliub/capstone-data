Ken Bond: Thank you, Lisa, and good afternoon, everyone, and welcome to Oracle's first quarter fiscal year 2024 earnings conference call. A copy of the press release and financial tables, which includes a GAAP to non-GAAP reconciliation and other supplemental financial information can be viewed and downloaded from our Investor Relations website. Additionally, a list of many customers who purchased Oracle Cloud Services or went live on Oracle Cloud recently will be available from our investor relations website. On the call today are Chairman and Chief Technology Officer, Larry Ellison, and Chief Executive Officer, Safra Catz. As a reminder, today's discussion will include forward-looking statements, including predictions, expectations, estimates, or other information that might be considered forward-looking. Throughout today's discussion, we will present some important factors relating to our business, which may potentially affect these forward-looking statements. These forward-looking statements are also subject to risks and uncertainties that may cause actual results to differ materially from statements made today. As a result, we caution you from placing undue reliance on these forward-looking statements and we encourage you to review our most recent reports including our 10-K and 10-Q and any applicable amendments for a complete discussion of these factors and other risks that may affect our future results or the market price of our stock. And finally, we are not obligating ourselves to revise our results or these forward-looking statements in light of new information or future events. Before taking questions, we'll begin with a few prepared remarks. And with that, I'd like to turn the call over to Safra.
Ken Bond: Absolutely. Before we do that, Lisa, just one quick clarification, that we currently have two EU sovereign regions live with more to come. Lisa, please poll the audience for questions.
Ken Bond: All right. Thank you, John, and thank you, Lisa. A telephonic replay of this conference call will be available for 24 hours on our Investor Relations website. Thank you for joining us today. And with that, I'll turn the call back to Lisa for closing.
Larry Ellison: Thank you, Safra. So, is generative AI is the most important new computer technology ever? Maybe, and we are about to find out. Self-driving cars, computer-designed antiviral drugs, voice user interfaces. Generative AI is changing the automobile industry, the pharmaceutical industry, how people communicate with their computers. Generative AI is changing everything. As of today, AI development companies have signed contracts to purchase more than $4 billion of AI training capacity in Oracle's Generation 2 cloud. That's twice as much AI training as we had booked at the end of the last Q4. I'm also very pleased to announce that Exai has signed the contract to do training in Oracle's Gen 2 Cloud. The largest AI technology companies and the leading AI startups continue to expand their business with Oracle for one simple reason, Oracle's RDMA interconnected NVIDIA superclusters train AI models at twice the speed and much less than half the cost of other clouds but growth in our AI cloud infrastructure business is not the only exciting news we have to report at Oracle. Our cloud applications business is doing quite well and it's about to get even better. In the current quarter we expect our Cerner Health business to be awarded two large new contracts with a total value of over $1 billion. And I’m now able to announce that all nine utility companies owned by Berkshire Hathaway are in the process of replacing all their existing ERP systems, and standardizing on Oracle's Fusion Cloud applications. Let me conclude with a few words about our database business and our upcoming announcement with Microsoft later this week. We will be substantially expanding our existing multi-cloud partnership with Microsoft by making it easier for Microsoft Azure customers to buy and use the latest Oracle cloud database technology in combination with Microsoft Azure cloud services. Satya and I will discuss the details of our expanding partnership at Microsoft headquarters in Redmond on the 14th. Please tune in, and thank you. Back to you, Safra.
Larry Ellison: Well, you can't build any of these AI models without enormous amounts of training data. So if anything, what AI -- generative AI has shown that the big issue about training one of these models is just getting that -- this vast amount of data ingested into your GPU supercluster. It is a huge data problem in the sense you need so much data. To train -- OpenAI to train ChatGPT 3.5, they read the entire public Internet, they read all of Wikipedia, they read everything, they ingested everything. And to specialize, and you take something like ChatGPT 4.0 and you want to specialize it, you need specialized training data from electronic health records to help doctors diagnose and treat cancer, let's say, and we are partners. Imaging for example, that is ingesting huge amounts of image data to train their AI models. We have our own -- another partner of ours in AI, ingesting huge amounts of electronic health records to train their models. AI doesn't work without getting access to and ingesting enormous amounts of data. So in terms of a shift away from data or a change in gravities at AI, AI is utterly dependent upon vast amounts of training data. Trillions of elements went into building ChatGPT 3.5, multiple times that for ChatGPT 4.0 because you have to deal with all the image data and ingest all of that to train image recognition. So we think this is very good for our database business, and Oracle's new Vector database will contain highly-specialized training data like electronic health records, while keeping that data anonymized and private, yet still training the specialized models that can help doctors improve their diagnostic capability and their treatment prescriptions for cancer and heart disease and all sorts of other diseases. So we think it's a boon to our business, and we are now getting into the deepwater of the information age. Nothing has changed about that. The demands on data are getting stronger and more important.
Larry Ellison: Well, again, our -- we have -- we are on our second generation of data center, and our second generation of cloud. Now a lot of people notice that we were a little bit late to the party, but that's because we moved from a generation which we were not very happy with to a second generation, which we think solved a lot of problems the other cloud companies have not yet solved. So the non-blocking ultrafast RDMA network is not only useful for AI -- training AI models, it's useful for almost everything. It's certainly useful for building a much faster database. It's useful for, in terms of the automation level we have in our data centers, our data centers are 100% automated. They configure themselves. They run themselves. We don't have a lot of labor. Now that saves us a huge amount of money, a lot of labor cost is saved. But the biggest advantage is, if you don't have human beings involved, you don't have human labor, you don't have human errors. You don't have mistakes. You can ensure security. Most security problems are caused by people that make mistakes or people that engage in mischief. We don't have that in our data center. That's another huge advantage. Our data centers are -- because they're all identical, the only way we could automate them was to make them all the same and they vary only by scale. There are big ones and small ones, but they are identical, they all have the same hardware pieces and the same software pieces. They all have the same automation and that automation allows us to put these data centers in very small countries. We expect to have many, many more data centers than any other cloud provider. But we also put those data centers at customers. Nomura Research, NRI, which resells Oracle Cloud capacity in Japan has two dedicated regions and are building two more. They run the Tokyo Stock Exchange. I don't know of any clouds that are running stock exchanges other than ours. And, again, it's because of the extreme reliability and security that we get with all of the automation that's included with our data center. So we have cost advantages, we have performance advantages, we have security advantages. And that's why we are growing much faster than any of the other hyperscalers.
Larry Ellison: Yeah, well the back-office in the cloud is very different than the back-office on-premise. And we have a big advantage that we are by far and away the biggest. I don't know, 95% of the cloud ERP market in terms of actual live customers using it. And we have an important partnership with JPMorgan Chase and we'll be announcing some more partnerships in the financial community at the upcoming CloudWorld, where we automate a lot of e-commerce, B2B e-commerce right in the cloud. So what is B2B big e-commerce between two Oracle Cloud customers, two Oracle ERP cloud customers? It's one Oracle procurement system talking to another Oracle order management system and financing the transaction through their bank. We automate that entirely in the cloud. If your bank is JPMorgan Chase, they originate the loan right along with your purchase. It’s e-commerce for B2B, with banking and shipping and insurance, all included and rolled together. No one -- we've done a great job as an industry, automating e-commerce for B2C. I mean, Amazon, Walmart, others have done a brilliant job in that. We've been doing that for a long time. We have not got the equivalent in B2B commerce because B2B transactions are much more complex. In the cloud, you can get all the parties together, the shippers, the insurance company, the manufacturers, the purchasers and we can automate that entirely within the Oracle Cloud. One ERP system talking to another, talking to their bank, talking to their insurance, doing a loan origination, getting it shipped and insured. So we make doing business much easier for our customers when they move to a modern cloud ERP system versus the on-premise ERP system that came before.
Larry Ellison: Well, if you're -- you're constantly training these models. Keep in mind, you have to bring in new data if you're in -- obviously in the healthcare field, in the legal field, new cases are being judged, new researches being published all the time and for your AI models to be relevant they have to be up-to-date. So it's not that you train and then do nothing but inferencing thereafter. So you're training and your inferencing sit right next to each other. As long as we can do this stuff twice as fast as everybody else that's on the -- not just on the training side, that's also on the inferencing side, then we are going to be half the cost or better. So we think we are going to be very, very competitive across the board whether it's training or an inferencing. So we don't -- so we are pretty confident that we've got a cost-performance advantages. Again, if you run twice as fast in the cloud, you cost half as much because you pay by the hour. So the performance advantage is really an enormous cost advantage for us. We don't see that going away anytime soon, and it applies to inferencing as well as well as training. Now as far as GPUs, are GPUs a low-margin business? Not for a 100% automated cloud with very, very low cost. We think, in some cases, our prices for GPU training, which are very profitable by the way, for us, but are often lower -- our prices are lower than the cost of other hyperscalers doing the training.
Larry Ellison: Okay. I'll talk about the progress on taking the existing Millennium’s Cerner software and moving it to new Millennium. We basically rewriting that software piece at a time by the way. It's not going to be a big rip and replace it all. There's a two-phase process with Cerner. The first thing is to get the lift and shift and get the existing system hardened, which we've done and moving the customers to the cloud, which we are in the process of moving everybody to the cloud. That will give them better performance, better security and new features will then start showing up with the system. And so there's a two-phase shift to the cloud, we are well on our way. The next is replace feature after feature after feature of the older Cerner system with a new Cerner system, new Millennium, which we are not coding in Java, like we usually do. The new Cerner system is being generated, as you know, generative AI generates code. We have an application generator called APEX. And we are not writing code for the new Cerner. We are generating that code in APEX, and it's going extremely well. Again, one of the great things about code generators is they don't make mistakes. Well, either they make the same mistake over and over again or once you fix the mistake, you fix it everywhere. So the code gen -- we are using a code generator, and to write the new features in Cerner and it's coming along very, very nicely. Also on the business side of things, we -- again, we think that Cerner business is going to get stronger and stronger again, Safra made the point. The old Cerner business you'd sell licenses. You sell a big contract and you get a big chunk of revenue in that quarter. Our new business model, as you know is cloud, so we get a big Cerner award and we get that money now over time rather than all upfront. So that's, if you will, a bit of a revenue headwind, but the Cerner business is doing extraordinarily well.
Larry Ellison: Let me let me just reinforce what Safra just said. We love to save money. One of the things we did with our data centers is we automated them. We -- what we saved labor costs and we saved -- we have better security and better reliability because we eliminated human error. With Cerner, the rewrite of Cerner, it's not armies of programmers that are going be rewriting this. We are generating the new Millennium software using APEX. And that's also going to save us a lot of human labor and generate higher quality code and higher quality user interfaces and better security all at once.
